
\addtocontents{toc}{\protect\thispagestyle{empty}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}\label{introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\AddToShipoutPicture*{\BackgroundPicA}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{What is Logic?}\label{What Is Logic}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Rational Creatures}\label{Rational Creatures}

Humans are rational creatures. 
As such, we reason about our circumstances and the world in general so we may understand them better. 
An improved understanding of the world helps us make informed decisions, which (ideally) tend to bring about preferable outcomes. 
If you find yourself lost in a labyrinth and hunted by a hungry minotaur, clever reasoning could help you escape. 
Poor reasoning could get you eaten! 

At least some of our reasoning is \emph{discursive}. 
Discursive reasoning is an iterative process: start with a set of initial claims and then infer a result from them, perhaps repeating the process until a certain conclusion is reached. 
Such a chain of inferences can be written down or otherwise recorded as an argument.

Knowledge of logic helps us exploit a particularly reliable kind of discursive reasoning. 
It enables us to judge an argument from any source according to independent, principled criteria.
Not only can we assess the strength of arguments presented to us; we can construct rigorous arguments of our own to share with others. 
Rationality thus has an important social aspect. 
By sharing arguments with each other we can, to some extent, coordinate beliefs and behaviors, and thereby complete tasks beyond the ability of any one person. 

The social role of argumentation provides a clue about the subject matter of logic. 
Arguments are shared by way of language. 
One can give an argument by writing it on paper, typing it in an e-mail, stating it in a speech, etc. 
Once inscribed or encoded in one linguistic medium or another, it can then be assessed by others. 
Accordingly, logicians must attend to certain public features of language. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Logical Consequence}\label{Logical Consequence}

Logic is the study of \emph{logical consequence} and \emph{logical truth}. 
When we say that one sentence `logically follows' from another, we mean that the first sentence is a logical consequence of the other. 
But how can we identify when some claim is a logical consequence of another? 
As suggested previously, we must attend to certain features of the language in which the argument is given. 

One sentence $\CAPPSI$ is a logical consequence of another sentence $\CAPPHI$ if and only if the truth of $\CAPPHI$ guarantees, in virtue of its logical structure, the truth of $\CAPPSI$.

Three points are worth making about this provisional definition. First, don't be afraid of the Greek letters: they're just variables for sentences. Second, the phrase `if and only if' is one we use throughout the text, sometimes abbreviated as `iff'. `$\CAPPHI$ if and only if $\CAPPSI$' is equivalent to `If $\CAPPHI$ then $\CAPPSI$ and if $\CAPPSI$ then $\CAPPHI$'. Third, a solid understanding of this definition depends on having a clear notion of \emph{logical structure}. One of the central goals of this textbook is to provide such a notion.

Consider the following two sentences:
\begin{smenumerate}
	\item George Washington was in the Continental Army and Nathanael Green was in the Continental Army.
	\item Nathanael Green was in the Continental Army.
\end{smenumerate}
The second sentence is a logical consequence of the first. If the first is true the second must be too. The next two sentences share the same structure as the last two:
\begin{menumerate}
	\item Benjamin Franklin was a delegate to the Continental Congress and Thomas Jefferson was a delegate to the Continental Congress.
	\item Thomas Jefferson was a delegate to the Continental Congress.
\end{menumerate}
As above, the second sentence is a logical consequence of the first. We can show the common logical structure of the preceding pairs of sentences using a \emph{schema}:
\begin{menumerate}
	\item $\CAPPHI$ and $\CAPPSI$.
	\item $\CAPPSI$.
\end{menumerate}
We have replaced the non-logical content of each sentence with Greek letters and kept the logical word `and'. The Greek letters serve as variables which stand for clauses of the English language. Any substitution of appropriate English clauses for the letters $\CAPPHI$ and $\CAPPSI$ in the above schema generates a pair of sentences in which the latter follows from the former.\footnote{We say more about what counts as an appropriate substitution later in the chapter.}

A sentence can also be the logical consequence of a set of sentences. For example, given the sentences,
\begin{menumerate}
	\item The sun is shining.
	\item\label{Birds} The birds are chirping.
\end{menumerate}
the following is a logical consequence:
\begin{menumerate}
	\item The sun is shining and the birds are chirping.
\end{menumerate}
We can represent the logical structure of these sentences in schematic form:
\begin{menumerate}
	\item $\CAPPHI$.
	\item $\CAPPSI$.
	\item $\CAPPHI$ and $\CAPPSI$.
\end{menumerate}
Any substitution of appropriate English clauses for the letters $\CAPPHI$ and $\CAPPSI$ in this schema generates three sentences in which the last follows logically from the first two.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Logical Truth}\label{Logical Truth}

A sentence is a \idf{logical truth} if and only if the logical structure of the sentence guarantees its truth.  For example,
\begin{menumerate}
	\item\label{Sun} If the sun is shining then the sun is shining.
\end{menumerate}
This sentence must be true, regardless of whether the sun is shining. Contrast that with sentence \ref{Birds}; if no birds exist, then \ref{Birds} can't be true.  There is nothing special about the non-logical content of \ref{Sun}.  We could replace `the sun is shining' with `it's raining outside' and get another logical truth:
\begin{menumerate}
	\item If it's raining outside then it's raining outside.
\end{menumerate}
The schema of these two logical truths is:
\begin{menumerate}
	\item If $\CAPPHI$ then $\CAPPHI$.
\end{menumerate}
The non-logical content is replaced with $\CAPPHI$ and the words `if\dots then' are retained. Any substitution of an appropriate clause of English for $\CAPPHI$ generates a logical truth.
More generally, logically true sentences have a structure such that, whatever appropriate clause(s) we substitute for the non-logical parts, the result is also a logical truth. 

To construct general schemas from particular examples, as we did above, requires distinguishing between the logical structure and the non-logical content of a sentence. 
We take for granted that certain ``logical'' words play a special role in constituting the logical structure of an English sentence---e.g., words such as `and', `or', `if\ldots  then', `not', `all', `some', among many others.

Logical consequence and logical truth are closely related concepts. In fact, each can be defined in terms of the other, though we won't specify the connection until we give a mathematically precise definition of each. Unfortunately, natural languages such as English have features that make these concepts difficult (or even impossible) to define adequately. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Natural and Formal Languages}\label{Preliminaries}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Natural Languages}\label{Natural Languages}

Calling English a \niidf{natural}\index{language!natural} language is only meant to indicate that it developed gradually and informally over time, and wasn't the product of, say, scholars officially defining the grammar and vocabulary from scratch. 
English, Greek, German, Russian, Spanish, Mandarin, and Hindi are all natural in this sense. 

Let's examine some of the obstacles to achieving mathematical precision in natural language. 
First, it is indeterminate which collections of words and letters are genuine sentences. 
The following strings are, perhaps, neither clearly sentences nor clearly not sentences of English:\footnote{Sentences \ref{Chom1} and \ref{Chom2} are from \citealp{Chomsky1957}.}
\begin{menumerate}
\item\label{Chom1} Colorless green ideas sleep furiously. 
\item\label{Chom2} Furiously sleep ideas green colorless. 
\item Seventeen is purple.
\item Green is a prime number.
\item Someone someone admires admires someone.
\end{menumerate}
There are no principled, universally accepted rules that determine whether each is officially a sentence of English. 
Without a clear distinction between sentences and non-sentences, we cannot be certain which are appropriate for substitution in logical schemas like those given in the previous section.

A second problem with natural languages is that they contain paradoxical sentences. 
A \underidf{paradoxical}{sentence} sentence is one that's true if and only if it's false. 
The most famous examples are those that engender the liar paradox, often called \underidf{liar}{sentence} sentences.\footnote{See the following: \citealt{Tarski1983,Tarski1944}, \citealp{Kripke1975}, \citealp{Barwise1987}, and \citealp{Gupta2001}.}
The following are two examples.
\begin{menumerate}
\item\label{liar1} Sentence \ref{liar1} is false.
\item\label{liar2} The second sentence on this page with exactly twelve words is false.
\end{menumerate}
Paradoxical sentences seem to be simultaneously both true and false. Try assuming that \ref{liar1} is false, and it seems to follow that it's also true. Try assuming that \ref{liar1} is true, and it comes out false.  Both outcomes are impossible because they're each contradictory. 
Paradoxical sentences frustrate systematic and coherent logical analysis, so logicians prefer to exclude them altogether.

A third problem is that natural languages contain \underidf{ungrounded}{sentence} sentences. 
The following pair is a good example:
\begin{menumerate} 
\item\label{si} Sentence \ref{sii} is true.
\item\label{sii} Sentence \ref{si} is true.
\end{menumerate}
These sentences seem to be unhinged from reality. 
We can assume consistently that both are true, and we can assume consistently that both are false, regardless of any substantive fact about the world. 
Most logicians prefer to exclude ungrounded sentences along with the paradoxical ones.

An important note is in order. 
Paradoxical and ungrounded sentences are different from \underidf{contradictory}{sentence} (or ``self-contradictory'') ones. 
The following is a contradiction, not a paradox:
\begin{menumerate} 
	\item The door is open and it isn't open.
\end{menumerate}
Unlike a paradoxical sentence, which seems to take both truth values, a contradictory sentence must be false. 
There is nothing wrong with contradictory sentences from a logician's point of view. 
They are perfectly legitimate relatives of logical truths. 
Just as a logical truth must be true, a contradiction (i.e., a logical falsehood) must be false. 
Contradictory sentences are self-refuting, but they take a single truth value and so are acceptable for our purposes. 

A fourth problem with natural language is that many, if not most, sentences of natural languages have ambiguous or context-dependent meanings. 
Consider the following. 
\begin{menumerate}
\item\label{syn1} Wealthy Americans flee south in record numbers.
\item\label{syn2} We gave the bananas to the monkeys because they
were hungry.
\item\label{syn3} We gave the bananas to the monkeys because they
were tasty.
\item\label{syn4} We gave the bananas to the monkeys because they
were there.
\item\label{he} Paul insulted George because he thought he was
someone else. 
\item\label{car} Sally's car is red. 
\item\label{tall} He is tall. 
\item\label{here} He is the tallest one here. 
\item\label{indexical} You are tall. 
\item\label{bank} Sally went to the bank. 
\end{menumerate} 
We can often resolve ambiguous sentence meaning by considering the particular circumstances in which a sentence is spoken or written. 
For instance, the ambiguity may come from an indexical term like \mention{you} (e.g., \ref{indexical}), in which case the intended referent is clear once we figure out who is speaking or writing to whom. 
Sometimes the meaning of a term is context-dependent, as with \mention{tall} (e.g., \ref{tall}). 
Five feet would be tall for a seven-year old, but not for an adult. 
Other cases are more complicated. 
Does \mention{Sally's car} in \ref{car} mean the car Sally owns, leases, or something else? 
Is \mention{red} the color of the car's exterior or interior? 
Is it light red, dark red, or something in between? 

Pronoun reference can be difficult to resolve, even in context (e.g., `he' in \ref{he}, \ref{tall}, \ref{here}). 
Finally, sometimes a word in the sentence has multiple distinct meanings (e.g., \mention{bank} in \ref{bank}) or the overall syntax of the sentence is ambiguous (e.g., \ref{syn1}--\ref{syn4}). As a result the intended meaning of the sentence may not be recoverable from the context without additional information.

Ambiguous sentences can make careful logical analysis difficult or impossible. The following looks like a logical truth:
\begin{menumerate}
	\item If she is tall then she is tall.
\end{menumerate}
But what if the first `she' refers to one person and the second refers to another? 

%\footnote{%
%A natural response to ambiguity is that typically it's a feature of sentence \emph{types} (see \pmvref{Some Distinctions} of this chapter). 
%Often the ambiguity is solved at the level of tokens: the context of utterance or writing typically makes it so that ambiguities in a given token sentence's type are resolved. 
%But this isn't always the case. 
%\label{pragmaticsfootnote}
%}

\subsection{Formal Languages}\label{Formal Languages}
The logician avoids these difficulties by using carefully constructed formal languages.\footnote{Poorly (or deviously) constructed formal languages can have the same problems as natural ones.} 
A \underidf{formal}{sentence} language has the following features: 
\begin{cenumerate}
	\item\label{formal1} There is an explicit list of permitted symbols.
	\item\label{formal2} There is a definition of which strings of symbols count as sentences.   
\end{cenumerate} 
A \idf{string} of symbols is just a row or sequence of symbols. 
For example, \mention{fq3H7} is a string consisting of \mention{f} followed by \mention{q}, \mention{3}, \mention{H}, and \mention{7}. The order of the characters is important; \mention{f7q} is not the same string as \mention{7fq}. 

Formal languages have a precisely defined syntax, but no fixed semantics. 
Definitions of sentences in formal languages make no reference to meanings of the sentences or their parts. 
These definitions make reference only to the \emph{form}, or shape of the symbols and their arrangements in strings. 
We should think of the symbols and sentences of a formal language as lacking inherent meaning.

In a well-constructed formal language we can check whether any given string is a genuine sentence, solving the indeterminacy problem faced by natural languages.
We also exclude the features of natural languages that lead to paradoxical and ungrounded sentences. 
Sentences of formal languages have no inherent meaning, but there are ways to assign meaning to them while avoiding the difficulties of natural language. 
In chapter \ref{Translations} we provide methods of translating English sentences into constructed formal languages.

By turning to formal languages we are using a familiar (and often successful) strategy of replacing a hard messy problem with a more tractable mathematical one. 
For example, geometry doesn't deal with points or lines in the physical world; the points and lines of geometry have zero area and zero width, respectively. 
Nevertheless, geometry provides useful models of the physical world when physical points and lines approximate geometrical ones sufficiently.
When the logical features of our formal language sufficiently reflect the logical features of our natural language, mathematical idealization is a productive strategy.\footnote{%  
	Historically the move to formal languages in the study of logic (and mathematics) has been fruitful. 
	One example, important for the development of modern logic, comes from set theory. 
	By using formal methods logicians found that the na\"{i}ve axioms of set theory are inconsistent \citetext{see \citealp{Demopoulos2005} for a quick overview of Russell's paradox, or \citealp[ch~1]{Smullyan2010} for a more careful discussion}.
} 

How do our formal languages relate to natural languages like English?
We think of the formal languages as abstract models of important parts of their natural counterparts. 
We cover several formal languages in this text: \GSL{} (chapter \ref{sententiallogic}), \GQL{}1 (chapter \ref{quantifierlogic1}), \GQL{} (chapter \ref{quantifierlogic}), and later \MGSL{} and \GQLI{} (chapter \ref{furtherdirections}), will serve as progressively more detailed models of English. 
After learning how to define these formal languages and how to translate between them and English, the logic student should have a better understanding of the logical structure of English and of logical consequence more generally.
The student should keep in mind that these formal languages cannot perfectly capture all the desirable logical features of English. 
There is a limit to both the range of English sentences they model and the accuracy with which they model them. 

\section{Some Distinctions}\label{Some Distinctions} 
\subsection{Use and Mention}\label{usemention}
There are three distinctions that are important in the modern study of logic. 
The first is the \distinction{use}{mention} distinction\index{\distinction{use}{mention} distinction}. 
For any word or expression (string of words), we can either \emph{use} the word or expression, or instead \emph{mention} it. 
\emph{Using} words and expressions is what we normally do, while \emph{mentioning} a word or expression is one way to talk about that word or expression. 
For example, you could say (i) that a cow is a four-legged bovine, or you could instead say (ii) that \mention{cow} has three letters. 
In case (i) we are talking about a particular kind of animal, while in case (ii) we are talking about the \emph{word} for that animal. 
In this textbook words that are mentioned are put in single quotes.\index{single quotes} Here are some examples:
\begin{menumerate}
\item Houston has over 2 million inhabitants. [True]
\item Houston has over 10 million inhabitants. [False]
\item \mention{Houston} has more than 2 million inhabitants. [False]
\item \mention{Houston} has more than 4 letters. [True]
\item Austin has more than 4 letters. [False]
\item\label{twentyeight} \mention{Austin} has exactly 6 letters. [True]
\end{menumerate}

\subsection{Type and Token}\label{typetoken}
The next distinction is the \distinction{type}{token} distinction.\index{\distinction{type}{token} distinction} 
How many letters does \mention{Houston} have?  The answer depends on whether the asker means letter tokens or letter types.
A \idf{token} is a physical object or event, while a \idf{type} is an abstract \emph{kind} of physical object or event. 
Tokens are located in space and time, while types presumably are not. 
The word \mention{Houston} has 7 letter tokens and 6 letter types, because the letter \mention{o} occurs twice.
In the sentence \mention{Ron went on and on} there are five word tokens and four word types.\footnote{In the sentence \mention{Ron went on and on}, there are three occurrences of the string \mention{on} with one of them in the name \mention{Ron}.  However, this instance doesn't count as a word token in English, because it's only a piece of a word, not a complete word.  Other cases in English are more ambiguous.  In the compound word \mention{footnote} does \mention{note} count as a word token?} 
In \mention{radar} there are five letter tokens and three letter types. 

\subsection{Object Language and Metalanguage}\label{objectandmetalanguage}
The third distinction is that between an object language and a metalanguage. 
Returning to the \distinction{use}{mention} distinction, if one mentions a word, then the \idf{object language}\index{language!object} is the language of the word being mentioned and the \idf{metalanguage}\index{language!meta-} is the language in which that word is mentioned. 
For example, if I say \q{The German word for dog is \mention{Hund},} I've used English (the metalanguage) to talk about German (the object language). 
In this text the metalanguage will always be English augmented with some carefully selected mathematical notation. 
The object language will be a formal language. 

Usually there's a little more to being a metalanguage than the mere fact that it's the language used to talk about another. 
Often there's some specific purpose. 
For example, the metalanguage might be used to give definitions of words in the object language. Or, as in our case, the metalanguage might be used to define when a sentence of the object language is true, or to describe when the logical consequence relationship holds between sentences of the object language. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{MathEnglish}\label{MathEnglish}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The various formal languages in this text are to be object languages.  However, before we can define our first formal language (\GSL{}) we need to familiarize the reader with certain mathematical concepts.  The metalanguage contains a mix of English, mathematical symbols (e.g., set theory operators), and other technical jargon.  We call our metalanguage \idf{MathEnglish}.   

\subsection{Metavariables}\label{metavariables}
One important tool for MathEnglish is the \emph{metavariable}, which we define as a variable for strings of the object language.\index{variables!MathEnglish}  
We use lowercase Greek letters as our metavariables, as we did in the schemas given at the beginning of the chapter.
The three we use most commonly are \mention{$\CAPPHI$} (phi), pronounced \q{fie}, \mention{$\CAPTHETA$} (theta), pronounced \q{theta}, and \mention{$\CAPPSI$} (psi), pronounced \q{sigh}.
These Greek letters are not in the object language, but instead are used in the metalanguage for talking about the object language. 

An example will make their role more clear.  Let's say that MathEnglish is our metalanguage and (regular) English is our object language.\footnote{As discussed earlier, in later chapters we use a formal language and not English as our object language, but for the purpose of illustration we temporarily ignore the problems of natural language.}  Recall the logically true sentence from the beginning of the chapter:

\begin{quote}
\noindent{}If the sun is shining then the sun is shining.
\end{quote}

\noindent{}We can replace `the sun is shining' with any other assertion and get another logically true sentence.  With this in mind, consider the following claim of MathEnglish: 

\noindent{}\begin{quote}All English sentences of the form \mention{If $\CAPPHI$ then $\CAPPHI$} are logical truths.\end{quote}

\noindent{}The use of `$\CAPPHI$' helps us talk about \emph{all} English sentences of a certain form as logically true, or at least all English sentences of a certain kind. 
As logicians we are concerned with truth and truth-preservation, so we are only going to address strings with plausible truth values, i.e. declarative sentences. 
A declarative sentence is one that makes an assertion. 
By restricting the substitutions to declaratives, we rule out substitutions such as `Ergle bergle barfle narfle,' 'nef34fwjh9ufh32,' `Kentucky fried chicken,' and `Are you cooking?'. 
We cannot legitimately affirm truth or falsity of these non-assertions. 
In the rest of the text, when we refer to \mention{all} sentences of a natural language we only mean the declarative ones.

In any case, metavariables are indispensable tools for making general claims about object languages.


\subsection{Sets}\label{sets}

MathEnglish makes use of set theory.  A \emph{set} is just a collection of items called \emph{elements}. Elements can be anything, like animals, people, planets, cartoon characters, or even abstract objects such as numbers.  A set can be specified using curly brackets, as in the following set of integers from 1 to 4:

\begin{center}
\noindent{}$\{1, 2, 3, 4\}$
\end{center}

\noindent{}The order of elements in set notation doesn't matter, so the following set is identical to the last:

\begin{center}
\noindent{}$\{2, 3, 1, 4\}$
\end{center}

\noindent{}Furthermore, repetition of an element in set notation is to be disregarded; an element can only be in the set once.  Accordingly, the following sets are the same set as the last two:

\begin{center}
\noindent{}$\{1, 2, 2, 3, 3, 3, 4, 4, 4, 4\}$\\
\noindent{}$\{2, 2, 3, 1, 4, 2, 3, 1, 4, 4, 3\}$
\end{center}

\noindent{}Sets don't have to be finite. Consider the set of positive integers:

\begin{center}
\noindent{}$\{1, 2, 3, 4, ..., 1002, 1003, 1004, ... \}$
\end{center}

There is one set that doesn't have any elements, and it's called either the \emph{null set} or the \emph{empty set}.  Symbolically the empty set is denoted by either $\{ \}$ or $\emptyset$.

Set membership is expressed with the `$\in$' symbol.  Let the Greek letters $\Delta$ and $\Gamma$ stand for arbitrary sets. (They are pronounced \mention{delta} and \mention{gamma}, respectively.)  We assert that $7$ is an element of set $\Delta$ and $3$ is an element of $\Gamma$ as follows: $7 \in \Delta$, $3 \in \Gamma$. On this notation,

\begin{center}
	\noindent{}$2\in\{1, 2, 3\}$
\end{center}

\noindent{}is true and,

\begin{center}
	\noindent{}$4\in\{1, 2, 3\}$ 
\end{center}

\noindent{}is false.

We use lowercase Greek letters $\alpha$ and $\beta$ (pronounced \mention{alpha} and \mention{beta}, respectively) as metavariables for elements. For example, if $\alpha$ and $\beta$ are odd numbers and $\Delta$ is the set of even numbers, then $\alpha + \beta \in \Delta$.

\begin{majorILnc}{\LnpDC{Subset}} For any two sets $\Delta$ and $\Gamma$, $\Delta$ is a \df{subset} of $\Gamma$ \Iff for each $\alpha$ such that $\alpha \in \Delta$, $\alpha \in \Gamma$.
\end{majorILnc} 

\noindent{}For example, $\{1, 2, 3\}$ is a subset of $\{1, 2, 3, 4\}$. The set $\{1, 2\}$ is a subset of each of the two previous sets.  The symbol `$\subseteq$' denotes the subset relation.  So if $\Delta$ is a subset of $\Gamma$, $\Delta \subseteq \Gamma$. Note that by the above definition every set is a subset of itself.

\begin{majorILnc}{\LnpDC{Proper Subset}} For any two sets $\Delta$ and $\Gamma$, $\Delta$ is a \df{proper subset} of $\Gamma$ \Iff 
	\begin{cenumerate}
		\item $\Delta \subseteq \Gamma$ and
		\item there is some $\alpha$ such that $\alpha \notin \Delta$ and $\alpha \in \Gamma$.
	\end{cenumerate}
\end{majorILnc}

\noindent{}As you can probably guess, the \mention{$\notin$} symbol means \mention{is not an element of}. The symbolic notation for \mention{$\Delta$ is a proper subset of $\Gamma$} is $\Delta \subset \Gamma$. No set is a proper subset of itself.

Take care to avoid confusing the membership, subset, and proper subset relations.

\begin{menumerate}
	\item $2\in\{1, 2, 3\}$ [True]
	\item $2\subseteq\{1, 2, 3\}$ [False]
	\item $\{2, 3\}\subseteq\{1, 2, 3\}$ [True]
	\item $\{2, 3\}\in\{1, 2, 3\}$ [False]
	\item $\{2, 3\}\subset\{1, 2, 3\}$ [True]
	\item $\{1, 2, 3\}\subset\{1, 2, 3\}$ [False]
\end{menumerate}

\subsection{More on Sets: Union and Intersection}\label{moreonsets}

Sometimes a set is defined by reference to other sets. Say that there is a set $\Delta$ that contains all the members of two other sets, $\Gamma_1$ and $\Gamma_2$, and nothing else. Then $\Delta$ is said to be the \emph{union} of $\Gamma_1$ and $\Gamma_2$. Let's give a strict definition:

\begin{majorILnc}{\LnpDC{Union}} $\Delta=\Gamma_1\cup\Gamma_2$ \Iff 
	\begin{cenumerate}
		\item for each $\alpha \in \Gamma_1$, $\alpha \in \Delta$ and
		\item for each $\alpha \in \Gamma_2$, $\alpha \in \Delta$ and
		\item for each $\alpha \in \Delta$, $\alpha \in \Gamma_1$ or $\alpha \in \Gamma_2$ (or both).
	\end{cenumerate}	
\end{majorILnc} 

\noindent{}The symbol \mention{$\cup$} means \mention{union}. Some examples:

\begin{center}
	\noindent{}$\{$Mercury, Jupiter, Mars, Saturn$\}=\{$Mercury, Jupiter$\}\cup\{$Mars, Saturn$\}$.
\end{center}

\begin{center}
	\noindent{}$\{$Newton, Bacon, Boyle$\}=\{$Newton, Bacon$\}\cup\{$Bacon, Boyle$\}$.
\end{center}

Another useful concept is \emph{intersection}.  The set $\Delta$ is the intersection of two sets $\Gamma_1$ and $\Gamma_2$ \Iff $\Delta$ contains all the elements shared by both $\Gamma_1$ and $\Gamma_2$ but nothing else. More strictly:

\begin{majorILnc}{\LnpDC{Intersection}} $\Delta=\Gamma_1\cap\Gamma_2$ \Iff 
	\begin{cenumerate}
		\item for each $\alpha$ such that $\alpha \in \Gamma_1$ and $\alpha \in \Gamma_2$, $\alpha \in \Delta$ and
		\item for each $\alpha \in \Delta$, $\alpha \in \Gamma_1$ and $\alpha \in \Gamma_2$.
	\end{cenumerate}	
\end{majorILnc} 

The symbol \mention{$\cap$} means \mention{intersection}.
The intersection of $\{$Mercury, Jupiter$\}$ and $\{$Mars, Saturn$\}$ is the empty set, $\{ \}$, because the former two sets have no members in common.

\begin{center}
	\noindent{}$\{$Mercury, Jupiter$\}\cap\{$Mars, Saturn$\}=\{ \}$.
\end{center}

\noindent{}By contrast, the intersection of $\{$1, 5, 6, 9$\}$ and $\{$2, 3, 5, 6$\}$ is $\{$5, 6$\}$.

\begin{center}
	\noindent{}$\{$1, 5, 6, 9$\}\cap\{$2, 3, 5, 6$\}=\{$5, 6$\}$.
\end{center}

\noindent{}Another example:

\begin{center}
	\noindent{}$\{$Carnap, Quine$\}=\{$Anscombe, Quine, Carnap$\}\cap\{$Carnap, Lewis, Quine$\}$.
\end{center}

\subsection{Ordered Pairs and Ordered n-tuples}\label{orderedpairs}

Sometimes we would like to describe a collection in which, unlike sets, the order does matter.  For that purpose we have \emph{ordered pairs} and \emph{ordered $n$-tuples}.  An ordered pair is a two-place collection in which the order matters.  To differentiate ordered pairs from sets, we indicate them using angled brackets rather than curly brackets.  So, while the sets $\{$1, 2$\}$ and $\{$2, 1$\}$ are identical, the ordered pairs $\langle$1, 2$\rangle$ and $\langle$2, 1$\rangle$ are not.

An ordered collection having more than two places is an $n$-tuple, where $n$ is the number of places needed.  So, $\langle$Mercury, Venus, Earth$\rangle$ is a 3-tuple, $\langle$Jupiter, Saturn, Uranus, Neptune$\rangle$ is a 4-tuple, and so on.

Also unlike sets, for ordered pairs and $n$-tuples, repetition makes a difference. For example, $\langle 1, 2, 3\rangle$ is different from $\langle 1, 2, 3, 3, 3\rangle$.

\subsection{Mathematical Proofs}\label{Mathematical Proofs}

We use proofs to establish that something has certain mathematical properties. 
A proof works from one or more definitions to some interesting result, called a \emph{theorem}. 
Much of this textbook is filled with proofs of theorems about the various formal languages defined in later chapters.
If we want to prove an intermediate result that isn't by itself particularly interesting but which is handy for use in one or more other proofs, we sometimes call it a \emph{lemma}.

To illustrate, let's look at a simple proof.

\begin{THEOREM}{\LnpTC{Transitivity of Subset}}
	Let $\Delta_1$, $\Delta_2$, and $\Delta_3$ be sets.
	If $\Delta_1\subseteq\Delta_2$ and $\Delta_2\subseteq\Delta_3$ then $\Delta_1\subseteq\Delta_3$.
\end{THEOREM}
\begin{PROOF}
	Assume that $\Delta_1\subseteq\Delta_2$ and $\Delta_2\subseteq\Delta_3$.
	Since $\Delta_1\subseteq\Delta_2$, then by the definition of $\subseteq$, any $\alpha$ in $\Delta_1$ is also in $\Delta_2$.
	And since $\Delta_2\subseteq\Delta_3$, any $\alpha$ in $\Delta_2$ is also in $\Delta_3$.
	It then follows that if $\alpha\in\Delta_1$ then $\alpha\in\Delta_3$. 
	Thus, by the definition of $\subseteq$, $\Delta_1\subseteq\Delta_3$.
\end{PROOF}

\begin{commentary}
	Some students are not used to the structure and rigor of mathematical proofs.
	As an aid to understanding we sometimes include commentary to explain how a particular proof works.
	We use a grayed box to signify that this commentary is not itself part of the proof.

	\commentaryspace
	Here we are trying to prove a \emph{conditional} theorem, i.e., a statement of the form ``If $\Al$ then $\Bl$.''
	The typical way to demonstrate such theorems is to start by assuming the antecedent, $\Al$.
	Then we work from that assumption to show that the consequent, $\Bl$, must follow.
	Each step is justified by reference to a given definition or by mathematical reasoning, often in the language of set theory.
\end{commentary}

\noindent{}We have proved that \mention{$\subseteq$} is transitive. 
Having achieved this result, we permit ourselves to use it throughout the rest of the text without proving it again. 
The end of a completed proof is indicated with a black box: $\blacksquare$.

\subsection{Recursive Definitions}\label{Recursive Definitions}

In later chapters we use MathEnglish to define concepts such as \emph{sentence}, \emph{truth}, and \emph{entailment} for a given object language. 
Many of these definitions are recursive.
Recursive definitions are an invaluable tool for logic because they enable us to give a rigorous finite definition of an infinite set.
They can be understood as defining which elements are in a given set.

\begin{majorILnc}{\LnpDC{Definition of Recursive Definition}}
A \df{recursive definition} of $\Delta$ has three clauses:
\begin{cenumerate}
\item the \df{base clause(s)}, which specifies one or more objects as elements of $\Delta$,
\item the \df{generating clause(s)}, which specifies one or more ways of generating (or finding) other objects that are elements of $\Delta$, and
\item the \df{closure clause}, which specifies that something is in $\Delta$ only if it can be shown to be so by applications of the first two clauses.
\end{cenumerate}
\end{majorILnc}

\noindent{}Think of the base clause as the place to specify specific elements for inclusion in the set.
The generating clause is more powerful.
It defines elements of the set by reference to more basic elements already included.
The closure clause is usually a simple statement, but it is essential to specify what isn't in the set.

One concept that we can define recursively is \emph{natural number}.
\begin{majorILnc}{\LnpDC{Natural Number}} The set $\mathbb{N}$ of natural numbers:
	\begin{cenumerate}
		\item Base Clause: Let $0$ be a natural number. I.e. $0 \in \mathbb{N}$.
		\item Generating Clause: If $\integer{n} \in \mathbb{N}$ then $\integer{n}+1 \in \mathbb{N}$.
		\item Closure Clause: Nothing else is in $\mathbb{N}$.  
	\end{cenumerate}
\end{majorILnc}
This definition unambiguously identifies infinitely many numbers as natural numbers. 
Obviously $0$ is a natural number. 
Is $7$ a natural number? 
It is. We know $0$ is a natural number because the base clause says so. 
Thus, according to the generating clause, $0+1$ (i.e., $1$) is also a natural number. Apply the generating clause again to show that $1+1$ (i.e., $2$) is natural number. One can continue applying the generating clause until $7$ is reached. 
Is $-3$ a natural number? No. $-3$ is less than $0$ and the generating clause only defines larger numbers as natural. The closure clause rules out the inclusion of anything else.

Let's use a recursive definition to identify which people are ancestors of French mathematician Blaise Pascal.

\begin{cenumerate}
	\item Base Clause: Blaise Pascal's mother and father are ancestors of Blaise Pascal.
	\item Generating Clause: If $x$ is an ancestor of Blaise Pascal and $y$ is a parent of $x$, then $y$ is also an ancestor of Blaise Pascal.
	\item Closure Clause: No one else is an ancestor of Blaise Pascal.
\end{cenumerate}
\noindent{}This definition picks out the mother and father of Blaise Pascal, their respective mothers and fathers, the mothers and fathers of the latter, and so on.  It excludes everyone else. Recursive definitions are powerful, because in a few lines we can fix an unambiguous collection that is arbitrarily large. The closure clause is usually relatively trivial (e.g., ``Nothing else is an $x$.'').

\subsection{Conclusion}\label{Conclusion}

Now we have most of the mathematical tools we need to define our first formal language, \emph{Sentential Logic}. Anything else we need will be given along the way.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Exercises}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\notocsubsection{Sets}{ex:Sets}

\begin{enumerate}
	\item True or false: $\{2, 3\}\subseteq\{1, 2, 3\}$
    \item True or false: $\{1, 2, 3\}\subset\{1, 2, 3\}$
	\item True or false: $\{2, 3\}\in\{1, 2, 3\}$
    \item True or false: $\{2, 3\}\in\{1, \{2, 3\}\}$
    \item True or false: $2\in\{1, \{2, 3\}\}$
    \item True or false: $\{1, 2, 3\}=\{1, \{2, 3\}\}$
    \item True or false: $\{1, 2, 3\}=\{3, 3, 1, 2, 3, 2, 2, 1\}$
\end{enumerate}

\notocsubsection{Unions and Intersections}{ex:Unions and Intersections}

\begin{enumerate}
	\item True or false: $\{2,4,6\}\cup\{1,2,3\}\subseteq\{1,2,3,4,5,6\}$
	\item True or false: $\{2,4,6\}\cap\{1,2,3\}=\{1,2,3,4,5,6\}$
    \item True or false: $\{1,2\}\cap\{3,4\}\subseteq\{1,2\}\cup\{3,4\}$
	\item True or false: $\{1\}\cup\{2, 3\}=\{1, \{2, 3\}\}$
\end{enumerate}

\notocsubsection{Proofs}{ex:Simple Proofs}
Prove each of the following.
\begin{enumerate}
	\item $\Delta_1\cap\Delta_2\subseteq\Delta_1\cup\Delta_2$.
	\item If $\Delta_1\subseteq\Delta_2$ then $\Delta_1\cup\Delta_3\subseteq\Delta_2\cup\Delta_3$.
    \item If $\Delta_1\subseteq\Delta_2$ then $\Delta_1\cap\Delta_3\subseteq\Delta_2\cap\Delta_3$.
\end{enumerate}

\notocsubsection{Recursive Definitions}{ex:Recursive Definitions}
Define the following recursively.
\begin{enumerate}
	\item The ancestors of George Washington.
    \item All positive even numbers.
	\item All integers.
\end{enumerate}

%\theendnotes

