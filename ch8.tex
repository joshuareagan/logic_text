
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Soundness and Completeness}\label{completenesschapter}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this chapter we establish various connections between the derivation rules of the systems defined in the last two chapters with the semantic notions of truth, logical truth, and entailment. 
We carefully defined the rules of \GSD{} and \GQD{} so that they are \emph{truth-preserving}.

\begin{majorILnc}{\LnpDC{Derivation Rule Soundness}}
	A rule is \df{truth-preserving}\index{derivation!rule!truth-preserving}\index{truth-preserving} \Iff the sentence or sentences to which the rule is applied entail any sentence which the rule sanctions you to write as the next step. 
\end{majorILnc}

To prove this we start with the following theorem:
\begin{THEOREM}{\LnpTC{Soundess of Basic GSD Rules}}
	Every application of every basic rule of \GSD{} is truth-preserving.
\end{THEOREM}
\begin{PROOF}
	It can be shown that: for any basic rule \Rule{R} of \GSD{}, if some substitution of \GSL{} sentences into the given schema of \Rule{R} results in \GSL{} sentences $\CAPPSI_1,\ldots,\CAPPSI_{\integer{n}}$ and that same substitution into the may-add schema of \Rule{R} results in the \GSL{} sentence $\CAPPHI$, then $\CAPPSI_1,\ldots,\CAPPSI_{\integer{n}}\sdtstile{}{}\CAPPHI$.
	Call this the truth-preservation lemma.\footnote{
	    See exercise \pmvref{exercises:truth-preservation lemma}.
	}
	Now consider some arbitrary application of some basic rule \Rule{R} of \GSD{}. 
	Say that in this application \Rule{R} is applied to sentences $\CAPTHETA_1,\ldots,\CAPTHETA_{\integer{m}}$ and permits, or sanctions, you to write down $\DELTA$. 
	By definition \mvref{RuleSanctioning}, there's some substitution of \GSL{} sentences that, for the given schemas of \Rule{R}, results in $\CAPTHETA_1,\ldots,\CAPTHETA_{\integer{m}}$ and, for the may-add schema, results in $\DELTA$. 
	By the truth preservation lemma, $\CAPTHETA_1,\ldots,\CAPTHETA_{\integer{m}}\sdtstile{}{}\DELTA$.
	By definition \mvref{Derivation Rule Soundness}, this application is truth-preserving. 
\end{PROOF}
\begin{commentary}
	This proof doesn't cover \Rule{$\HORSESHOE$-Intro} or \Rule{Assume}.  These rules require special treatment.  The former is the only rule that eliminates an assumption, and the latter is the only rule that adds an assumption, so they each have a unique role.
\end{commentary}

Recall from section \mvref{Derivation Preliminaries} that we want to use derivations as a way of showing that a sentence is a logical truth, or of showing that some set of sentences entails some other sentence.
Specifically, we want to use derivations in \GSD{} and \GQD{} to show that sentences of \GSL{} and \GQL{} are \CAPS{tft} and \CAPS{qt}, or to show entailments between sentences of \GSL{} or between sentences of \GQL{}.  
But derivations can only fill this role if the derivation system in question is sound.
Let \Language{L} be some formal language for which we have defined some kind of models.
\begin{majorILnc}{\LnpDC{LSoundness}}
A derivation system \DerivationSystem{D} for \Language{L} is \nidf{sound}\index{soundness|textbf} \Iff for every set $\Delta$ of sentences of \Language{L} and every sentence $\CAPPHI$ of \Language{L}, if $\Delta\sststile{}{}\CAPPHI$, then $\Delta\sdtstile{}{}\CAPPHI$.
\end{majorILnc} 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Soundness}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Soundness of \GSD{}}
We prove the soundness of \GSD{} by way of a lemma.\index{soundness!of \GSD{}}
\begin{THEOREM}{\LnpTC{Soundness of Sentential Logic} \GSD{} Soundness Theorem:}
\GSD{} is sound; i.e., for every set $\Delta$ of sentences of \GSL{} and every sentence $\CAPPHI$ of \GSL{}, if $\Delta\sststile{}{}\CAPPHI$ in \GSD{}, then $\Delta\sdtstile{}{}\CAPPHI$.
\end{THEOREM}
\begin{THEOREM}{\LnpTC{Main GSL Soundness Lemma} Soundness Lemma:}
For any sequence of derivation lines that is a derivation, the sentence $\CAPPHI$ on the last line is entailed by the set $\Delta$ of sentences that are on unboxed lines and are sanctioned by \Rule{Assume}.
\end{THEOREM}
\noindent{}Since the definition of a derivation is a recursive definition\footnote{See definition \pmvref{Recursive definition of Derivation}.}, the most natural way to prove theorem \ref{Main GSL Soundness Lemma} is through a recursive proof. 
The recursive proof uses three easily proved lemmas (proofs are left to the reader; the first lemma, on monotonicity, is also used to prove thm. \ref{Soundness of Sentential Logic}). 
Two are facts about entailment and one is about derivation.
\begin{THEOREM}{\LnpTC{Monotonicity of Entailment} Monotonicity of Entailment:}
For all \GSL{} sentences $\CAPPHI_1,\ldots,\CAPPHI_{\integer{n}},\CAPTHETA,\CAPPSI$:
\begin{center}
If $\CAPPHI_1,\CAPPHI_2,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\CAPPSI$, then $\CAPPHI_1,\CAPPHI_2,\ldots,\CAPPHI_{\integer{n}},\CAPTHETA\sdtstile{}{}\CAPPSI$
\end{center}
\end{THEOREM}
\begin{THEOREM}{\LnpTC{Transitivity of Entailment} Transitivity of Entailment:}
For all \GSL{} sentences $\CAPPHI_1,\ldots,\CAPPHI_{\integer{n}}$, $\CAPTHETA$, and $\CAPPSI_1,\ldots,\CAPPSI_{\integer{k}}$:
\begin{center}
\begin{tabular}{ l@{\hspace{.25em}}l@{\hspace{.25em}}l }
If & $\CAPPHI_1,\CAPPHI_2,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\CAPPSI_1$ & and \\
   & $\CAPPHI_1,\CAPPHI_2,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\CAPPSI_2$ & and \\
   & \hspace{.5in} $\vdots$ &  \\
   & $\CAPPHI_1,\CAPPHI_2,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\CAPPSI_{\integer{k}}$ & and \\
   & $\CAPPSI_1,\CAPPSI_2,\ldots,\CAPPSI_{\integer{k}}\sdtstile{}{}\CAPTHETA$ & then: \\
   & & $\CAPPHI_1,\CAPPHI_2,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\CAPTHETA$   \\
\end{tabular}
\end{center}
\end{THEOREM}
\begin{THEOREM}{\LnpTC{Non-decreasing Assumption Principle} Non-decreasing Assumption Principle (NDAP):}
If $\Delta_1$ is the set of assumptions of an unboxed line and $\Delta_2$ is the set of assumptions of a later unboxed line, then $\Delta_1$ is a subset of $\Delta_2$, i.e., $\Delta_1\subseteq\Delta_2$.
\end{THEOREM}
\begin{PROOFOF}{Thm. \ref{Main GSL Soundness Lemma}, Soundness Lemma}
\begin{description}

\item[Base Step:] 
Consider a single-line derivation $\Derivation{D}$ of the sentence $\CAPPHI$ sanctioned by the rule \Rule{Assume}. 
Since the sentence on the last line is $\CAPPHI$, sanctioned by \Rule{Assume}, and $\CAPPHI\sdtstile{}{}\CAPPHI$, it follows that the set of all unboxed sentences sanctioned by \Rule{Assume} entails $\CAPPHI$. 

\item[Inheritance Step:]
Let $\Derivation{D}$ be an arbitrary derivation consisting of $k$ lines, where $k>1$.
Let $\Delta_\integer{i}$ be the set of unboxed assumptions occurring in a derivation $\Derivation{D}$ up to (and including) line number $\integer{i}$.
Consider the case in which a new line with sentence $\CAPPHI$ is added to derivation $\Derivation{D}$, sanctioned by rule \Rule{R}.

\begin{commentary}
	The resulting derivation has $k+1$ lines.
	We want to show, for each rule \Rule{R} of \GSD{}, that $\Delta_{k+1}\sdtstile{}{}\CAPPHI$.
	Each rule is considered separately in the following.
\end{commentary}

\begin{description}

\item[Recursive Assumption:]
Assume for each line $i$ of derivation $\Derivation{D}$, where $i\leq k$ and $\CAPPHI_{i}$ is the sentence on line $i$, that $\Delta_{\integer{i}}\sdtstile{}{}\CAPPHI_{i}$.

\item[\Rule{Assume}:] 
Let line $k+1$ of $\Derivation{D}$ be sanctioned by \Rule{Assume}.
Note that the set $\Delta_{k+1}$ of unboxed assumptions are those in $\Delta_{k}$ plus $\CAPPHI$. 
Clearly $\CAPPHI\sdtstile{}{}\CAPPHI$.
Then $\Delta,\CAPPHI\sdtstile{}{}\CAPPHI$ follows by monotonicity.

\item[\Rule{Repetition}:] 
Let line $k+1$ of $\Derivation{D}$ be sanctioned by \Rule{Repetition}.
Since $\CAPPHI$ is sanctioned at line $k+1$, then it must already occur on some line $i$, where $i<k+1$.
By the recursive assumption $\Delta_{\integer{i}}\sdtstile{}{}\CAPPHI$.
By NDAP, $\Delta_{\integer{i}}\subseteq\Delta_{k+1}$. 
So by monotonicity, $\Delta_{k+1}\sdtstile{}{}\CAPPHI$.

\item[\Rule{$\VEE$-Intro}:]
Let line $k+1$ of $\Derivation{D}$ be sanctioned by \Rule{$\VEE$-Intro}.
Then $\CAPPHI$ must be a disjunction with some disjunct, $\CAPTHETA$, that is already present on some line $i$, where $i<k+1$.
$\Delta_{\integer{i}}$ is the set of unboxed assumptions at that line, and by NDAP $\Delta_{\integer{i}}\subseteq\Delta_{k+1}$.
By the recursive assumption, $\Delta_{\integer{i}}\sdtstile{}{}\CAPTHETA$.
So by monotonicity, $\Delta_{k+1}\sdtstile{}{}\CAPTHETA$.
Since \Rule{$\VEE$-Intro} is truth preserving, $\CAPTHETA\sdtstile{}{}\CAPPHI$. 
So by transitivity of entailment, $\Delta_{k+1}\sdtstile{}{}\CAPPHI$. 

\item[\Rule{$\WEDGE\!$-Elim}:]
Let line $k+1$ of $\Derivation{D}$ be sanctioned by \Rule{$\WEDGE\!$-Elim}.
Then there's some earlier line $\integer{i}$ with the sentence $\conjunction{\CAPTHETA_\integer{1}}{\conjunction{\ldots}{\CAPTHETA_{\integer{m}}}}$ and $\CAPPHI$ is one of the conjuncts. 
As before, by NDAP $\Delta_{\integer{i}}\subseteq\Delta_{k+1}$.
By the recursive assumption, $\Delta_{\integer{i}}\sdtstile{}{}\conjunction{\CAPTHETA_\integer{1}}{\conjunction{\ldots}{\CAPTHETA_{\integer{m}}}}$. 
So by monotonicity, $\Delta_{k+1}\sdtstile{}{}\conjunction{\CAPTHETA_\integer{1}}{\conjunction{\ldots}{\CAPTHETA_{\integer{m}}}}$.
And $\CAPPHI$ is one of the conjuncts of $\conjunction{\CAPTHETA_\integer{1}}{\conjunction{\ldots}{\CAPTHETA_{\integer{m}}}}$, so it follows that $\conjunction{\CAPTHETA_\integer{1}}{\conjunction{\ldots}{\CAPTHETA_{\integer{m}}}}\sdtstile{}{}\CAPPHI$. 
So by transitivity, $\Delta_{k+1}\sdtstile{}{}\CAPPHI$.

\item[\Rule{$\NEGATION$-Elim}:] 
Let line $k+1$ of $\Derivation{D}$ be sanctioned by \Rule{$\NEGATION$-Elim}.
Then there's some earlier line $\integer{i}$ with the sentence $\horseshoe{\negation{\CAPPHI}}{\parconjunction{\CAPPSI}{\negation{\CAPPSI}}}$.
As before, by NDAP $\Delta_{\integer{i}}\subseteq\Delta_{k+1}$.
By the recursive assumption, $\Delta_{\integer{i}}\sdtstile{}{}\horseshoe{\negation{\CAPPHI}}{\parconjunction{\CAPPSI}{\negation{\CAPPSI}}}$.
So by monotonicity, $\Delta_{k+1}\sdtstile{}{}\horseshoe{\negation{\CAPPHI}}{\parconjunction{\CAPPSI}{\negation{\CAPPSI}}}$.
Since the \CAPS{rhs} of $\horseshoe{\negation{\CAPPHI}}{\parconjunction{\CAPPSI}{\negation{\CAPPSI}}}$ is false in all models (it's \CAPS{tff}), the conditional is true in a model $\IntA{}$ only if the \CAPS{lhs} is false in $\IntA{}$.
So if the conditional is true in a model $\IntA{}$, $\CAPPHI$ is true in $\IntA{}$.
In other words, $\horseshoe{\negation{\CAPPHI}}{\parconjunction{\CAPPSI}{\negation{\CAPPSI}}}\sdtstile{}{}\CAPPHI$. 
So by transitivity, $\Delta_{k+1}\sdtstile{}{}\CAPPHI$.

\item[\Rule{$\NEGATION$-Intro}:] 
This case is similar to the previous one and is left as an exercise for the reader. 

\item[\Rule{$\HORSESHOE$-Elim}:]
Let line $k+1$ of $\Derivation{D}$ be sanctioned by \Rule{$\HORSESHOE$-Elim}.
Then there are two earlier lines $\integer{i}$ and $\integer{j}$, and (say) line $\integer{i}$ has a sentence $\horseshoe{\CAPTHETA}{\CAPPHI}$ and line $\integer{j}$ has sentence $\CAPTHETA$. 
By NDAP we have that $\Delta_{\integer{i}}\subseteq\Delta_{k+1}$ and $\Delta_{\integer{j}}\subseteq\Delta_{k+1}$.
By the recursive assumption, $\Delta_{\integer{i}}\sdtstile{}{}\horseshoe{\CAPTHETA}{\CAPPHI}$ and $\Delta_{\integer{j}}\sdtstile{}{}\CAPTHETA$.
By monotonicity, 
$\Delta_{k+1}\sdtstile{}{}\horseshoe{\CAPTHETA}{\CAPPHI}$ and $\Delta_{k+1}\sdtstile{}{}\CAPTHETA$.
Since the rule is truth preserving, $\CAPTHETA,\horseshoe{\CAPTHETA}{\CAPPHI}\sdtstile{}{}\CAPPHI$.
So by transitivity, $\Delta_{k+1}\sdtstile{}{}\CAPPHI$.

\item[\Rule{$\TRIPLEBAR$-Elim}:] The argument for each of the two versions of \Rule{$\TRIPLEBAR$-Elim} is the same as that for \Rule{$\HORSESHOE$-Elim}.

\item[\Rule{$\TRIPLEBAR$-Intro}:]
Let line $k+1$ of $\Derivation{D}$ with sentence $\CAPPHI=\triplebar{\CAPPHI}{\CAPTHETA}$ be sanctioned by \Rule{$\TRIPLEBAR$-Intro}.
Then there are two earlier lines $\integer{i}$ and $\integer{j}$, and (say) line $\integer{i}$ has a sentence $\horseshoe{\CAPTHETA}{\CAPPHI}$ and line $\integer{j}$ has sentence $\horseshoe{\CAPPHI}{\CAPTHETA}$. 
By NDAP we have that $\Delta_{\integer{i}}\subseteq\Delta_{k+1}$ and $\Delta_{\integer{j}}\subseteq\Delta_{k+1}$.
By the recursive assumption, $\Delta_{\integer{i}}\sdtstile{}{}\horseshoe{\CAPTHETA}{\CAPPHI}$ and $\Delta_{\integer{j}}\sdtstile{}{}\horseshoe{\CAPPHI}{\CAPTHETA}$.
By monotonicity, $\Delta_{k+1}\sdtstile{}{}\horseshoe{\CAPTHETA}{\CAPPHI}$ and $\Delta_{k+1}\sdtstile{}{}\horseshoe{\CAPPHI}{\CAPTHETA}$.
Since the rule is truth preserving, $\horseshoe{\CAPPHI}{\CAPTHETA},\horseshoe{\CAPTHETA}{\CAPPHI}\sdtstile{}{}\triplebar{\CAPPHI}{\CAPTHETA}$.
So by transitivity, $\Delta_{k+1}\sdtstile{}{}\CAPPHI$.

\item[\Rule{$\WEDGE\!$-Intro}:]
Let line $k+1$ of $\Derivation{D}$ with sentence $\CAPPHI=\conjunction{\CAPPHI_1}{\conjunction{\ldots}{\CAPPHI_{\integer{m}}}}$ be sanctioned by \Rule{$\WEDGE\!$-Intro}.
Then there are $\integer{m}$ earlier lines numbered $\integer{i}_{1},\ldots,\integer{i}_{\integer{m}}$ with, respectively, sentences $\CAPPHI_1,\ldots,\CAPPHI_{\integer{m}}$. 
By NDAP we have that $\Delta_{\integer{i}_1}\subseteq\Delta_{k+1},\ldots,\Delta_{\integer{i}_\integer{m}}\subseteq\Delta_{k+1}$.
By the recursive assumption, $\Delta_{\integer{i}_1}\sdtstile{}{}\CAPPHI_1,\ldots,\Delta_{\integer{i}_\integer{m}}\sdtstile{}{}\CAPPHI_{\integer{m}}$.
So by monotonicity, $\Delta_{k+1}\sdtstile{}{}\CAPPHI_1,\ldots,\Delta_{k+1}\sdtstile{}{}\CAPPHI_{\integer{m}}$.
Observe that $\CAPPHI_1,\ldots,\CAPPHI_{\integer{m}}\sdtstile{}{}\conjunction{\CAPPHI}{\conjunction{\ldots}{\CAPPHI_{\integer{m}}}}$.
So by transitivity, $\Delta_{k+1}\sdtstile{}{}\CAPPHI$.

\item[\Rule{$\VEE$-Elim}:]
Let line $k+1$ of $\Derivation{D}$ be sanctioned by \Rule{$\VEE$-Elim}.
Then there are $\integer{m}+1$ earlier lines numbered $\integer{i}_{1},\ldots,\integer{i}_{\integer{m}},\integer{i}_{\integer{m}+1}$ with, respectively, sentences $\horseshoe{\CAPTHETA_1}{\CAPPHI}$, $\ldots$, $\horseshoe{\CAPTHETA_{\integer{m}}}{\CAPPHI}$, and  $\disjunction{\CAPTHETA_1}{\disjunction{\ldots}{\CAPTHETA_{\integer{m}}}}$.
By NDAP we have that $\Delta_{\integer{i}_1}\subseteq\Delta_{k+1},\ldots,\Delta_{\integer{i}_\integer{m}}\subseteq\Delta_{k+1}$ and $\Delta_{\integer{i}_{\integer{m}+1}}\subseteq\Delta_{k+1}$.
By the recursive assumption, $\Delta_{\integer{i}_1}\sdtstile{}{}\horseshoe{\CAPTHETA_1}{\CAPPHI}$, $\ldots$, $\Delta_{\integer{i}_\integer{m}}\sdtstile{}{}\horseshoe{\CAPTHETA_{\integer{m}}}{\CAPPHI}$ and $\Delta_{\integer{i}_{\integer{m}+1}}\sdtstile{}{}\disjunction{\CAPTHETA_1}{\disjunction{\ldots}{\CAPTHETA_{\integer{m}}}}$.
By monotonicity, $\Delta_{k+1}\sdtstile{}{}\horseshoe{\CAPTHETA_1}{\CAPPHI}$, $\ldots$, $\Delta_{k+1}\sdtstile{}{}\horseshoe{\CAPTHETA_{\integer{m}}}{\CAPPHI}$ and $\Delta_{k+1}\sdtstile{}{}\disjunction{\CAPTHETA_1}{\disjunction{\ldots}{\CAPTHETA_{\integer{m}}}}$.
Observe that $\horseshoe{\CAPTHETA_1}{\CAPPHI},\ldots,\horseshoe{\CAPTHETA_{\integer{m}}}{\CAPPHI},\disjunction{\CAPTHETA_1}{\disjunction{\ldots}{\CAPTHETA_{\integer{m}}}}\sdtstile{}{}\CAPPHI$.
So by transitivity, $\Delta_{k+1}\sdtstile{}{}\CAPPHI$.

\item[\Rule{$\HORSESHOE$-Intro}:]
The rule \Rule{$\HORSESHOE$-Intro} changes the number of unboxed assumptions.
If line $k+1$ sanctioned by \Rule{$\HORSESHOE$-Intro} has sentence $\horseshoe{\CAPPHI}{\CAPTHETA}$ and unboxed assumptions $\Delta_{k+1}$, then there must be an assumption line (now in a box) that starts with $\CAPPHI$ and $\Delta_{k+1}$ as its other assumptions, and we have a line (now at the bottom of the box) with $\CAPTHETA$ on it with assumptions $\CAPPHI,\Delta_{k+1}$. 
By the recursive assumption we have that $\CAPPHI,\Delta_{k+1}\sdtstile{}{}\CAPTHETA$. 
Consider any model $\IntA{}$ that makes $\Delta_{k+1}$ true;
if it also makes $\CAPPHI$ true, then $\CAPTHETA$ is true in $\IntA{}$ as well and so is $\horseshoe{\CAPPHI}{\CAPTHETA}$. 
If $\IntA{}$ makes $\CAPPHI$ false, then $\horseshoe{\CAPPHI}{\CAPTHETA}$ is true. 
(Notice that this step only works because we defined the conditional to be true when the \CAPS{lhs} is false.)
So if $\IntA{}$ makes $\Delta_{k+1}$ true, it makes $\horseshoe{\CAPPHI}{\CAPTHETA}$ true too. 
So, $\Delta_{k+1}\sdtstile{}{}\horseshoe{\CAPPHI}{\CAPTHETA}$.  

\end{description}
\item[Closure Step:] We have now covered all the generating cases for derivations. By the closure clause of the definition, we have proved soundness for all derivations. 
\end{description}
\end{PROOFOF} 

\begin{PROOFOF}{Thm. \ref{Soundness of Sentential Logic}, SL Soundness Theorem}
Assume that $\Delta$ is a set of \GSL{} sentences. 
Assume $\Delta\sststile{}{}\CAPPHI$ and consider some derivation $\Derivation{D}$ of $\CAPPHI$ from $\Delta$. 
Let $\Delta'$ be the set of sentences in $\Delta$ that appear as unboxed assumptions in $\Derivation{D}$. 
By the soundness lemma (Thm. \ref{Main GSL Soundness Lemma}), $\Delta'\sdtstile{}{}\CAPPHI$. 
It follows immediately by monotonicity that $\Delta\sdtstile{}{}\CAPPHI$.  
\end{PROOFOF} 

\subsection{Soundness of \GQD{}}
In this section we prove that \GQD{} is also sound.\index{soundness!of \GQD{}}
\begin{THEOREM}{\LnpTC{Soundness of Quantifier Logic} \GQD{} Soundness Theorem:}
\GQD{} is sound; i.e., for every set $\Delta$ of sentences of \GQL{} and every sentence $\CAPPHI$ of \GQL{}, if $\Delta\sststile{}{}\CAPPHI$ in \GSD{}, then $\Delta\sdtstile{}{}\CAPPHI$.
\end{THEOREM}
\noindent{}The proof given in the last section of the \GSL{} Soundness Theorem \ref{Soundness of Sentential Logic} can be carried over to the \GQL{} Soundness Theorem. 
That proof relied on the monotonicity of entailment and the soundness lemma (Thm. \ref{Main GSL Soundness Lemma}). 
It should be clear that entailment is also monotonic in the case of \GQL{}. 
Since \GQD{} is an extension of \GSD{} (it's just \GSD{} plus the rules for the quantifiers in table \pncmvref{GQD}), all we need to do to show that the soundness lemma holds for \GQD{} is add a case, for each new rule of \GQD{}, to the inheritance step of the proof of the soundness lemma for \GSD{}.
\begin{PROOFOF}{Thm. \ref{Main GSL Soundness Lemma} for GQD}
\begin{description}

\item[Base Step:] 
The base case is covered in Thm. \ref{Main GSL Soundness Lemma}.

\item[Inheritance Step:]
Let $\Derivation{D}$ be an arbitrary derivation consisting of $k$ lines, where $k>1$.
Let $\Delta_\integer{i}$ be the set of unboxed assumptions occurring in a derivation $\Derivation{D}$ up to (and including) line number $\integer{i}$.
Consider the case in which a new line with sentence $\CAPPHI$ is added to derivation $\Derivation{D}$, sanctioned by rule \Rule{R}.

\begin{commentary}
	The resulting derivation has $k+1$ lines.
	We want to show, for each rule \Rule{R} of \GQD{}, that $\Delta_{k+1}\sdtstile{}{}\CAPPHI$.
	It was shown already that the property holds of each \GSD{} rule, so we only need to consider the quantifier introduction and elimination rules.
\end{commentary}

\begin{description}

\item[Recursive Assumption:]  
Assume for each line $i$ of derivation $\Derivation{D}$, where $i\leq k$ and $\CAPPHI_{i}$ is the sentence on line $i$, that $\Delta_{\integer{i}}\sdtstile{}{}\CAPPHI_{i}$.

\item[\Rule{$\forall$-Elim}:]
Let line $k+1$ of $\Derivation{D}$ with sentence $\CAPPHI\variable{s}/\BETA$ be sanctioned by \Rule{$\forall$-Elim}.
Then there's some earlier line $\integer{i}$ with the sentence $\universal{\BETA}\CAPPHI$. 
$\Delta_{\integer{i}}$ is the set of unboxed assumptions of line $\integer{i}$, and by NDAP $\Delta_{\integer{i}}\subseteq\Delta_{k+1}$.
By the recursive assumption, $\Delta_{\integer{i}}\sdtstile{}{}\universal{\BETA}\CAPPHI$.
So by monotonicity, $\Delta_{k+1}\sdtstile{}{}\universal{\BETA}\CAPPHI$.

Assume some model $\IntA$ such that $\universal{\BETA}\CAPPHI$ is true.
By the def. of truth of $\forall$, $\CAPPHI{\variable{t}/\BETA}$ is true on all $\variable{t}$-variants of $\IntA$.
Notice that $\CAPPHI{\variable{t}/\BETA}$ and $\CAPPHI{\variable{s}/\BETA}$ are exactly the same, except that the latter has $\variable{s}$ substituted for $\variable{t}$.
These sentences satisfy condition (1) of Dragnet.

Consider the $\variable{t}$-variant that assigns to $\variable{t}$ what $\IntA$ assigns to $\variable{s}$.
Name that $\variable{t}$-variant $\As{\variable{t}}{}$.
The models $\IntA$ and $\As{\variable{t}}{}$ meet Dragnet condition (2).
Thus, by Dragnet, $\CAPPHI{\variable{t}/\BETA}$ is true on $\As{\variable{t}}{}$ iff $\CAPPHI{\variable{s}/\BETA}$ is true on $\IntA$.
Therefore, $\CAPPHI{\variable{s}/\BETA}$ is true on $\IntA$.

Any model such that $\universal{\BETA}\CAPPHI$ is true also makes $\CAPPHI{\variable{s}/\BETA}$ true.
Thus, $\universal{\BETA}\CAPPHI\sdtstile{}{}\CAPPHI\variable{s}/\BETA$.
So by transitivity, $\Delta_{k+1}\sdtstile{}{}\CAPPHI\variable{s}/\BETA$.   

\item[\Rule{$\exists$-Intro}:]
Let line $k+1$ of $\Derivation{D}$ with sentence $\existential{\BETA}\CAPPHI$ be sanctioned by \Rule{$\exists$-Intro}.
Then there's some earlier line $\integer{i}$ with the sentence $\CAPPHI\variable{s}/\BETA$.
$\Delta_{\integer{i}}$ is the set of unboxed assumptions of line $\integer{i}$, and by NDAP $\Delta_{\integer{i}}\subseteq\Delta_{k+1}$.
By the recursive assumption, $\Delta_{\integer{i}}\sdtstile{}{}\CAPPHI\variable{s}/\BETA$.
By monotonicity, $\Delta_{k+1}\sdtstile{}{}\CAPPHI\variable{s}/\BETA$.

Assume some model $\IntA$ such that $\existential{\BETA}\CAPPHI$ is false.
By the def. of truth of $\exists$, there is no $\variable{t}$-variant of $\IntA$ that makes $\CAPPHI{\variable{t}/\BETA}$ true.
Notice that $\CAPPHI{\variable{t}/\BETA}$ and $\CAPPHI{\variable{s}/\BETA}$ are exactly the same, except that the latter has $\variable{s}$ substituted for $\variable{t}$.
These sentences satisfy condition (1) of Dragnet.

Consider the $\variable{t}$-variant that assigns to $\variable{t}$ what $\IntA$ assigns to $\variable{s}$.
Name that $\variable{t}$-variant $\As{\variable{t}}{}$.
The models $\IntA$ and $\As{\variable{t}}{}$ meet Dragnet condition (2).
Thus, by Dragnet, $\CAPPHI{\variable{t}/\BETA}$ is true on $\As{\variable{t}}{}$ iff $\CAPPHI{\variable{s}/\BETA}$ is true on $\IntA$.
Therefore, $\CAPPHI{\variable{s}/\BETA}$ is false on $\IntA$.

Any model that makes $\existential{\BETA}\CAPPHI$ false also makes $\CAPPHI{\variable{s}/\BETA}$ false.
Thus, $\CAPPHI\variable{s}/\BETA\sdtstile{}{}\existential{\BETA}\CAPPHI$.
So by transitivity, $\Delta_{k+1}\sdtstile{}{}\existential{\BETA}\CAPPHI$.

\item[\Rule{$\forall$-Intro}:]
Let line $k+1$ of $\Derivation{D}$ with sentence $\universal{\BETA}\CAPPHI$ be sanctioned by \Rule{$\forall$-Intro}.
Then there's some earlier line $\integer{i}$ with the sentence $\CAPPHI\variable{s}/\BETA$. 
$\Delta_{\integer{i}}$ is the set of unboxed assumptions of line $\integer{i}$, and by NDAP $\Delta_{\integer{i}}\subseteq\Delta_{k+1}$.
By the recursive assumption, $\Delta_{\integer{i}}\sdtstile{}{}\CAPPHI\variable{s}/\BETA$. 
By monotonicity, $\Delta_{k+1}\sdtstile{}{}\CAPPHI\variable{s}/\BETA$.
However $\CAPPHI\variable{s}/\BETA$ does not entail $\universal{\BETA}\CAPPHI$, so we have to do some extra work and make use of the restrictions on the rule \Rule{$\forall$-Intro}. 

Let $\IntA$ be some model that makes all of $\Delta_{k+1}$ true; and let's assume for \emph{reductio} that $\IntA$ that makes $\universal{\BETA}\CAPPHI$ false.
One of the restrictions for \Rule{$\forall$-Intro} is that $\variable{s}$ must not occur in $\universal{\BETA}\CAPPHI$.
Hence, by the Free Choice Theorem, $\CAPPHI\variable{s}/\BETA$ is false on some $\variable{s}$-variant of $\IntA$.
Let's name that $\variable{s}$-variant $\As{\variable{s}}{}$.

The other rule restriction for \Rule{$\forall$-Intro} is that $\variable{s}$ must not occur in $\Delta_{k+1}$.
The variant $\As{\variable{s}}{}$ differs from $\IntA$ only on the assignment to $\variable{s}$; otherwise, they make all the same assignments.
Since $\variable{s}$ doesn't occur in $\Delta_{k+1}$ and $\IntA$ makes all of $\Delta_{k+1}$ true, $\As{\variable{s}}{}$ also makes all of $\Delta_{k+1}$ true.
The assignment $\As{\variable{s}}{}$ makes to $\variable{s}$ doesn't matter for this result.

Since $\Delta_{k+1}\sdtstile{}{}\CAPPHI\variable{s}/\BETA$, $\As{\variable{s}}{}$ makes $\CAPPHI\variable{s}/\BETA$ true.
But we already showed that $\CAPPHI\variable{s}/\BETA$ is false on $\As{\variable{s}}{}$.
From the assumption that $\IntA$ makes $\universal{\BETA}\CAPPHI$ is false we have proven a contradiction.
So $\IntA$ makes $\universal{\BETA}\CAPPHI$ true.

Therefore, if $\IntA$ is a model that makes all of $\Delta_{k+1}$ true, then $\IntA$ makes $\universal{\BETA}\CAPPHI$ true as well. 
So, $\Delta_{k+1}\sdtstile{}{}\universal{\BETA}\CAPPHI$.

\item[\Rule{$\exists$-Elim}:]
Let line $k+1$ of $\Derivation{D}$ with sentence $\CAPTHETA$ be sanctioned by \Rule{$\exists$-Elim}.
Then there's some earlier line $\integer{i}$ with the sentence $\horseshoe{\CAPPHI\variable{s}/\BETA}{\CAPTHETA}$ and an earlier line $\integer{j}$ with the sentence $\existential{\BETA}\CAPPHI$. 
$\Delta_{\integer{i}}$ is the set of unboxed assumptions of line $\integer{i}$ and $\Delta_{\integer{j}}$ the unboxed assumptions of line $\integer{j}$.
By NDAP $\Delta_{\integer{i}}\subseteq\Delta_{k+1}$ and $\Delta_{\integer{j}}\subseteq\Delta_{k+1}$.
By the recursive assumption, $\Delta_{\integer{i}}\sdtstile{}{}\horseshoe{\CAPPHI\variable{s}/\BETA}{\CAPTHETA}$ and $\Delta_{\integer{j}}\sdtstile{}{}\existential{\BETA}\CAPPHI$.
By monotonicity, $\Delta_{k+1}\sdtstile{}{}\horseshoe{\CAPPHI\variable{s}/\BETA}{\CAPTHETA}$ and $\Delta_{k+1}\sdtstile{}{}\existential{\BETA}\CAPPHI$.
We have make use of the restrictions on the rule \Rule{$\exists$-Elim} to show that $\Delta_{k+1}\sdtstile{}{}\CAPTHETA$. 

Let $\IntA$ be some model that makes all of $\Delta_{k+1}$ true. 
Since $\Delta_{k+1}\sdtstile{}{}\existential{\BETA}\CAPPHI$, $\IntA$ also makes $\existential{\BETA}\CAPPHI$ true.
One of the rule restrictions for \Rule{$\exists$-Elim} is that $\variable{s}$ must not occur in $\existential{\BETA}\CAPPHI$.
Hence, by the Free Choice theorem, $\CAPPHI{\variable{s}/\BETA}$ is true on some $\variable{s}$-variant of $\IntA$.
Name that $\variable{s}$-variant $\As{\variable{s}}{}$.  

Another of the rule restrictions for \Rule{$\exists$-Elim} is that $\variable{s}$ must not occur in $\Delta_{k+1}$.
The variant $\As{\variable{s}}{}$ makes all the same assignments as $\IntA$ except in what it assigns to $\variable{s}$.
Since $\IntA$ makes $\Delta_{k+1}$ true and $\Delta_{k+1}$ doesn't contain $\variable{s}$, $\As{\variable{s}}{}$ also makes $\Delta_{k+1}$ true.
The assignment $\As{\variable{s}}{}$ makes to $\variable{s}$ doesn't make any difference.

Thus, because $\Delta_{k+1}\sdtstile{}{}\horseshoe{\CAPPHI\variable{s}/\BETA}{\CAPTHETA}$, $\As{\variable{s}}{}$ makes $\horseshoe{\CAPPHI\variable{s}/\BETA}{\CAPTHETA}$ true.
We saw earlier that $\As{\variable{s}}{}$ makes $\CAPPHI\variable{s}/\BETA$ true, so $\As{\variable{s}}{}$ makes $\CAPTHETA$ true as well (def. of truth, $\HORSESHOE$).  

According to the third rule restriction for \Rule{$\exists$-Elim}, $\variable{s}$ must not occur in $\CAPTHETA$.
Because $\As{\variable{s}}{}$ makes $\CAPTHETA$ true and $\variable{s}$ isn't in $\CAPTHETA$, $\IntA$ also makes $\CAPTHETA$ true.
The assignment that $\As{\variable{s}}{}$ makes to $\variable{s}$ is irrelevant.

So, we have shown that $\Delta_{k+1}\sdtstile{}{}\CAPTHETA$.

\end{description}

\item[Closure Step:] We have covered all the generating cases for derivations. By the closure clause of the definition, we have proved soundness for all derivations in \GQD{}. 

\end{description}
\end{PROOFOF} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Completeness}\label{Section:Completeness for GSD}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Next we prove the completeness of \GSD{}.

\begin{majorILnc}{\LnpDC{LRCompleteness}}
	A derivation system \DerivationSystem{D} for \Language{L} is \nidf{complete}\index{completeness|textbf} \Iff for every finite set $\Delta$ of sentences of \Language{L} and every sentence $\CAPPHI$ of \Language{L}, if $\Delta\sdtstile{}{}\CAPPHI$, then $\Delta\sststile{}{}\CAPPHI$.
\end{majorILnc} 
\noindent{}When $\Delta$ is limited to the empty set, the result is weak completeness:
\begin{majorILnc}{\LnpDC{LWCompleteness}}
	A derivation system \DerivationSystem{D} for \Language{L} is \nidf{weakly complete}\index{completeness!weak|textbf} \Iff for every sentence $\CAPPHI$ of \Language{L}, if $\sdtstile{}{}\CAPPHI$, then $\sststile{}{}\CAPPHI$.
\end{majorILnc} 
\noindent{}The following theorem can be proved using basic results already shown.
In other systems of logic, what we call completeness and weak completeness are not equivalent.
They \emph{are} equivalent in our systems, so we do not always distinguish them.
There is also a notion of `strong' completeness, which we define shortly.
\GSD{} and \GQD{} are strongly complete, but this result is not trivially equivalent to completeness.
There are other systems that are complete but not strongly complete.
\begin{THEOREM}{\LnpTC{RegWeakCompletenessEquiv}}
	\GSD{} is weakly complete \Iff it's complete; and likewise for \GQD{}.
\end{THEOREM}
\begin{PROOF}
	$(\Leftarrow)$ Assume that \GSD{}/\GQD{} is complete. 
	Then for any finite set $\Delta$, if $\Delta\sdtstile{}{}\CAPPHI$, then $\Delta\sststile{}{}\CAPPHI$. 
	This includes the case when $\Delta$ is the empty set. 
	So if $\sdtstile{}{}\CAPPHI$, then $\sststile{}{}\CAPPHI$.
	Hence \GSD{}/\GQD{} is weakly complete. 
	
	$(\Rightarrow)$ Assume that \GSD{}/\GQD{} is weakly complete: for any sentence $\CAPPHI$, if $\sdtstile{}{}\CAPPHI$, then $\sststile{}{}\CAPPHI$. 
	Assume that, for some finite set $\Delta$ of sentences and sentence $\CAPPHI$, $\Delta\sdtstile{}{}\CAPPHI$.
	Since $\Delta$ is finite, there is a sentence $\DELTA$ that is a conjunction of all the sentences in $\Delta$.
	We want to show that $\sdtstile{}{}\horseshoe{\DELTA}{\CAPPHI}$.
	So, assume for \emph{indirect proof} there's some model $\IntA$ that makes $\horseshoe{\DELTA}{\CAPPHI}$ false.
	By the definition of truth for $\HORSESHOE$ and $\WEDGE$, it follows that $\IntA$ makes all the conjuncts of $\DELTA$ true and $\CAPPHI$ false. 
	Then $\IntA$ makes all the sentences in $\Delta$ true and $\CAPPHI$ false.
	But we assumed that $\Delta\sdtstile{}{}\CAPPHI$.
	It follows that there's no model $\IntA$ that makes $\horseshoe{\DELTA}{\CAPPHI}$ false.
	Hence $\sdtstile{}{}\horseshoe{\DELTA}{\CAPPHI}$, and so by weak completeness, $\sststile{}{}\horseshoe{\DELTA}{\CAPPHI}$.
	It should be clear to the reader that if $\sststile{}{}\horseshoe{\DELTA}{\CAPPHI}$, then $\DELTA\sststile{}{}\CAPPHI$.
	Hence, $\DELTA\sststile{}{}\CAPPHI$.
	Finally, since $\Delta\sststile{}{}\DELTA$ and $\sststile{}{}$ is transitive, $\Delta\sststile{}{}\CAPPHI$.
\end{PROOF}
\begin{majorILnc}{\LnpDC{LCompleteness}}
	A derivation system \DerivationSystem{D} for \Language{L} is \nidf{strongly complete}\index{completeness!strong|textbf} \Iff for every set $\Delta$ of sentences of \Language{L} and every sentence $\CAPPHI$ of \Language{L}, if $\Delta\sdtstile{}{}\CAPPHI$, then $\Delta\sststile{}{}\CAPPHI$.
\end{majorILnc} 
\noindent{}Strong completeness differs from (regular) completeness in that $\Delta$ is allowed to be infinite.
If we limit $\Delta$ so that it must be finite (but still allow it to be empty), we get completeness.
\noindent{}Note that both \GSD{} and \GQD{} are strongly complete, but there is no simple theorem that uses results we already have which extends weak completeness to strong completeness in the way this theorem (Thm. \ref{RegWeakCompletenessEquiv}) extends weak completeness to (regular) completeness.

Letting $\Delta$ be infinite may seem excessive, since we have defined derivations (def. \pmvref{Recursive definition of Derivation}) to have only finitely many lines. 
A derivation can only have finitely many assumptions.
And, as we've defined the single turnstile, $\Delta\sststile{}{}\CAPPHI$ iff there's a derivation of $\CAPPHI$ from the sentences in $\Delta$. 

As it turns out, however, there's nothing wrong with letting $\Delta$ be infinite.
Showing that there's a derivation of $\CAPPHI$ from the sentences in $\Delta$ doesn't require that the derivation use \emph{all} the sentences in $\Delta$ as assumptions.
In general, even when $\Delta$ is finite, any derivation of $\CAPPHI$ from some subset of sentences in $\Delta$ shows that $\Delta\sststile{}{}\CAPPHI$. 
So, if $\Delta$ is infinite and $\Delta\sdtstile{}{}\CAPPHI$, if the derivation system \DerivationSystem{D} is complete it follows that $\CAPPHI$ can be derived from some finite subset of sentences of $\Delta$.\footnote{Before turning to the proofs of these theorems, some historical background might be of interest. 
	As mentioned above (Sec. \ref{Sec:GQLSymbols}), quantificational languages were first developed by Frege, Peirce and Mitchell in the 1870's and 1880's. 
	But it wasn't until David Hilbert and Wilhelm Ackermann published their hugely influential text \emph{Grundz\"uge der theoretischen Logik} (Principles of Mathematical Logic) in \citeyear{Hilbert1928} that the question of completeness was clearly formulated. 
	While Kurt G\"odel, in his \citeyear{Godel1929} doctorial dissertation (republished in \citeyear{Godel1930}), is widely accepted as the first person to prove that quantificational logic is strongly complete, Church \citeyearpar[291,~fn.464]{Church1956} reports that the Jacques Herbrand's dissertation in 1930 had the essential material for the same proof.  
	Further, completeness follows from results of Skolem \citeyearpar{Skolem1928}, but since the question of completeness hadn't been clearly raised yet no one seems to have noticed. 
	Leon Henkin \citeyearpar{Henkin1949} later developed a method of proving completeness different from G\"odels. 
	Henkin's approach is probably the most common one used today in logic textbooks, but the proof we give here is a constructive proof closer to G\"odel's original.
	(Ours owes much to Willard Quine's completeness proof \citeyearpar{Quine1982}.)}

By theorem \mvref{RegWeakCompletenessEquiv}, if we show that \GSD{} is weakly complete, it follows that \GSD{} is complete.
To demonstrate the weak completeness of \GSD{} we prove this intermediate result:
\begin{THEOREM}{\LnpTC{GSDCompletenessLemma} The \GSD{} Weak Completeness Lemma:}
For\index{completeness!weak \GSD{}} any sentence $\CAPPHI$ of \GSD{}, either $\CAPPHI\sststile{}{}\conjunction{\Al}{\negation{\Al}}$, or $\CAPPHI$ is true in some model $\IntA$.
\end{THEOREM}

As an aid to prove this result, we introduce a new exchange rule for \GQD{} and then show that anything derivable with \GQD{} and this rule can be derived using \GQD{} alone.
We call the rule \Rule{$\TRIPLEBAR$-Exchange}.
(Note that every application of \Rule{$\TRIPLEBAR$-Exchange} is truth preserving, as the last problem in exercise \pmvref{exercises:GSDTFETheorem}, extends theorem \pmvref{ExchangeRuleGSDSoundnessLemma}, to it.)
It's given in table \ref{GSDplusDNF}.
\begin{table}[!ht]
\renewcommand{\arraystretch}{1.5}
\begin{center}
\begin{tabular}{ p{1in} l l } %p{2.2in} p{2in}
\toprule
\textbf{Name} & \textbf{Given} & \textbf{May Add} \\ 
\midrule
\Rule{$\TRIPLEBAR$-Exchange} &  $\triplebar{\CAPTHETA}{\CAPPSI}$ & $\disjunction{\parconjunction{\CAPTHETA}{\CAPPSI}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}$ \\
\nopagebreak
 & $\disjunction{\parconjunction{\CAPTHETA}{\CAPPSI}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}$ &  $\triplebar{\CAPTHETA}{\CAPPSI}$ \\
\bottomrule
\end{tabular}
\end{center}
\caption{\Rule{$\TRIPLEBAR$-Exchange}}
\label{GSDplusDNF}%
\end{table}
\index{derivation!rule!for DNF}\index{DNF}
\noindent{}All we need to show that anything that can be derived using \GQD{} and \Rule{$\TRIPLEBAR$-Exchange} can be derived using just \GQD{}, is to prove the following:\footnote{
	See section \ref{Shortcut Rule Elimination Theorem Section}.
}
\begin{THEOREM}{\LnpTC{GQD NDF Rule}}
Any two \GQL{} formulas got by substituting other \GQL{} formulas into the may-add and given schemas of \Rule{$\TRIPLEBAR$-Exchange} are provably equivalent; that is, $\sststile{}{}\forall\bpartriplebar{\partriplebar{\CAPTHETA}{\CAPPSI}}{\pardisjunction{\parconjunction{\CAPTHETA}{\CAPPSI}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}}$.
\end{THEOREM}
\begin{PROOF}
We show that $\sststile{}{}\forall\bpartriplebar{\partriplebar{\CAPTHETA}{\CAPPSI}}{\pardisjunction{\parconjunction{\CAPTHETA}{\CAPPSI}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}}$ by giving a derivation schema, which for any two formulas $\CAPTHETA$ and $\CAPPSI$ results in the needed derivation. 
(Note that to save space $\integer{q}=\integer{n}+\integer{m}$.)
\begin{gproofnn}
\gaproof{
\galine{1}{$\partriplebar{\CAPTHETA}{\CAPPSI}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{Assume}}
\galine{2}{$\partriplebar{\negation{\CAPTHETA}}{\negation{\CAPPSI}}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{$\NEGATION$/$\TRIPLEBAR$-Intro}, 1}
\gaaproof{
\gaaline{3}{$\negation{\parconjunction{\CAPTHETA}{\CAPPSI}}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{Assume}}
\gaaline{4}{$\pardisjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{DeM}, 3}
\gaaaproof{
\gaaaline{5}{$\negation{\CAPTHETA}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{Assume}}
\gaaaline{6}{$\negation{\CAPPSI}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{$\TRIPLEBAR$-Elim}, 2, 5}
\gaaaline{7}{$\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{$\WEDGE\!$-Intro}, 5, 6}
}
\gaaline{8}{$\parhorseshoe{\negation{\CAPTHETA}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{$\HORSESHOE$-Intro}, 5--7}

\gaaaproof{
\gaaaline{9}{$\negation{\CAPPSI}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{Assume}}
\gaaaline{10}{$\negation{\CAPTHETA}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{$\TRIPLEBAR$-Elim}, 2, 9}
\gaaaline{11}{$\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{$\WEDGE\!$-Intro}, 9, 10}
}
\gaaline{12}{$\parhorseshoe{\negation{\CAPPSI}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{$\HORSESHOE$-Intro}, 9--11}
\gaaline{13}{$\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{$\VEE$-Intro}, 4, 8, 12}
}
\galine{14}{$\parhorseshoe{\negation{\parconjunction{\CAPTHETA}{\CAPPSI}}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{$\HORSESHOE$-Intro}, 3--13}
\galine{15}{$\pardisjunction{\negation{\negation{\parconjunction{\CAPTHETA}{\CAPPSI}}}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{$\HORSESHOE$/$\VEE$-Exch.}, 14}
\galine{16}{$\pardisjunction{\parconjunction{\CAPTHETA}{\CAPPSI}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{$\NEGATION\NEGATION$-Elim}, 15}
}
\gline{17}{$[\partriplebar{\CAPTHETA}{\CAPPSI}\HORSESHOE$}{ }
\nopagebreak
\glinend{ }{$\qquad\pardisjunction{\parconjunction{\CAPTHETA}{\CAPPSI}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}]\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{$\HORSESHOE$-Intro}, 1--16}
\gaproof{
\galine{18}{$\pardisjunction{\parconjunction{\CAPTHETA}{\CAPPSI}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{Assume}}
\galinend{ }{ }{ }
\galinend{ }{$\qquad\vdots$}{ }
\galinend{ }{ }{ }
\galine{$\integer{n}$}{$\partriplebar{\CAPTHETA}{\CAPPSI}\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{ }
}
\gline{$\integer{n}+1$}{$[\pardisjunction{\parconjunction{\CAPTHETA}{\CAPPSI}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}\HORSESHOE$}{ }
\glinend{ }{$\qquad\partriplebar{\CAPTHETA}{\CAPPSI}]\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{\Rule{$\HORSESHOE$-Intro}, 18--$\integer{n}$}
\gline{$\integer{n}+2$}{$[\partriplebar{\CAPTHETA}{\CAPPSI}\TRIPLEBAR$}{\Rule{$\TRIPLEBAR$-Intro}, 17,}
\glinend{ }{$\qquad\pardisjunction{\parconjunction{\CAPTHETA}{\CAPPSI}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}]\constant{c_{\integer{1}}}\ldots\constant{c_{\integer{\integer{m}}}}/\variable{x}_1\ldots\variable{x}_{\integer{m}}$}{$\integer{n}+1$}
\glinend{ }{ }{ }
\glinend{ }{$\qquad\vdots$}{ }
\glinend{ }{ }{ }
\gline{$\integer{q}+2$}{$\forall\bpartriplebar{\partriplebar{\CAPTHETA}{\CAPPSI}}{\pardisjunction{\parconjunction{\CAPTHETA}{\CAPPSI}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}}$}{\Rule{$\forall$-Intro}, $\integer{q}+1$}
\end{gproofnn}
\noindent{}Note that we have left steps $18$--$\integer{n}$ for the reader; 
this is just the derivation of the other conditional needed for \Rule{$\TRIPLEBAR$-Intro} on line $\integer{n}+2$. 
Also note that the last steps, lines $\integer{n}+3$ to the end, are all \Rule{$\forall$-Intro} meant to eliminate the constants $\constant{c_{\integer{1}}},\ldots,\constant{c_{\integer{\integer{m}}}}$.
\end{PROOF}
%Now we turn to the proof of the \GSD{} Completeness Lemma.
\begin{PROOFOF}{Thm. \ref{GSDCompletenessLemma}}
To prove the theorem, we shall describe an algorithm for applying the rules of \GSDP{} and \Rule{$\TRIPLEBAR$-Exchange} that takes a \GSL{} sentence $\CAPPHI$ and either halts in a derivation of $\conjunction{\Al}{\negation{\Al}}$, or halts with a sentence in \CAPS{dnf} for which there is some model $\IntA$ that makes $\CAPPHI$ true.
Since a sentence can be derived using the rules of \GSDP{} and \Rule{$\TRIPLEBAR$-Exchange} \Iff it can be derived using the basic rules of \GSD{}, this is sufficient to prove the theorem. 

The algorithm begins with $\CAPPHI$ as an assumption on line 1. 
The algorithm then applies the method studied earlier in section \mvref{Disjunctive Normal Form} to produce a sentence $\CAPPHI'$ in \CAPS{dnf} that's \CAPS{tfe} to $\CAPPHI$.
We have to show that each step of the earlier method can be carried out in steps using the rules of \GSDP{} and \Rule{$\TRIPLEBAR$-Exchange}.
The earlier method proceeded in three stages. 
\begin{description}
\item[Step A:] \hfill
\begin{cenumerate}
\item If a subsentence of $\CAPPHI$ has $\HORSESHOE$ as its main connective, i.e. if $\CAPPHI=\horseshoe{\CAPTHETA}{\CAPPSI}$, replace the subsentence by $\disjunction{\negation{\CAPTHETA}}{\CAPPSI}$.
Repeat as necessary to obtain a sentence $\CAPPHI^*$ without conditionals. 
Each of these steps are sanctioned by \Rule{$\HORSESHOE$/$\VEE$-Exchange}.

\item If a subsentence of $\CAPPHI$ has $\TRIPLEBAR$ as its main connective, i.e. if $\CAPPHI=\triplebar{\CAPTHETA}{\CAPPSI}$, it is replaced with the subsentence $\disjunction{\parconjunction{\CAPTHETA}{\CAPPSI}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}$.
Repeat as necessary to obtain a sentence $\CAPPHI^{**}$ without biconditionals.
Each of these steps are sanctioned by \Rule{$\TRIPLEBAR$-Exchange}.
\end{cenumerate}

\item[Step B:]
In the case where $\CAPPHI^{**}$ contains a subsentence whose main connective is negation and which contains other connectives, we replace that subsentence by the following steps:
\begin{cenumerate}
\item Replace $\negation{\negation{\CAPTHETA}}$ by $\CAPTHETA$; this step is sanctioned by \Rule{$\NEGATION\NEGATION$-Elim}.
\item Replace $\negation{\parconjunction{\CAPTHETA}{\CAPPSI}}$ by $\disjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}$; this step is sanctioned by \Rule{DeM}.
\item Replace $\negation{\pardisjunction{\CAPTHETA}{\CAPPSI}}$ by $\conjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}$; this step is sanctioned by \Rule{DeM}.
\end{cenumerate}
Repeat as necessary to obtain a sentence $\CAPPHI^{***}$ in which negations govern nothing but sentence letters. 

\item[Step C:]
The only thing that could prevent $\CAPPHI^{***}$ from being in \CAPS{dnf} is that some conjunctions govern some disjunctions, i.e., there is a subsentence of the form $\conjunction{\CAPTHETA}{\pardisjunction{\CAPPSI_1}{\disjunction{\ldots}{\CAPPSI_{\integer{n}}}}}$, or the reverse $\conjunction{\pardisjunction{\CAPPSI_1}{\disjunction{\ldots}{\CAPPSI_{\integer{n}}}}}{\CAPTHETA}$.
Those subsentences can each be replaced by the equivalent sentence $\disjunction{\parconjunction{\CAPTHETA}{\CAPPSI_1}}{\disjunction{\ldots}{\parconjunction{\CAPTHETA}{\CAPPSI_{\integer{n}}}}}$ or $\disjunction{\parconjunction{\CAPPSI_1}{\CAPTHETA}}{\disjunction{\ldots}{\parconjunction{\CAPPSI_{\integer{n}}}{\CAPTHETA}}}$.
These steps are sanctioned by \Rule{Distribution}.
\end{description}
\noindent{}Applying the above steps A, B, and C provides us a derivation starting with $\CAPPHI$ as an assumption (and no other assumptions) and ending with a \CAPS{dnf} sentence that's \CAPS{tfe} to $\CAPPHI$. 
There are two cases:
\begin{description}
\item[Case 1:] 
Every disjunct contains a sentence letter and the negation of that sentence letter. 
That is, each disjunction has the form $\parconjunction{\CAPPSI_1}{\conjunction{\ldots}{\conjunction{\CAPPSI_{\integer{i}}}{\conjunction{\ldots}{\conjunction{\negation{\CAPPSI_{\integer{i}}}}{\conjunction{\ldots}{\CAPPSI_{\integer{n}}}}}}}}$; for example: $\parconjunction{\Al}{\conjunction{B}{\conjunction{\Cl}{\conjunction{\negation{\El}}{\conjunction{\negation{\Bl}}{\negation{\Kl}}}}}}$.

\item[Case 2:]
At least one disjunct contains no sentence letter such that the negation of the sentence letter is also in the disjunct. 
\end{description}
\noindent{}It can be shown in case $1$ that the algorithm derives a contradiction from the original sentence.
First, observe that any conjunction that contains a sentence letter and its negation leads to a contradiction by repeated steps of \Rule{$\WEDGE\!$-Elim}. 
Thus we can derive the negation of any such conjunction using \Rule{$\NEGATION$-Intro}.
So if the last line of the derivation so far is of the form $\pardisjunction{\CAPPSI_1}{\disjunction{\ldots}{\CAPPSI_{\integer{n}}}}$ and each $\CAPPSI_{\integer{i}}$ contains a sentence letter and the negation of that sentence letter, then add to the derivation lines that establish the negation of each $\CAPPSI_{\integer{i}}$. 
Thus by $\integer{n}-1$ steps of \Rule{D.S.} the result is a single $\CAPPSI_{\integer{i}}$ by itself with only the first line as an assumption.
Since this remaining conjunct has both a sentence letter and its negation it is trivial to derive a contradiction.

Schematically, the procedure looks like:

\begin{gproofnn}
\glinend{ }{$\CAPPHI$}{\Rule{Assume}} %\marginnote{\scriptsize{}The original sentence}[0cm]
\glinend{ }{ }{ }
\glinend{ }{$\qquad\vdots$}{ }
\glinend{ }{ }{ }
\glinend{ }{$\disjunction{\CAPPSI_1}{\disjunction{\ldots}{\CAPPSI_{\integer{n}}}}$}{ } %\marginnote{\scriptsize{}The \CAPS{dnf} sentence after steps A, B, and C}[0cm]
\gaproof{
\galinend{ }{$\CAPPSI_1$}{\Rule{Assume}}
\galinend{ }{ }{ }
\galinend{ }{$\qquad\vdots$}{ }
\galinend{ }{ }{ }
\galinend{ }{$\conjunction{\CAPTHETA_1}{\negation{\CAPTHETA_1}}$}{ }
}
\glinend{ }{$\horseshoe{\CAPPSI_1}{\parconjunction{\CAPTHETA_1}{\negation{\CAPTHETA_1}}}$}{\Rule{$\HORSESHOE$-Intro}} %\marginnote{\scriptsize{}We start deriving the negation of each disjunct}[0cm]
\glinend{ }{$\negation{\CAPPSI_1}$}{\Rule{$\NEGATION$-Intro}}
\glinend{ }{ }{ }
\glinend{ }{$\qquad\vdots$}{ }
\glinend{ }{ }{ }
\gaproof{
\galinend{ }{$\CAPPSI_{\integer{n}}$}{\Rule{Assume}}
\galinend{ }{ }{ }
\galinend{ }{$\qquad\vdots$}{ }
\galinend{ }{ }{ }
\galinend{ }{$\conjunction{\CAPTHETA_{\integer{n}}}{\negation{\CAPTHETA_{\integer{n}}}}$}{ }
}
\glinend{ }{$\horseshoe{\CAPPSI_{\integer{n}}}{\parconjunction{\CAPTHETA_{\integer{n}}}{\negation{\CAPTHETA_{\integer{n}}}}}$}{\Rule{$\HORSESHOE$-Intro}}
\glinend{ }{$\negation{\CAPPSI_{\integer{n}}}$}{\Rule{$\NEGATION$-Intro}}
\glinend{ }{$\disjunction{\CAPPSI_1}{\disjunction{\ldots}{\CAPPSI_{\integer{n}-1}}}$}{\Rule{D.S.}} %\marginnote{\scriptsize{}Start applying \Rule{D.S.}}[0cm]
\glinend{ }{$\disjunction{\CAPPSI_1}{\disjunction{\ldots}{\CAPPSI_{\integer{n}-2}}}$}{\Rule{D.S.}}
\glinend{ }{$\disjunction{\CAPPSI_1}{\disjunction{\ldots}{\CAPPSI_{\integer{n}-3}}}$}{\Rule{D.S.}}
\glinend{ }{ }{ }
\glinend{ }{$\qquad\vdots$}{ }
\glinend{ }{ }{ }
\glinend{ }{$\disjunction{\CAPPSI_1}{\CAPPSI_2}$}{\Rule{D.S.}}
\glinend{ }{$\CAPPSI_1$}{\Rule{D.S.}}
\glinend{ }{$\negation{\CAPPSI_1}$}{\Rule{Rep.}}
\glinend{ }{$\conjunction{\Al}{\negation{\Al}}$}{\Rule{A.C.}} %\marginnote{\scriptsize{}Finally we reach a contradiction}[0cm]
\end{gproofnn}

\noindent{}So much for case 1.

In case $2$ it can be shown that there is a model that makes all sentences in the derivation true, starting with the last.
To construct this model, first choose the disjunction that does not contain a sentence letter and its negation.
If there is more than one, it doesn't matter which is chosen.
Then construct a model $\IntA$ by assigning $\TrueB$ to each sentence letter that occurs positively (without a negation in front) and $\FalseB$ to each sentence letter that occurs negatively (with a negation in front).

This model makes each element of the conjunction true and thus makes the entire conjunction true. 
Since the sentence containing it is a disjunction, this is sufficient to make the entire sentence true.
Thus it makes the last line of the derivation true.
Observe that all of the steps we used in the derivation were replacement of provably equivalence sentences;
that is, they used exchange shortcut rules.
Thus, we can also construct a derivation by \mention{turning this proof upside down}, so to speak.
In other words, we can construct a new derivation, with the last step of the original derivation as the initial assumption step, then use the exchange rules to work back to original $\CAPPHI$.

Thus, by soundness, if the first sentence of the \mention{upside-down derivation} (the sentence in \CAPS{dnf} that was at the bottom) is true in a model, then so is everything that can be derived from it, including our original sentence $\CAPPHI$ that is now at the end of the inverted derivation. 
Therefore, $\CAPPHI$ is true in some model. 
\end{PROOFOF}
\begin{THEOREM}{\LnpTC{GSDWCompleteness} Weak \GSD{} Completeness Theorem:}
For all \GSL{} sentences $\CAPPHI$: if $\sdtstile{}{}\CAPPHI$, then $\sststile{}{}\CAPPHI$ in \GSD{}.
\end{THEOREM}
\begin{PROOF}
We apply the method above from the \GSD{} Completeness Lemma to the negation of $\CAPPHI$. 
This either produces a derivation of a contradiction from $\negation{\CAPPHI}$, in which case we can prove $\CAPPHI$ by adding two more steps justified by \Rule{$\HORSESHOE$-Intro} and \Rule{$\NEGATION$-Elim}, or it produces a model that makes $\negation{\CAPPHI}$ true and that therefore makes $\CAPPHI$ false. So, $\CAPPHI$ is either false in some model or is derivable in \GSD{}. 
\end{PROOF}
\noindent{}Finally, as a corollary we get:
\begin{THEOREM}{\LnpTC{GSDCompleteness} \GSD{} Completeness Theorem:}
For every finite set $\Delta$ of sentences of \GSL{} and every sentence $\CAPPHI$ of \GSL{}, if $\Delta\sdtstile{}{}\CAPPHI$, then $\Delta\sststile{}{}\CAPPHI$ in \GSD{}.
\end{THEOREM}
\begin{PROOF}
This follows immediately from the Weak \GSD{} Completeness Theorem and theorem \mvref{RegWeakCompletenessEquiv}.
\end{PROOF}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Completeness of \GQD{}}\label{Sec:Completeness of GQD}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Next we prove the completeness of \GQD{}.  We want to use a similar strategy for \GQD{} we did for \GSD{}, but we have to deal with the quantifiers somehow.
Unfortunately, the quantifiers prevent us from proving the analogue of DNF for \GQL{}.
Given an arbitrary sentence, there is no guarantee that we can reorder the quantifiers so that each has its scope contained in a single disjunct.
For example:  $\universal{\variable{x}}\pardisjunction{\Hp{\variable{x}}}{\Gp{\variable{x}}}$ is not equivalent to $\disjunction{\universal{\variable{x}}\Hp{\variable{x}}}{\universal{\variable{x}}\Gp{\variable{x}}}$.

To get around problems like this, we instead show we can move all the quantifiers to the front of the sentence.
This has the advantage of separating the quantifier parts of the logical structure from the SL parts.

\subsection{Prenex Definition and Steps}\label{Prenex Definition and Steps}
\begin{majorILnc}{\LnpDC{PrenexNF}}
A sentence $\CAPPHI$ of \GQL{} is in \df{prenex normal form} \Iff every quantifier is in initial position, or, in other words, the scope of all quantifiers is greater than that of any non-quantifier connective.
\end{majorILnc}
\begin{THEOREM}{\LnpTC{PrenexNFTheorem} Prenex Normal Form Theorem:}
For each sentence $\CAPTHETA$ of \GQL{}, there is a provably equivalent sentence $\CAPTHETA^*$ in prenex normal form; that is, $\CAPTHETA^*$ is in prenex normal form and $\sststile{}{}\triplebar{\CAPTHETA}{\CAPTHETA^*}$ in \GQD{}.
\end{THEOREM}
\begin{PROOF}
As with \CAPS{dnf} there are a set of steps for turning sentence $\CAPTHETA$ into a sentence $\CAPTHETA^*$ in prenex normal form. 
First we give the steps, and then show that each step can be sanctioned either by \Rule{QN}, \Rule{$\TRIPLEBAR$-Exchange}, or an exchange rule that can be introduced.
(We call these new exchange rules the \niidf{Prenex Exchange Rules}.\index{Exchange Rules!Prenex}) 
Because all the steps in the process are justified by exchange rules, we can either read the resulting series of steps top-down as a derivation of $\CAPTHETA^*$ from $\CAPTHETA$, or bottom-up as a derivation of $\CAPTHETA$ from $\CAPTHETA^*$. 
So, we'll have shown that $\sststile{}{}\triplebar{\CAPTHETA}{\CAPTHETA^*}$ in the derivation system consisting of \Rule{$\TRIPLEBAR$-Exchange} and the Prenex Exchange Rules.
But, as with all the other exchange rules anything that can be derived using the Prenex Exchange Rules can be derived in \GQD{} alone;
so, this is sufficient to show that $\sststile{}{}\triplebar{\CAPTHETA}{\CAPTHETA^*}$ in \GQD{}. First, the steps are:
\begin{cenumerate}
\item Replace biconditionals with disjunctions of conjunctions; i.e. replace $\triplebar{\CAPPHI}{\CAPPSI}$ with $\disjunction{\parconjunction{\CAPPHI}{\CAPPSI}}{\parconjunction{\negation{\CAPPHI}}{\negation{\CAPPSI}}}$.
\item Rewrite any variables that occur bound by more than one quantifier.
\item Move the first quantifier not in prenex position one step towards the front by the following principles. Repeat this step as often as necessary.  Keep in mind that you can't move forward a quantifier that binds the variable \mention{$\variable{x}$} if it has within its scope a new subformula that has a free \mention{$\variable{x}$}.  But we have prevented that problem by eliminating potentially clashing variables in Step 2.
\begin{longtable}[c]{ l l }
\toprule
\textbf{Replace} & \textbf{by} \\
\midrule
$\parconjunction{(\#\variable{x})\CAPTHETA}{\CAPPSI}$ & $(\#\variable{x})\parconjunction{\CAPTHETA}{\CAPPSI}$ \\
$\parconjunction{\CAPTHETA}{(\#\variable{x})\CAPPSI}$ & $(\#\variable{x})\parconjunction{\CAPTHETA}{\CAPPSI}$ \\

$\pardisjunction{(\#\variable{x})\CAPTHETA}{\CAPPSI}$ & $(\#\variable{x})\pardisjunction{\CAPTHETA}{\CAPPSI}$ \\
$\pardisjunction{\CAPTHETA}{(\#\variable{x})\CAPPSI}$ & $(\#\variable{x})\pardisjunction{\CAPTHETA}{\CAPPSI}$ \\

$\parhorseshoe{\CAPTHETA}{(\#\variable{x})\CAPPSI}$ & $(\#\variable{x})\parhorseshoe{\CAPTHETA}{\CAPPSI}$ \\

$\parhorseshoe{\existential{\variable{x}}\CAPTHETA}{\CAPPSI}$ & $\universal{\variable{x}}\parhorseshoe{\CAPTHETA}{\CAPPSI}$ \\
$\parhorseshoe{\universal{\variable{x}}\CAPTHETA}{\CAPPSI}$ & $\existential{\variable{x}}\parhorseshoe{\CAPTHETA}{\CAPPSI}$ \\

$\negation{\existential{\variable{x}}\CAPTHETA}$ & $\universal{\variable{x}}\negation{\CAPTHETA}$ \\
$\negation{\universal{\variable{x}}\CAPTHETA}$ & $\existential{\variable{x}}\negation{\CAPTHETA}$ \\
\bottomrule
\end{longtable}
Note that $(\#\variable{x})$ is just a dummy quantifier standing for either; 
replacement is the same for both quantifiers.  Also, we use \mention{$\variable{x}$} in the chart above, but the same principles hold for quantifiers with any other variable.
\end{cenumerate}
After applying these steps to a sentence $\CAPTHETA$ we get a sentence $\CAPTHETA^*$ that is in prenex normal form.\footnote{For more discussion of Prenex Form, see \citealt[132]{Kleene1967}, \citealt[54]{Hodges2001}, \citeyear[30]{Hodges2001b}.} 
We have to show that each step can be sanctioned by an exchange rule.
Step (1) is straightforward, since it is sanctioned by \Rule{$\TRIPLEBAR$-Exchange}.
But steps (2) and (3) we need new rules (although the replacements involving negations in (3) can be handled with \Rule{QN}).
The most straightforward strategy is to read the needed exchange rules right off the steps. 
Thus, the Prenex Exchange Rules are given in the following chart.
%\begin{table}[!ht]
%\renewcommand{\arraystretch}{1.5}
%\begin{center}
%\begin{tabular}{ p{1in} l l } %p{2.2in} p{2in}
%\toprule
%\textbf{Name} & \textbf{Given} & \textbf{May Add} \\ 
%\midrule
\renewcommand{\arraystretch}{1.5}
\begin{longtable}[c]{ p{1in} l l } %p{2.2in} p{2in}
\toprule
\textbf{Name} & \textbf{Given} & \textbf{May Add} \\ 
\midrule
\endfirsthead
\multicolumn{3}{c}{\emph{Continued from Previous Page}}\\
\toprule
\textbf{Name} & \textbf{Given} & \textbf{May Add} \\ 
\midrule
\endhead
\bottomrule
\caption{Prenex Exchange Short-Cut Rules for \GQD{}}\\[-.15in]
\multicolumn{3}{c}{\emph{Continued next Page}}\\
\endfoot
\bottomrule
\caption{Prenex Exchange Shortcut Rules for \GQD{}}\\
\endlastfoot
\label{GSDplusPrenex}\Rule{$\ALPHA$/$\BETA$-Exch} & $(\#\ALPHA)\CAPPHI$ & $(\#\BETA)\CAPPHI\BETA/\ALPHA$ \\
\Rule{Q Shuffling} & $\parconjunction{(\#\variable{x})\CAPTHETA}{\CAPPSI}$ & $(\#\variable{x})\parconjunction{\CAPTHETA}{\CAPPSI}$ \\
& $\parconjunction{\CAPTHETA}{(\#\variable{x})\CAPPSI}$ & $(\#\variable{x})\parconjunction{\CAPTHETA}{\CAPPSI}$ \\

& $\pardisjunction{(\#\variable{x})\CAPTHETA}{\CAPPSI}$ & $(\#\variable{x})\pardisjunction{\CAPTHETA}{\CAPPSI}$ \\
& $\pardisjunction{\CAPTHETA}{(\#\variable{x})\CAPPSI}$ & $(\#\variable{x})\pardisjunction{\CAPTHETA}{\CAPPSI}$ \\

& $\parhorseshoe{\CAPTHETA}{(\#\variable{x})\CAPPSI}$ & $(\#\variable{x})\parhorseshoe{\CAPTHETA}{\CAPPSI}$ \\

& $\parhorseshoe{\existential{\variable{x}}\CAPTHETA}{\CAPPSI}$ & $\universal{\variable{x}}\parhorseshoe{\CAPTHETA}{\CAPPSI}$ \\
& $\parhorseshoe{\universal{\variable{x}}\CAPTHETA}{\CAPPSI}$ & $\existential{\variable{x}}\parhorseshoe{\CAPTHETA}{\CAPPSI}$ \\
\end{longtable}
%\bottomrule
%\end{tabular}
%\end{center}
%\caption{Exchange Short-Cut Rules for \GSD{} (\GSD{})}
%\label{GSDplus2}
%\end{table}
\noindent{}Finally we show that anything that can be derived using the Prenex Exchange Rules can be derived using the basic rules of \GQD{} alone.
Recall from section \ref{Shortcut Rule Elimination Theorem Section} that all we need to do to show this is to prove the following:
\begin{THEOREM}{\LnpTC{GQD NDF Rule2}}
For all Prenex Exchange Rules \Rule{R}, any two \GQL{} formulas got by substituting other \GQL{} formulas into the may-add and given schemas of \Rule{R} are provably equivalent.
\end{THEOREM}
\noindent{}We leave the proof of this theorem to the reader, since as with the other exchange rules it just involves writing down the appropriate derivation schemas. 
\end{PROOF}

\subsection{The Strategy for Proving \GQD{} Completeness}
Our goal is to prove the strong completeness of \GQD{}: for any set $\Delta$ of \GQL{} sentences and \GQL{} sentence $\CAPPHI$, if $\Delta\sdtstile{}{}\CAPPHI$, then $\Delta\sststile{}{}\CAPPHI$. 
First we prove the completeness of \GQD{} and then show how to modify the method to prove strong completeness.
To prove completeness we show that for any sentence we can either (1) find a derivation of it or (2) prove that there is a model that makes it false. 
(This part of the strategy is more or less the same as what we did to show that \GSD{} is complete.)
In other words, $\CAPPHI$ is either derivable or not quantificationally true, from which it immediately follows that if $\CAPPHI$ is quantificationally true, then it is derivable. 

The method,\index{method, the} in brief, is to negate the sentence $\CAPPHI$ and begin a derivation.
Then we transform the negation of the sentence into prenex normal form, using the steps outlined in section \ref{Prenex Definition and Steps}. 
Next we transform the inner part of the sentence (remember the quantifiers are all up front) into \CAPS{dnf} form, using our standard method for that (see Sec. \pmvref{Disjunctive Normal Form}).
This does not introduce any new assumptions. 
We then systematically take instances of the bound variables and try to derive a contradiction.
If we can derive a contradiction we can then (assuming all goes well) use \Rule{$\NEGATION$-Elim} to obtain a derivation of $\CAPPHI$.

We must be very systematic since we have to be sure that if we get a contradiction we can derive it from the initial sentence $\CAPPHI$; and that if we do not get a contradiction we have not overlooked anything and that we can show the existence of a model making the sentence on the first line, $\CAPPHI$, true. 

It is important that we know the form of the sentence we have reached and are able to prescribe a uniform systematic method.
The sentence has been highly standardized; 
there are no biconditionals or conditionals (these have been eliminated in early steps of the transformation), negations govern only atomic sentences, and conjunctions govern only atomic sentences or their negations. 
These last, atomic sentence and their negations, are called \idf{ions}. 
We say an ion occurs \niidf{positively} \Iff it's an atomic sentence without a negation, and it occurs \niidf{negatively} \Iff it's a negated atomic sentence. 
We call the quantifier free part of the original sentence the \idf{matrix}. 
It is usually not a sentence since it may have free variables.
We call the sentences that are obtained from the matrix by substitution in the process of constructing the derivation \niidf{matrix instances}\index{matrix!instances|textbf}. 
To put some of our jargon together, the matrix of the sentence consists of disjunctions of conjunctions of ions. 

\subsection{The Method and Completeness Lemmas}\label{The Method Section}
In this section we describe the method sketched above.\index{method, the} 
Given a sentence $\CAPTHETA$, the Method either produces a derivation of $\CAPTHETA$ or indicates a model that makes it false:

\begin{description}
\item[Step 0:] Write $\negation{\CAPTHETA}$ on line 1 as an assumption.
Then first apply the prenex steps to put $\negation{\CAPTHETA}$ in Prenex Normal Form (\CAPS{pnf}). 
Next, apply the disjunctive normal form steps to the inner, quantifier-free part of the sentence until it's in \CAPS{dnf}. 
At this point we'll have a sentence $(\negation{\CAPTHETA})^*$ that's in what we'll call \idf{prenex disjunctive normal form}\index{disjunctive normal form!prenex} (\CAPS{pdnf}).  

\item[Step 1:] We continue the derivation operating on $(\negation{\CAPTHETA})^*$, the \CAPS{pdnf} of the sentence we're concerned with. 
If this \CAPS{pdnf} is a universal statement and contains no constants we write as the next line the instance of it we obtain by eliminating the quantifier and substituting the constant $\constant{a}$ for the previously bound variable;
these steps are sanctioned by \Rule{$\forall$-Elim}.
This step is only done once, whereas the next three steps generally require repeated recursive applications. 

\item[Step 2:] For every universal sentence that appears thus far in the derivation, we add \emph{all new instances} that can be formed with constants that occur earlier in the derivation;
these steps are sanctioned by \Rule{$\forall$-Elim}.
E.g., if $\universal{\variable{x}}\CAPPHI$ appears on a line and the constant $\constant{c}$ appears anywhere (earlier) in the derivation, then if we have not taken an instance of $\CAPPHI$ with $\constant{c}$ yet (i.e., $\CAPPHI\constant{c}/\variable{x}$), we do so.
As a practical matter, this means that it is useful in following the method to keep track somewhere of the constants used at each stage and of which constants have been used to instantiate which universal statements.
Note that in this step we are taking new instances with old constants and that we are not adding any new assumptions. 
We may, however, be adding new existentials. 

\item[Step 3:] For every existential sentence that appears in the derivation for which no instance has been added yet, add an instance using the first constant which \emph{does not occur in any previous assumption}. 
Note that \mention{instance} is to be taken very strictly here. 
The fact that we instantiated $\existential{\variable{x}}\Kpp{\variable{x}}{\constant{a}}$ with $\Kpp{\constant{b}}{\constant{a}}$ takes care of that existential, but if we later add the sentence $\existential{\variable{x}}\Kpp{\variable{x}}{\constant{b}}$ then we must add an instance of it. 
The rule which sanctions these steps is \Rule{Assume}. 
We eventually discharge these premises by \Rule{$\HORSESHOE$-Elim} and \Rule{$\exists$-Elim} if we get to a contradiction.
It is in anticipation of this eventuality that we carefully chose a constant which does not occur in any previous assumption.
Note that with this step we are adding new instances with new constants in new assumptions. 

\item[Step 4:] Determine whether the conjunction of the \emph{instances} of the matrix in the derivation thus far are contradictory. 
Officially, the way to do this is to take the conjunction of them all by \Rule{$\WEDGE\!$-Intro}, use \Rule{Distribution} to get the conjunction into \CAPS{dnf} and check whether every disjunct contains a contradiction. 
If so, then by a process of \Rule{$\VEE$-Elim} and \Rule{Any Contradiction} we can eventually produce the line $\conjunction{\Al}{\negation{\Al}}$. 

This step can be cumbersome in practice. We give some unofficial short cuts to make this more manageable soon.

\item[Step 5:] \hfill
\begin{cenumerate}
\item If the matrices are contradictory (see step 4) we stop.
\item Or if the conjunction of the matrix instances is consistent and the last applications of Steps 2 and 3 produce no new sentences, we stop.
\item Or if the conjunction of the matrix instance is consistent and the last applications of Steps 2 and 3 produced new sentences, then we return to Step 2 and reapply those steps.
\end{cenumerate}
\end{description}
There are three possible outcomes of applying this method to a sentence:
\begin{cenumerate}
\item The method reaches a contradiction.
\item The method stops without a contradiction.
\item The method generates new sentences perpetually without contradiction.
\end{cenumerate}
We show first that if a contradiction is reached we can construct a derivation of $\CAPTHETA$. 

\begin{THEOREM}{\LnpTC{Derivational Lemma} Derivational Lemma:}
If the Method starts with $\negation{\CAPTHETA}$ and produces a contradiction, then there is a derivation of $\CAPTHETA$.
\end{THEOREM}
\begin{PROOF}
Step 3 left us with $\conjunction{\Al}{\negation{\Al}}$ on a line with its assumptions being those of the matrices. 
We want to shift those assumptions so that we end up with the contradiction from the first assumption, $\negation{\CAPTHETA}$, alone.
We know by considering our method that other assumptions entered only by Step 2, where we added instances of existentials using new constants. 
We eliminate the last assumption by a \Rule{$\HORSESHOE$-Intro}. 
We know that this eliminated assumption introduced a \emph{new} constant from an existential. 
Therefore we know that this constant did not appear in any earlier assumption or in the existential of which we are taking an instance.
It also (obviously) does not occur in $\conjunction{\Al}{\negation{\Al}}$.
Thus we are allowed to use the rule \Rule{$\exists$-Elim} on the existential claim from which we assumed that instance. 

So we derive the contradiction $\conjunction{\Al}{\negation{\Al}}$ again, by \Rule{$\exists$-Elim}. 
We continue this process, repeating $\conjunction{\Al}{\negation{\Al}}$ as often as necessary to shift the dependence back to the assumption on line 1. 
This gives us a derivation of $\conjunction{\Al}{\negation{\Al}}$ from the first assumption, $\negation{\CAPTHETA}$, only. 

We then add two more lines: $\horseshoe{\negation{\CAPTHETA}}{\parconjunction{\Al}{\negation{\Al}}}$, sanctioned by \Rule{$\HORSESHOE$-Intro}, and $\CAPTHETA$, sanctioned by \Rule{$\NEGATION$-Elim}. 
Thus we have a derivation of $\CAPTHETA$ from no assumptions. 
\end{PROOF}

We have shown that if we obtain a contradiction in the derivation process we can derive the original sentence that interests us.


We must now show that if we do not obtain a contradiction (whether or not the method stops), then there is a model that makes $\negation{\CAPTHETA}$ true (and hence makes $\CAPTHETA$ false).

Before giving the rigorous version of the construction of the model, we present some of the ideas in a more concrete context. 
If we consider a sentence such as $\disjunction{\parconjunction{\Kp{\constant{a}}}{\negation{\Gp{\constant{b}}}}}{\parconjunction{\negation{\Kp{\constant{b}}}}{\Hp{\constant{c}}}}$ we can observe several things. 
First, each disjunct is satisfiable \Iff no ion occurs both positively and negatively in it. 
It is obvious that a conjunction that includes a sentence and its negation cannot be satisfied, but we can show for a conjunction of ions that that is the only way in which it can fail to be satisfiable. 
For example, we can make $\Kp{\constant{a}}$ and $\negation{\Gp{\constant{b}}}$ true by letting $\KK$ be interpreted as the set of even numbers, $\GG$ the set of numbers divisible by $10$ and letting \mention{$\constant{a}$} be assigned $2$ and \mention{$\constant{b}$} be assigned $7$. 

Of course several such sentences taken together produce different results. E.g., as we saw above $\disjunction{\parconjunction{\Kp{\constant{a}}}{\conjunction{\negation{\Kp{\constant{b}}}}{\negation{\Gp{\constant{c}}}}}}{\parconjunction{\Gp{\constant{b}}}{\negation{\Gp{\constant{c}}}}}$ is satisfiable, as is $\disjunction{\parconjunction{\Kp{\constant{b}}}{\conjunction{\negation{\Kp{\constant{c}}}}{\negation{\Gp{\constant{b}}}}}}{\parconjunction{\Gp{\constant{c}}}{\negation{\Gp{\constant{d}}}}}$, but the two together (taken as a conjunction) are not.
The reason is that while each disjunct of the first sentence is self-consistent, it cannot be true simultaneously with either of the disjuncts of the second sentence. If we have a series of disjunctions then they are simultaneously satisfiable only if we can find a way of picking a disjunct from each one in such a way that all the chosen disjuncts can be true together.

This is relevant to the task at hand because we know that all of the non-quantified sentences in our derivation are in \CAPS{dnf} and are thus disjunctions of conjunctions of ions.
We are calling the quantifier free part of the original sentence the matrix.
It is usually not a sentence since it may have free variables. 
The sentences that are obtained from the matrix by substitution in the process of constructing the derivation are the matrix instances. 
We use the notation $M_{i,j}$ for the disjuncts of the matrix instances, specifically the disjuncts of the first matrix instance are $M_{1,1},M_{1,2},\ldots,M_{1,m}$.
Thus the first matrix instance is $\disjunction{M_{1,1}}{\disjunction{M_{1,2}}{\disjunction{\ldots}{M_{1,m}}}}$.
The matrix instances that appear in the derivation can be listed in an array:
\begin{center}
\begin{tabular}{ c }
$\disjunction{M_{1,1}}{\disjunction{M_{1,2}}{\disjunction{\ldots}{M_{1,m}}}}$ \\
$\disjunction{M_{2,1}}{\disjunction{M_{2,2}}{\disjunction{\ldots}{M_{2,m}}}}$ \\
\\
\hspace{.5in} $\vdots$ \\
\\
$\disjunction{M_{n,1}}{\disjunction{M_{n,2}}{\disjunction{\ldots}{M_{n,m}}}}$ \\
\end{tabular}
\end{center}
Note that if the the method never stops, then this array is infinitely long. 

The matrices are jointly consistent \Iff there is a way of picking an $M_{i,j}$ from each matrix instance so that the conjunction of those $M_{i,j}$ contains no atomic sentence and its negation. 
In one direction this is easy to see: if there is no way of choosing a disjunct from each matrix instance that does not end up with an atomic sentence and its negation among the chosen sentences then the set of instances is inconsistent. 

To show that all instances are satisfiable when such a selection can be made without choosing a sentence and its negation takes some proving.
In order to do this we need to define the \idf{master matrix list} $M$.\index{matrix!master list} 
We first choose (if there is more than one) a set of disjuncts $M_{i,j}$ (including one from each matrix instance $M_i$) that does not contain any atomic sentence and its negation.
This is a set of conjunctions of atomic sentences and negations of atomic sentences.
Our master matrix list $M$ simply consists of all these atomic sentences and negated atomic sentences.
Note that since the $M_{i,j}$ selections must be consistent no atomic sentence that appears unnegated also appears negated.
\begin{majorILnc}{\LnpDC{MatrixModel}}
Given a master matrix list $M$, the \nidf{matrix model of $M$}\index{matrix!model} is the model $\IntA_M$ such that:
\begin{cenumerate}
\item The universe of $\IntA_M$ contains one natural number for each constant that appears in $M$, and $\IntA_M(\constant{a})=1$, $\IntA_M(\constant{b})=2$, $\IntA_M(\constant{c})=3$, $\IntA_M(\constant{d})=4$, and so on; $\IntA_M(\variable{t})=1$ for any constant $\variable{t}$ that doesn't appear in $M$. 
\item For each $\integer{m}$-place predicate $\PP$, $\IntA_M(\PP)$ is the set of $\integer{m}$-tuples of natural numbers $\langle\integer{n}_1,\ldots,\integer{n}_\integer{m}\rangle$ such that $\IntA_M(\variable{t}_1)=\integer{n}_1,\ldots,\IntA_M(\variable{t}_\integer{m})=\integer{n}_\integer{m}$ and $\Pp{\variable{t}_1\ldots\variable{t}_\integer{m}}$ appears on the list $M$.
\item Assignments are only made if justified by these principles.
\end{cenumerate}
\end{majorILnc}
A bit more informally, we list the constants that occur on the master matrix list. $\IntA_M$ has a universe that contains as many natural numbers as constants used.
We assign to each constant that occurs on the list the natural number that indicates its place in the order, i.e. $1$ to $\constant{a}$, $2$ to $\constant{b}$, and so on.
%Any constants not occurring on the master matrix list $M$ will be assigned $1$. 
Note that this produces a \idf{census}.
Each $1$-place predicate is assigned the set of numbers associated with the constants such that an instance of the predicate followed by that constant appears on the master matrix list $M$. 
Each $2$-place predicate is assigned the set of pairs of numbers associated with constants such that an instance of the predicate followed by that pair of constants appears on the master matrix list $M$. 
E.g., if $\Kpp{\constant{a}}{\constant{b}}$, $\Kpp{\constant{b}}{\constant{c}}$, and $\Kpp{\constant{d}}{\constant{e}}$ appear on $M$, then $\IntA_M(\KK)$ is assigned $\{\langle1,2\rangle,\langle2,3\rangle,\langle4,5\rangle\}$.
Assignments are made in a similar fashion for $\integer{n}$-placed predicates for $\integer{n}>2$.\footnote{Note 
that if the method never stops, then the master matrix list $M$ is infinite and we won't actually be able to write down the matrix model $\IntA_M$. 
But this isn't a problem, the matrix model $\IntA_M$ still exists, even if we can't write it down.} 
\begin{THEOREM}{\LnpTC{MethodLemmaA} The Method Lemma 1:}
The matrix model $\IntA_M$ makes true all sentences on the master matrix list $M$.
\end{THEOREM}
\begin{PROOF}
By construction, if an atomic sentence appears on the list we decided to put the relevant pair, triple, or whatever, of numbers in the set assigned to the predicate letter. 
For each negated atomic sentence on the list we know that we would not put the relevant pair, triple, or whatever, in the model of the predicate letter unless the atomic sentence which is being negated also appeared. 
But that never happened because $M$ is consistent by hypothesis.
\end{PROOF}
\begin{THEOREM}{\LnpTC{MethodLemmaB} The Method Lemma 2:}
All matrix instances in the derivation are true in the matrix model $\IntA_M$.
\end{THEOREM}
\begin{PROOF}
By Lemma 1 (Thm. \ref{MethodLemmaA}), all sentences on the master matrix list $M$ are true, and we included all the conjuncts of at least one disjunct $M_{i,j}$ from each matrix instance in forming the master list.
\end{PROOF}
\begin{THEOREM}{\LnpTC{MethodLemmaC} The Method Lemma 3:}
All quantified sentences in the derivation are true in the matrix model $\IntA_M$.
\end{THEOREM}

Informally, every universal has been instantiated with all the relevant constants, and every existential by at least one. 
Since $\IntA_M$ is a census, it follows that all the sentences in the derivation are true.

More rigorously...

\begin{PROOF}
We prove this lemma using a recursive proof on the number of quantifiers in each sentence.
\begin{description}
\item[Base Case:] 
The base case is the case of the sentences with $\integer{k}=0$ quantifiers. 
But these sentences are just the matrix instances in the derivation. 
We already proved in The Method Lemma 2 (Thm. \ref{MethodLemmaB}) that all these sentences are true the matrix model $\IntA_M$, so the base case is complete.

\item[Inheritance Step:] \hfill
\begin{description}
\item[Recursive Assumption:]
Our recursive assumption is that all sentences in the derivation with less than $\integer{k}$ quantifiers are true in the matrix model $\IntA_M$.

\item[Existential Quantifier:]
Say $\CAPTHETA$ is a sentence appearing in the derivation of the form $\existential{\ALPHA}\CAPPHI$, where $\CAPPHI$ is a formula with $\integer{k}-1$ quantifiers. 
Step 3 of the method guarantees that the sentence $\CAPPHI\variable{t}/\ALPHA$, for some constant $\variable{t}$, appears somewhere in the derivation. 
This sentence $\CAPPHI\variable{t}/\ALPHA$ has $\integer{k}-1$ quantifiers, so by the recursive assumption it is true in the matrix model $\IntA_M$. 
But then the existentially quantified sentence $\existential{\ALPHA}\CAPPHI$ is true in $\IntA_M$ as well.
(To show this rigorously, consider the $\variable{s}$-variant of $\IntA_M$, $\As{\variable{s}_1}{}$, that assigns the same element of the universe of $\IntA_M$ to $\variable{s}$ as $\IntA_M$ assigns to the constant $\variable{t}$.
Now by the Dragnet Theorem, Thm. \pncmvref{The Dragnet Theorem}, since $\IntA_M$ makes $\CAPPHI\variable{t}/\ALPHA$ true, the sentence $\CAPPHI\variable{s}/\ALPHA$ is true on $\As{\variable{s}_1}{}$.
It follows from this that $\existential{\ALPHA}\CAPPHI$ is true on $\IntA_M$.)

\item[Universal Quantifier:]
Say $\CAPTHETA$ is a sentence appearing in the derivation of the form $\universal{\ALPHA}\CAPPHI$, where $\CAPPHI$ is a formula with $\integer{k}-1$ quantifiers. 
All instances $\CAPPHI\variable{t}/\ALPHA$ which appear in the derivation have $\integer{k}-1$ quantifiers, and so by the recursive hypothesis are true in the matrix model $\IntA_M$. 
If we consider any $\variable{s}$-variant of $\IntA_M$, we know that what it assigns to $\variable{s}$ must be a number from the universe of $\IntA_M$;
we also know from the way that we constructed the matrix model $\IntA_M$ that a number was included in the universe of $\IntA_M$ only if it was assigned to some constant that occurred in the derivation.  
Let what's assigned to $\variable{s}$ by some $\variable{s}$-variant, $\As{\variable{s}_2}{}$, be the number associated with the constant $\constant{c}$.
Because the universal statement $\universal{\ALPHA}\CAPPHI$ occurred in the derivation, we know that we took all instances of it, including $\CAPPHI\constant{c}/\ALPHA$. 
As already stated, all instances $\CAPPHI\variable{t}/\ALPHA$ are true in $\IntA_M$, including $\CAPPHI\constant{c}/\ALPHA$.
By the Dragnet Theorem (Thm. \pncmvref{The Dragnet Theorem}), since $\CAPPHI\constant{c}/\ALPHA$ is true in $\IntA_M$ it follows that $\CAPPHI\variable{s}/\ALPHA$ is true on $\As{\variable{s}_2}{}$. 
But the exact same argument works for every $\variable{s}$-variant of $\IntA_M$; so $\CAPPHI\variable{s}/\ALPHA$ is true on every $\variable{s}$-variant of $\IntA_M$. 
It follows that $\universal{\ALPHA}\CAPPHI$ is true on the matrix model $\IntA_M$. 
\end{description}

\item[Closure Step:]
Every sentence in the derivation is true in the matrix model $\IntA_M$, which is what was to be shown. 
\end{description}
\end{PROOF}

\subsection{Proving Completeness}
In\index{completeness!weak \GQD{}} this section we put together all the pieces from the last section to prove that \GQD{} is complete. 
\begin{THEOREM}{\LnpTC{MainGQDWCompletenessLemma} Main Weak \GQD{} Completeness Lemma:}
For all sentences $\CAPTHETA$ of \GQL{}, if the method is applied to $\negation{\CAPTHETA}$ then either: (a) the method produces a derivation of $\CAPTHETA$ in \GQDP{}, or (b) there is some model $\IntA$ that makes $\CAPTHETA$ false.
\end{THEOREM}
\begin{PROOF}
If the method is applied to $\negation{\CAPTHETA}$, then either (1) it produces a contradiction $\conjunction{\Al}{\negation{\Al}}$, (2) the method halts without a contradiction, or (3) the method never halts (and hence never halts in a contradiction). 
If (1), then by the Derivational Lemma (Thm. \pmvref{Derivational Lemma}) there is a derivation of $\CAPTHETA$. 

If either (2) or (3) is the case, then by the Method Lemma 3 (Thm. \pmvref{MethodLemmaC}) we know that all sentences in the derivation starting with $(\negation{\CAPTHETA})^*$, the prenex disjunctive normal form sentence produced in Step 0 of the method from the sentence $\negation{\CAPTHETA}$ on line 1, are true in the matrix model $\IntA_M$. 
Note that all the steps in the derivation of $(\negation{\CAPTHETA})^*$ from $\negation{\CAPTHETA}$ are sanctioned by exchange rules;
therefore those steps can be turned upside down to produce a derivation in \GQDP{} of $\negation{\CAPTHETA}$ from $(\negation{\CAPTHETA})^*$. 
So by theorem \mvref{GQD Shortcut Theorem3} there's a derivation in \GQD{} of $\negation{\CAPTHETA}$ from $(\negation{\CAPTHETA})^*$.
Since \GQD{} is sound (Thm. \pmvref{Soundness of Quantifier Logic}), it follows that $(\negation{\CAPTHETA})^*\sdtstile{}{}\;\negation{\CAPTHETA}$.
Since we know that $(\negation{\CAPTHETA})^*$ is true in the matrix model $\IntA_M$, it follows that $\negation{\CAPTHETA}$ is true in $\IntA_M$ too.
So it follows that $\CAPTHETA$ is false in $\IntA_M$. 
\end{PROOF}
\begin{THEOREM}{\LnpTC{GQDWeakCompletenessTheorem} Weak \GQD{} Completeness Theorem:}
For all sentences $\CAPTHETA$ of \GQL{}, if $\sdtstile{}{}\CAPTHETA$, then $\sststile{}{}\CAPTHETA$ in \GQD{}.
\end{THEOREM}
\begin{PROOF}
Assume that $\sdtstile{}{}\CAPTHETA$. Then there are no models $\IntA$ which makes $\CAPTHETA$ false. 
Thus, if the method is applied to $\negation{\CAPTHETA}$ it can't be that some model $\IntA$ makes $\CAPTHETA$ false. 
By the Main \GQD{} Weak Completeness Lemma (Thm. \ref{MainGQDWCompletenessLemma}), it follows that when the method is applied to $\negation{\CAPTHETA}$ it produces a derivation of $\CAPTHETA$ in \GQDP{}. 
Hence there is a derivation of $\CAPTHETA$ in \GQD{}.
\end{PROOF}
\begin{THEOREM}{\LnpTC{GQDCompletenessTheorem} \GQD{} Completeness Theorem:}
For all finite sets $\Delta$ of \GQL{} sentences and \GQL{} sentence $\CAPPHI$, if $\Delta\sdtstile{}{}\CAPPHI$, then $\Delta\sststile{}{}\CAPPHI$.
\end{THEOREM}
\begin{PROOF}
The theorem follows immediately from the Weak \GQD{} Completeness Theorem and theorem \mvref{RegWeakCompletenessEquiv}.
\end{PROOF}

A consequence of our Strong Method  is that if $\CAPPHI$ is  entailed by an infinite set of sentences $\Delta$, it is entailed by and derivable from  a finite subset of $\Delta$.  If the Strong Method does not go on forever, then we get a contradiction at a finite stage and we have only assumed a finite subset of $\Delta$.

\subsection{Shortcut Rules for the Method}
The method discussed in section \ref{The Method Section} becomes practically unwieldy.
For example, if the matrix has three disjuncts with two sentences each, then combining two instances gives 9 disjuncts with 4 elements each, and combining three gives 27 disjuncts with 8 elements each. 
Thus we use some additional short cut rules to speed the process of detecting contradictions. 
(But note that \emph{two} of the shortcut Rules we add here are not \emph{exchange} shortcut rules.  Greg's rule is the exception.)

Our first shortcut rule is \Rule{Greg's Rule}. We\index{Greg's Rule} know that if a conjunction contains an atomic formula and the negation of that atomic formula then we can derive the negation of the conjunction.
E.g., we can derive the negation of $\parconjunction{\Kp{\constant{a}}}{\conjunction{\Gp{\constant{b}}}{\conjunction{\Kp{\constant{c}}}{\negation{\Gp{\constant{b}}}}}}$.
So if we have a disjunction, one disjunct of which contains a contradiction of this kind, we can derive the negation of that disjunct and use disjunctive syllogism to prune that disjunct.
For example, assume the Method ends at the sentence $\disjunction{\parconjunction{\Kp{\constant{a}}}{\conjunction{\Gp{\constant{b}}}{\conjunction{\Kp{\constant{c}}}{\negation{\Gp{\constant{b}}}}}}}{\parconjunction{\Kp{\constant{a}}}{\conjunction{\Gp{\constant{b}}}{\conjunction{\Kp{\constant{c}}}{\negation{\Gp{\constant{a}}}}}}}$. We can independently derive $\negation{\parconjunction{\Kp{\constant{a}}}{\conjunction{\Gp{\constant{b}}}{\conjunction{\Kp{\constant{c}}}{\negation{\Gp{\constant{b}}}}}}}$. From these two we derive  $\parconjunction{\Kp{\constant{a}}}{\conjunction{\Gp{\constant{b}}}{\conjunction{\Kp{\constant{c}}}{\negation{\Gp{\constant{a}}}}}}$. 
Greg's Rule lets us accomplish those steps by crossing out the contradictory part and writing down the remaining ones.

It\index{$\VEE$/$\WEDGE$-Elim} is helpful to have a short cut rule which combines \Rule{$\WEDGE\!$-Elim} steps with \Rule{$\VEE$-Elim} steps to go from a disjunction of which each disjunct contains a particular sentence to that sentence itself on a later line;
we call it \Rule{$\VEE$/$\WEDGE\!$-Elim} and it sanctions the step from $\disjunction{\parconjunction{\Kp{\constant{a}}}{\conjunction{\Gp{\constant{b}}}{\conjunction{\Kp{\constant{c}}}{\negation{\Gp{\constant{c}}}}}}}{\parconjunction{\Kp{\constant{a}}}{\conjunction{\Gp{\constant{b}}}{\conjunction{\Kp{\constant{c}}}{\negation{\Gp{\constant{a}}}}}}}$ to $\Gp{\constant{b}}$. 
In addition to citing the justification, if the sentence is at all complex you should circle the repeated subsentence.

Finally,\index{One Bad Apple} given the opposite of even one conjunct in a conjunction, we can derive the negation of the conjunction.
E.g., from $\Gp{\constant{a}}$ we can derive $\negation{\parconjunction{\Kp{\constant{a}}}{\conjunction{\Gp{\constant{b}}}{\conjunction{\Kp{\constant{c}}}{\negation{\Gp{\constant{a}}}}}}}$.
We call this rule \Rule{One Bad Apple}, or \Rule{OBA}.
%\begin{table}[!ht]
%\renewcommand{\arraystretch}{1.5}
%\begin{center}
%\begin{tabular}{ p{1in} l l } %p{2.2in} p{2in}
%\toprule
%\textbf{Name} & \textbf{Given} & \textbf{May Add} \\ 
%\midrule
\renewcommand{\arraystretch}{1.5}
\begin{longtable}[c]{ p{1in} l l } %p{2.2in} p{2in}
\toprule
\textbf{Name} & \textbf{Given} & \textbf{May Add} \\ 
\midrule
\endfirsthead
\multicolumn{3}{c}{\emph{Continued from Previous Page}}\\
\toprule
\textbf{Name} & \textbf{Given} & \textbf{May Add} \\ 
\midrule
\endhead
\bottomrule
\caption{Short-Cut Rules for the Method}\\[-.15in]
\multicolumn{3}{c}{\emph{Continued next Page}}\\
\endfoot
\bottomrule
\caption{Short-Cut Rules for the Method}\\
\endlastfoot
\label{GSDplusMethod}\Rule{Greg's Rule} & $\disjunction{\CAPPSI_1}{\disjunction{\ldots}{\CAPPSI_{\integer{n}}}}$, where some & $\disjunction{\CAPPSI_1}{\disjunction{\ldots}{\disjunction{\CAPPSI_{\integer{i}-1}}{\disjunction{\CAPPSI_{\integer{i}+1}}{\disjunction{\ldots}{\CAPPSI_{\integer{n}}}}}}}$ \\[-.25cm]
 & $\CAPPSI_{\integer{i}}=\conjunction{\CAPPHI_1}{\conjunction{\ldots}{\conjunction{\CAPPHI_{\integer{j}}}{\ldots}}}$ & \\[-.25cm]
\nopagebreak
 & $\WEDGE\conjunction{\negation{\CAPPHI_{\integer{j}}}}{\conjunction{\ldots}{\CAPPHI_{\integer{m}}}}$ & \\
 
\Rule{$\VEE$/$\WEDGE\!$-Elim} & $\disjunction{\CAPPSI_{1}}{\disjunction{\ldots}{\CAPPSI_{\integer{n}}}}$, where & $\CAPPHI$ \\[-.25cm]
 & each $\CAPPSI_{\integer{i}}$ contains $\CAPPHI$ & \\
 
\Rule{OBA} &  $\conjunction{\CAPPHI_1}{\conjunction{\ldots}{\conjunction{\CAPPHI_i}{\conjunction{\ldots}{\CAPPHI_{\integer{n}}}}}}$, $\negation{\CAPPHI_i}$ & $\negation{\parconjunction{\CAPPHI_1}{\conjunction{\ldots}{\conjunction{\CAPPHI_i}{\conjunction{\ldots}{\CAPPHI_{\integer{n}}}}}}}$ \\
\nopagebreak
 & $\conjunction{\CAPPHI_1}{\conjunction{\ldots}{\conjunction{\negation{\CAPPHI_i}}{\conjunction{\ldots}{\CAPPHI_{\integer{n}}}}}}$, ${\CAPPHI_i}$ & $\negation{\parconjunction{\CAPPHI_1}{\conjunction{\ldots}{\conjunction{\negation{\CAPPHI_i}}{\conjunction{\ldots}{\CAPPHI_{\integer{n}}}}}}}$ \\
\end{longtable}
%\bottomrule
%\end{tabular}
%\end{center}
%\caption{Exchange Short-Cut Rules for \GSD{} (\GSDP{})}
%\label{GSDplus2}
%\end{table}

\section{Strong Completeness and Other Results}\label{Sec:Proving Strong Completeness}
In this section we want to extend our results and show that \GQD{} is strongly complete.
Note that the method we used to extend the Weak Completeness Theorem to the Completeness Theorem does not work here.
To do that, we used theorem \mvref{RegWeakCompletenessEquiv}, the proof of which depending on $\Delta$ being finite.  
To show that \GQD{} is strongly complete, we have modify the method we used to show that it's weakly complete.
\begin{THEOREM}{\LnpTC{GQDStrongCompletenessTheorem} Strong \GQD{} Completeness Theorem:}
For any set $\Delta$ of \GSL{} sentences and any \GSL{} sentence $\CAPPHI$, if $\Delta\sdtstile{}{}\CAPPHI$, then $\Delta\sststile{}{}\CAPPHI$.
\end{THEOREM}
\noindent{}To show that \GQD{} is weakly complete, we gave a method that, given a sentence $\CAPTHETA$, either produces a derivation of $\CAPTHETA$ or produces a model $\IntA$ which makes $\CAPTHETA$ false. 
To show that \GQD{} is strongly complete, what we want is a method that, given a (possibly infinite) set $\Delta$ of sentences and another sentence $\CAPPHI$, either produces a derivation of a contradiction $\conjunction{\Al}{\negation{\Al}}$ from $\negation{\CAPPHI}$ and some finite subset of $\Delta$ or produces a model $\IntA$ that makes $\negation{\CAPPHI}$ and every sentence in $\Delta$ true.

The method we'll give is a modification of the original method given in section \ref{The Method Section}. 
Since it is just a modification of the the original method, we'll only sketch the changes needed. 
We'll call the modified method the \niidf{strong method}\index{strong method, the}\index{method, the!strong}. 
Given some possibly countably infinite set $\Delta$ and sentence $\CAPPHI$, the strong method is:
\begin{description}
\item[Step 1:] Let $\Delta^*=\Delta\cup\{\negation{\CAPPHI}\}$. 
Then pair each sentence of $\Delta^*$ with a natural number and use that to determine the order in which they are assumed. 
The only constraint on this ordering is that $\negation{\CAPPHI}$ should be first.

\item[Step 2:] Put the first sentence of $\Delta^*$ on line 1 and put it in \CAPS{pdnf}, just as was done in Step 0 of the method.

\item[Step 3:] Apply Step 1 of the method.

\item[Step 4:] Apply Steps 2 and 3 of the method to the whole derivation thus far.

\item[Step 5:] Check for contradictions, just as in Step 4 of the method.

\item[Step 6:] \hfill
\begin{cenumerate}
\item If there's a contradiction, stop.
\item If there's no contradiction, write the next sentence of $\Delta^*$ on the next line of the derivation, put that sentence in \CAPS{pdnf}, and go back into Step 4. 
\end{cenumerate}
\end{description}
The strong method either halts in a contradiction, or it does not. 
\begin{THEOREM}{\LnpTC{DerivationalLemmaS} Strong Derivational Lemma:}
If the strong method halts in a contradiction, then $\Delta\sststile{}{}\CAPPHI$.
\end{THEOREM}
\begin{PROOF}
If the strong method halts in a contradiction, then it has produced a derivation of a contradiction $\conjunction{\Al}{\negation{\Al}}$ from $\negation{\CAPPHI}$ and some subset $\Delta'$ of $\Delta$.  We want to show that $\Delta\sststile{}{}\CAPPHI$; to do this, we first want to show that $\Delta'\sststile{}{}\CAPPHI$.

We might think we already know that $\negation{\CAPPHI},\Delta'\sststile{}{}\conjunction{\Al}{\negation{\Al}}$, but in fact, there are additional open assumptions that we made; the Strong Method tells us to make an additional assumption for each line containing an existentially quantified sentence. For these lines, we assume an instance of the existentially quantified sentence.  We want to discharge these assumptions by using \Rule{$\exists$-Elim}, but these assumptions may come prior to some of the assumptions we made from $\Delta'$.  We want to keep the sentences of $\Delta'$ as assumptions, because the contradiction we reached depends on them. 

We can discharge the assumed instances of existentially quantified sentences only by additionally discharging all the assumptions that come later in the derivation.  Accordingly, we want to extend our derivation so that we discharge \emph{all} our assumptions and then repeat all the assumptions \emph{except} for the instances of existentially quantified sentences. 

Let $\CAPTHETA_1, \CAPTHETA_2, \CAPTHETA_3, \ldots, \CAPTHETA_{\integer{n}}$ be the sentences of $\Delta'$ assumed in our derivation.  The last open assumption is either (a) the last sentence of $\Delta'$, i.e., $\CAPTHETA_{\integer{n}}$; (b) an instance of an existentially quantified sentence on an earlier line of the derivation which we'll call $\CAPPSI$; or (c) $\negation{\CAPPHI}$.  If (a) is the case, then discharge the assumption by applying the rule \Rule{$\HORSESHOE$-Intro} to get $\horseshoe{\CAPTHETA_{\integer{n}}}{\parconjunction{\Al}{\negation{\Al}}}$.  If (b) is the case, then first apply \Rule{$\HORSESHOE$-Intro} to get $\horseshoe{\CAPPSI}{\parconjunction{\Al}{\negation{\Al}}}$, and then apply \Rule{$\exists$-Elim} to get $\conjunction{\Al}{\negation{\Al}}$.  When (b) is the case, we know that the assumption introduced a \emph{new} constant, and therefore we know that that constant did not appear in any earlier assumption or in the existential of which we are taking an instance.
It also (obviously) does not occur in $\conjunction{\Al}{\negation{\Al}}$.
Thus the \Rule{$\exists$-Elim} step is legitimate. If (c) is the case then we don't have to worry about instances of existentially quantified sentences, and we can skip this part of the process.  Let us disregard case (c) for now.

Now we must continue to discharge the rest of the assumptions.  For any assumption of an instance of an existentially quantified sentence, we may do the same thing we did in (b) above---first use \Rule{$\HORSESHOE$-Intro} to derive a conditional, and then use \Rule{$\exists$-Elim} to derive the RHS of that conditional.  For any assumption that is a sentence of $\Delta'$ (i.e., $\CAPTHETA_{\integer{i}}$), we use \Rule{$\HORSESHOE$-Intro} to derive a conditional, as in (a) above.  So, after discharging the assumption with the second to last sentence from $\Delta'$ we get $\horseshoe{\CAPTHETA_{\integer{n-1}}}{\parhorseshoe{\CAPTHETA_{\integer{n}}}{\parconjunction{\Al}{\negation{\Al}}}}$.  After the third instance, we derive $\horseshoe{\CAPTHETA_{\integer{n-2}}}{\parhorseshoe{\CAPTHETA_{\integer{n-1}}}{\parhorseshoe{\CAPTHETA_{\integer{n}}}{\parconjunction{\Al}{\negation{\Al}}}}}$.  And so on, so that we eventually get a sentence of the form $\horseshoe{\CAPTHETA_1}{\parhorseshoe{\CAPTHETA_2}{\parhorseshoe{\CAPTHETA_3}{\ldots \parhorseshoe{\CAPTHETA_{\integer{n}}}{\parconjunction{\Al}{\negation{\Al}}}}}}$.

After discharging all such assumptions, the only open assumption left is $\negation{\CAPPHI}$.  Apply \Rule{$\HORSESHOE$-Intro} once more to get something like the following: \\
$\horseshoe{\negation{\CAPPHI}}{\parhorseshoe{\CAPTHETA_1}{\parhorseshoe{\CAPTHETA_2}{\ldots \parhorseshoe{\CAPTHETA_{\integer{n}}}{\parconjunction{\Al}{\negation{\Al}}}}}}$.  Now we have no open assumptions remaining.  (Note that we have effectively covered case (c) above, since applying \Rule{$\HORSESHOE$-Intro} in this case would give us $\horseshoe{\negation{\CAPPHI}}{\parconjunction{\Al}{\negation{\Al}}}$ and no open assumptions.  In this case, we didn't have to assume any of the sentences of $\Delta$ to get a contradiction, so $\Delta'$ is the empty set.)

At this point we have a conditional, possibly a very long one.  The RHS of the last conditional (possibly embedded in several conditionals) is our contradiction, $\parconjunction{\Al}{\negation{\Al}}$.  We want to show that $\Delta'\sststile{}{}\CAPPHI$, so let us make a series of assumptions from the sentences of $\Delta'$.  That is, let us assume each of $\CAPTHETA_1, \CAPTHETA_2, \CAPTHETA_3, \ldots, \CAPTHETA_{\integer{n}}$.  Now that we've assumed all the sentences of $\Delta'$, let us assume $\negation{\CAPPHI}$.

Given our earlier conditional of the form $\horseshoe{\negation{\CAPPHI}}{\parhorseshoe{\CAPTHETA_1}{\parhorseshoe{\CAPTHETA_2}{\ldots, \parhorseshoe{\CAPTHETA_{\integer{n}}}{\parconjunction{\Al}{\negation{\Al}}}}}}$ and the assumption $\negation{\CAPPHI}$, we may now apply \Rule{$\HORSESHOE$-Elim} to get \\
$\horseshoe{\CAPTHETA_1}{\parhorseshoe{\CAPTHETA_2}{\parhorseshoe{\CAPTHETA_3}{\ldots, \parhorseshoe{\CAPTHETA_{\integer{n}}}{\parconjunction{\Al}{\negation{\Al}}}}}}$.  Because we also have all the sentences of $\Delta'$ as assumptions (i.e., all of $\CAPTHETA_1, \CAPTHETA_2, \CAPTHETA_3, \ldots, \CAPTHETA_{\integer{n}}$), we may apply a series of \Rule{$\HORSESHOE$-Elim} steps until we eventually derive $\conjunction{\Al}{\negation{\Al}}$.  That is, given our earlier assumption $\CAPTHETA_1$ and the conditional $\horseshoe{\CAPTHETA_1}{\parhorseshoe{\CAPTHETA_2}{\parhorseshoe{\CAPTHETA_3}{\ldots, \parhorseshoe{\CAPTHETA_{\integer{n}}}{\parconjunction{\Al}{\negation{\Al}}}}}}$, we may apply \Rule{$\HORSESHOE$-Elim} to derive $\horseshoe{\CAPTHETA_2}{\parhorseshoe{\CAPTHETA_3}{\ldots, \parhorseshoe{\CAPTHETA_{\integer{n}}}{\parconjunction{\Al}{\negation{\Al}}}}}$.  And then because we have $\CAPTHETA_2$ as an assumption we may again apply \Rule{$\HORSESHOE$-Elim} to get $\horseshoe{\CAPTHETA_3}{\ldots, \parhorseshoe{\CAPTHETA_{\integer{n}}}{\parconjunction{\Al}{\negation{\Al}}}}$.  And so on, until we derive $\conjunction{\Al}{\negation{\Al}}$.

Remember that our last open assumption is $\negation{\CAPPHI}$.  We may now discharge that assumption and apply \Rule{$\HORSESHOE$-Intro} to get $\horseshoe{\negation{\CAPPHI}}{\parconjunction{\Al}{\negation{\Al}}}$.  Then we apply \Rule{$\NEGATION$-Elim} to derive $\CAPPHI$.

Now we have as our open assumptions only the sentences of $\Delta'$ and we have derived $\CAPPHI$.  We have thus shown that $\Delta'\sststile{}{}\CAPPHI$.  And because $\Delta'$ is a subset of $\Delta$, it follows that $\Delta\sststile{}{}\CAPPHI$.
\end{PROOF}
\noindent{}Next, note that if the strong method doesn't halt in a contradiction, then we have a list of matrix instances from which we can construct a matrix model $\IntA_M$ in just the same way we did for the method (Def. \pmvref{MatrixModel}).
Similar to the method, we have the following three theorems.
\begin{THEOREM}{\LnpTC{MethodSLemmaA} The Strong Method Lemma 1:}
The matrix model $\IntA_M$ makes true all sentences on the master matrix list $M$.
\end{THEOREM}
\begin{PROOF}
The same proof used for the method (Thm. \pmvref{MethodLemmaA}) applies here too.
\end{PROOF}
\begin{THEOREM}{\LnpTC{MethodSLemmaB} The Strong Method Lemma 2:}
All matrix instances in the derivation are true in the matrix model $\IntA_M$.
\end{THEOREM}
\begin{PROOF}
The same proof used for the method (Thm. \pmvref{MethodLemmaB}) applies here too.
\end{PROOF}
\begin{THEOREM}{\LnpTC{MethodSLemmaC} The Strong Method Lemma 3:}
All quantified sentences in the derivation are true in the matrix model $\IntA_M$.
\end{THEOREM}
\begin{PROOF}
The same proof used for the method (Thm. \pmvref{MethodLemmaC}) applies here too, so long as we can show that if an existential $\existential{\ALPHA}\CAPPSI$ appears on a line, at least one instance $\CAPPSI\variable{t}/\ALPHA$ does, and if a universal $\universal{\ALPHA}\CAPPSI$ appears on a line, then every instance $\CAPPSI\variable{t}/\ALPHA$ of it with a constant $\variable{t}$ appearing somewhere in the derivation appears somewhere in the derivation. So, all we need to show is that the strong method derives the appropriate instances of all quantified sentences that appear in our derivation. Let $\Delta'$ be those sentences of $\Delta^*$ that appear in our derivation as a result of the application of the strong method.

\begin{description}
\item[Existential Quantifier:] 
Say $\CAPTHETA$ is some sentence in the derivation of the form $\existential{\ALPHA}\CAPPHI$. 
Step 4 of the strong method uses step 3 of the method on $\CAPTHETA$, which guarantees that the sentence $\CAPPHI\variable{t}/\ALPHA$, for some constant $\variable{t}$, appears somewhere in the derivation.
By hypothesis, step 4 of the strong method is applied to all sentences in $\Delta'$, so we know that it derives the appropriate instances of all existentially quantified statements in in $\Delta'$.

\item[Universal Quantifier:]
Say $\CAPTHETA$ is a sentence appearing in the derivation of the form $\universal{\ALPHA}\CAPPHI$. 
Step 4 of the strong method uses step 2 of the method on $\CAPTHETA$, which, for every constant $\variable{t}$ in the derivation, guarantees that the sentence $\CAPPHI\variable{t}/\ALPHA$ is derived.
By hypothesis, step 4 of the strong method is applied to all sentences in $\Delta'$, so we know that it derives the appropriate instances of all universally quantified statements in $\Delta'$.
\end{description}

\noindent{}So, the strong method derives the appropriate instances of all quantified sentences in $\Delta'$.

%(Why? assume not. Then say that universal is PHI and that constant is b. Since the derivation is never ending, there must have been a pass of steps 1 and 2 that comes after both the pass that introduced b and the pass that introduced PHI. So contra assumption, this pass put that instance of PHI in the sequence.).
\end{PROOF}
\noindent{}Finally, we have one last lemma:
\begin{THEOREM}{\LnpTC{MainGQDSCompletenessLemma} Main Strong \GQD{} Completeness Lemma:}
For all sets of \GQL{} sentences $\Delta$ and \GQL{} sentences $\CAPPHI$, if the strong method is applied to $\Delta^*=\Delta\cup\{\negation{\CAPPHI}\}$ then either: (a) the strong method produces a derivation of $\CAPPHI$ from $\Delta$ in \GQDP{}, or (b) there is a model $\IntA$ which makes every sentence in $\Delta$ true and $\CAPPHI$ false.
\end{THEOREM}
\begin{PROOF}
If the method is applied to $\Delta^*=\Delta\cup\{\negation{\CAPPHI}\}$, then either it halts in a contradiction or not. 
By the Strong Derivational Lemma (\pmvref{DerivationalLemmaS}), if the strong method halts in a contradiction, then $\Delta\sststile{}{}\CAPPHI$ in \GQDP{}.

If the method does not halt in a contradiction, then by the Strong Method Lemma 3 (Thm. \pmvref{MethodSLemmaC}) the matrix model $\IntA_M$  makes all the sentences in the derivation true. 
But since the strong method did not halt in a contradiction, for every sentence $\CAPPSI$ in $\Delta$ and $\negation{\CAPPHI}$, there's some sentence in \CAPS{pdnf} that's quantificationally equivalent to $\CAPPSI$ and appears in the derivation. 
So $\IntA_M$ makes all the sentences in $\Delta$ and the sentence $\negation{\CAPPHI}$ true; 
hence $\IntA_M$ makes all the sentences in $\Delta$ true and $\CAPPHI$ false. 
\end{PROOF}
\begin{PROOFOF}{Thm. \ref{GQDStrongCompletenessTheorem}, The Strong Completeness Theorem for GQD}
Assume that $\Delta\sdtstile{}{}\CAPPHI$. 
Then there can be no model $\IntA$ which makes all of the sentences in $\Delta$ true and $\CAPPHI$ false;
so, application of the method can't produce such a model.
Thus by the Main \GQD{} Strong Completeness Lemma (Thm. \ref{MainGQDSCompletenessLemma}), $\Delta\sststile{}{}\CAPPHI$ in \GQDP{}. 
It follows by theorem \mvref{GQD Shortcut Theorem3} that $\Delta\sststile{}{}\CAPPHI$ in \GQD{}.
\end{PROOFOF}

Our Method for proving completeness for QD is short of being a decision procedure.  If $\CAPPHI$ is a logical truth, then The Method produces a derivation of it.  And if $\CAPPHI$ is not a logical truth, then in many cases it produces a model that makes $\CAPPHI$ false.  But sometimes it just doesn't stop.  We know that if it doesn't stop there is a model that makes the original sentence false, but at each stage we may not know whether it stops (soon?) or not.   And we know that it can't stop at a finite stage for some sentences because those sentences are only false in an infinite model.

All we know from our work so far is that The Method works as described above. We don't know that there isn't a better method that provides a decision procedure.  Church's Theorem, proved by more advanced methods that involve clarifying what counts as a ``method'' or ``algorithm'' tells us that our result is as good as we can do for all of \GQL{}.

However, we can do better for the language \GQL{}1 and a little more.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Decidability and Church's Theorem}\label{Decidability and Churchs Theorem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Next\index{decidable}\index{undecidable} we turn to refinements of the method to obtain what are called \niidf{decision procedures} for logical truth in a language \Language{L}. %\index{decision procedure}
We first introduced the idea of a decision procedure in section \mvref{Section:Intro to Decidability}; here we shall fill things out a bit further. 
\begin{majorILnc}{\LnpDC{Def:DecisionProcedure}}
A \df{decision procedure} for logical truth in a language (or sublanguage) \Language{L} is a completely specified method which produces, for any sentence $\CAPPHI$ of \Language{L} and in a finite number of steps, the answer YES if $\CAPPHI$ is a logical truth and the answer NO otherwise.
\end{majorILnc}
\begin{majorILnc}{\LnpEC{TruthTableDecisionProcedure}}
We have already seen two decision procedures for \CAPS{tft} in \GSL{}: truth tables and the method discussed in the completeness proof of \GSD{}. 
(Others include truth trees and Quine's ``fell swoop'', \citealt{Quine1950}, \citealt[23]{Hodges2001}.)
The truth-table decision procedure is simple:\index{decision procedure!truth table} take a sentence $\CAPPHI$ of \GSL{} and construct a truth table for it. If you get all $\TrueB{}$ in the column under $\CAPPHI$; answer YES. If you don't, answer NO. 
Likewise for the method discussed in the completeness proof of \GSD{}:\index{decision procedure!for \CAPS{tft} in \GSL{}} take a sentence $\CAPPHI$, negate it to get $\negation{\CAPPHI}$, and apply the method. 
If it results in a contradiction $\conjunction{\Al}{\negation{\Al}}$, answer YES. 
If no contradiction is reached, answer NO. 
\end{majorILnc}
\noindent{}Our method of proving completeness for \GQD{} is a little short of being a decision procedure for quantificational truth in \GQL{} because it does not always produce an answer in a finite amount of time.
It can be shown that there is no decision procedure for the whole language \GQL{} \citetext{\citealp[83--86]{Hodges2001}, \citeyear[31]{Hodges2001b}, \citealp[486]{Bergmann2003}}.
\begin{THEOREM}{\LnpTC{ChurchsTheorem} Church's Theorem:}
If\index{Church's Theorem}\index{decision procedure!for \CAPS{qt} in \GQL{}|see{Church's Theorem}} \Language{L} is a sublanguage of \GQL{} with (1) the same logical connectives as \GQL{}, and (2) at least one 2-place predicate symbol, then there is no decision procedure for the set of logical truths of \Language{L}.\footnote{Actually, 
Church's Theorem also says that if we also consider languages with function symbols, then if \Language{L} has at least two 1-place function symbols there is no decision procedure for the set of logical truths of \Language{L}.}
\end{THEOREM}
Church's Theorem at once tells us that there is no decision procedure for quantificational truth in \GQL{}, but we can show that with some modifications our method from section \ref{The Method Section} can be turned into a decision procedure for certain sublanguages of \GQL{}. 
As the theorem suggests, one such sublanguage of \GQL{} consists of just 1-place predicate symbols. 
We've been calling this language \GQL{}1.\index{decision procedure!for \CAPS{qt} in monadic \GQL{}}\index{GQL!monadic}

Let's modify the method to prove that \GQL{}1 has a decision procedure.
The problem with the existing method is that infinite loops are created by having an existential quantifier inside a universal quantifier.
The existential requires a new constant to be instantiated, and that creates a new potential instance for the universal, which then creates a new existential, and so on.
We want a procedure that is guaranteed to halt.

If the method produces a sentence in standardized form which has only existential, or only universal quantifiers, then the method stops. 
Moreover, if in the standardized form the existentials all precede the universals the method also stops, for we first take instances of all the existentials using $\integer{n}$ constants if there are $\integer{n}$ existentials, and afterwards we instantiate the $\integer{n}$ new constants in the $\integer{m}$ universals giving $\integer{n}^\integer{m}$ instances.
We are done then, since no additional constants are added.

But what about sentences with an existential quantifier within the scope of a universal quantifier, e.g. $\universal{\variable{x}}\existential{\variable{y}}\pardisjunction{\parconjunction{\Bp{\variable{x}}}{\Cp{\variable{y}}}}{\parconjunction{\Dp{\variable{x}}}{\Gp{\variable{y}}}}$?
Since \GQL{} has many-place predicates, if one quantifier occurs within the scope of another then it often cannot be moved in front of the other quantifier. 
But since the predicates of \GQL{}1 are 1-place there is a procedure to switch quantifier order in all cases.
It takes some work to establish this result.

\begin{majorILnc}{\LnpDC{Independent}}
Two quantifiers are \df{independent}\index{quantifier!s, independent} \Iff neither is in the scope of the other.
\end{majorILnc}

Let's say we have a sentence all of whose quantifiers are independent of each other.
Then these quantifiers can be brought forward in any order, and so we have a decision procedure for such sentences. 
We claim that each \GQL{}1 sentence is equivalent to one whose quantifiers are all independent.
To simplify the proof for this we introduce some additional exchange rules.

\subsection{Additonal Exchange Rules}\label{Additonal Exchange Rules}

Our aim is to move the quantifiers of a \GQL{}1 sentence so that all are independent.
To simplify this task we introduce new quantifier exchange rules, as well as some rules that permit rearranging the order of conjunctions and disjunctions.
These rules allow us to provide a procedure to push each quantifier in far enough so that the scope of each covers the variables it binds and no others.

\renewcommand{\arraystretch}{1.5}
\begin{longtable}[c]{ p{1in} l l } %p{2.2in} p{2in}
\toprule
\textbf{Name} & \textbf{Given} & \textbf{May Add} \\ 
\midrule
\endfirsthead
\multicolumn{3}{c}{\emph{Continued from Previous Page}}\\
\toprule
\textbf{Name} & \textbf{Given} & \textbf{May Add} \\ 
\midrule
\endhead
\bottomrule
\caption{Additonal Exchange Rules for \GQD{}}\\[-.15in]
\multicolumn{3}{c}{\emph{Continued next Page}}\\
\endfoot
\bottomrule
\caption{Additonal Exchange Rules for \GQD{}}\\
\endlastfoot
\label{AdditionalQuantifierExRules}\Rule{$\universal$-Shuffle} & $\universal\variable{\alpha}\parconjunction{\CAPPHI_1}{\conjunction{\ldots}{\CAPPHI_n}}$ & $\conjunction{\universal\variable{\alpha}\CAPPHI_1}{\conjunction{\ldots}{\universal\variable{\alpha}\CAPPHI_n}}$ \\
\Rule{$\existential$-Shuffle} & $\existential\variable{\alpha}\pardisjunction{\CAPPHI_1}{\disjunction{\ldots}{\CAPPHI_n}}$ & $\par\disjunction{\existential\variable{\alpha}\CAPPHI_1}{\disjunction{\ldots}{\existential\variable{\alpha}\CAPPHI_n}}$ \\
\Rule{Q-Deletion} & $\#\variable{\alpha}\CAPPHI$ & $\CAPPHI$, iff $\alpha$ does  \\[-.25cm]
\nopagebreak
 &  &  not occur in $\CAPPHI$  \\
\Rule{$\wedge$-Shuffle} & $\conjunction{\CAPPHI_1}{\conjunction{\ldots}{\conjunction{\CAPPHI_k}{\conjunction{\ldots}{\CAPPHI_n}}}}$ & $\conjunction{\CAPPHI_k}{\conjunction{\CAPPHI_1}{\conjunction{\ldots}{\CAPPHI_n}}}$ \\
\Rule{$\vee$-Shuffle} & $\disjunction{\CAPPHI_1}{\disjunction{\ldots}{\disjunction{\CAPPHI_k}{\disjunction{\ldots}{\CAPPHI_n}}}}$ & $\disjunction{\CAPPHI_k}{\disjunction{\CAPPHI_1}{\disjunction{\ldots}{\CAPPHI_n}}}$ \\
\end{longtable}

It is left as an exercise for the reader to prove that these rules are sound.
Note that $\universal$-Shuffle is only sound when the universal quantifier is moved over a conjunction, and $\existential$-Shuffle is only sound when moved over a disjunction.
For example, the sentence $\universal\variable{x}\pardisjunction{\Bp{\variable{x}}}{\negation{\Bp{\variable{x}}}}$ is a logical truth but $\disjunction{\universal\variable{x}\Bp{\variable{x}}}{\universal\variable{x}\negation{\Bp{\variable{x}}}}$ isn't.
Similarly, $\negation{\existential\variable{x}\parconjunction{\Bp{\variable{x}}}{\negation{\Bp{\variable{x}}}}}$ is a logical truth but $\negation{\parconjunction{\existential\variable{x}\Bp{\variable{x}}}{\existential\variable{x}\negation{\Bp{\variable{x}}}}}$ isn't.

These rules enable us to push the quantifiers all the way into a suffiently well-behaved sentence.
To push universal quantifiers inward over conjunctions, we use \Rule{$\universal$-Shuffle}.
To push exstential quantifiers inward over disjunctions, we use \Rule{$\existential$-Shuffle}.
In cases when the universal quantifer governs a disjunction we must isolate the disjuncts with a matching variable, using \Rule{$\vee$-Shuffle} to move those disjuncts to the left.
Then we use Q shuffle to move the quantifier to just those disjuncts.
Similarly, when an existential quantifier governs a conjunction, we isolate the conjuncts with a matching variable, using \Rule{$\wedge$-Shuffle} to move those conjuncts to the left.
Then we use Q shuffle to move the quantifier to just those conjuncts.

\subsection{The QL1 Decision Procedure}\label{The QL1 Decision Procedure}

\begin{THEOREM}{\LnpTC{MonadicGQLEquivTheorem} \GQL{}1 Independent Quantifiers Theorem:}
Every sentence of \GQL{}1 is quantificationally equivalent to a sentence whose quantifiers are independent.
\end{THEOREM}
\begin{PROOF}
\begin{commentary}
	The basic strategy to prove this theorem is relatively straightforward even if some of the details aren't.
	\commentaryspace
	First, we start with a \GQL{}1 sentence and get its PDNF equivalent. 
	All the quantifiers are in the initial position of the latter sentence.
	Then we push each quantifier inward, using the new quantifier exchange rules, to shrink its scope.
	We show that after the quantifiers are pushed in they are all independent.
\end{commentary}
Let there be a sentence of \GQL{}1.
Then by theorem \ref{PrenexNFTheorem} there is an equivalent sentence, $\CAPPHI$, that is in prenex disjunctive normal form.
So $\CAPPHI$ is of the form $\#_1\#_2\ldots\#_n\CAPPHI'$, where for each $i\in\{1,\ldots,n\}$, $\#_i$ is a quantifier, and $\CAPPHI'$ is a DNF formula.
Then $\CAPPHI'$ is of the form $\pardisjunction{\disjunction{\CAPPSI_1}{\CAPPSI_2}}{\disjunction{\ldots}{\CAPPSI_k}}$, where for each $j\in\{1,\ldots,k\}$, $\CAPPSI_j$ is a conjunction of ions.

Let $\CAPPHI_{n+1}$ be $\CAPPHI'$, i.e., the DNF body of $\CAPPHI$.
To make the quantifiers independent of each other, each quantifier must be pushed in to govern the variables it binds and no others.
We start with $\#_n$, pushing the quantifier in, and work backward in sequence to $\#_1$.
The formula we start with, $\CAPPHI_{n+1}$, is transformed $n$ times, once for each of the $n$ quantifiers.
Let $\#_i$ be the the $i^{\text{th}}$ quantifier of the sequence in $\CAPPHI$, $\#_1\#_2\ldots\#_n$.
Then let $\CAPPHI_i$ for each $i\in\{1,\ldots,n\}$ be the result of having pushed in the $i^{\text{th}}$ quantifier, $\#_i$, into the formula $\CAPPHI_{i+1}$.
The final product of all these transformations is $\CAPPHI_{1}$, at which point all the quantifiers are moved in.
Each transformation uses exchange rules only, so $\CAPPHI_{1}$ is equivalent to $\CAPPHI$.

The following steps define the transformation to push in each quantifier, starting with $\#_n$ and working back to $\#_1$.
For each quantifer $\#_i$ to move there are two cases, handled separately:

\vspace*{0.15in}
\noindent{}\textbf{Case 1}: $\#_i$ is an existential quantifier.
\begin{commentary}
	To push an existential quantifier in is easier, since the body of the formula is a disjunction.
	We push it in using \Rule{$\existential$-Shuffle} so that each disjunct is governed by an existential quantifer.
	Then, for each disjunct, we reorder the conjuncts using \Rule{$\wedge$-Shuffle} to isolate the conjuncts with a matching variable, and use Q shuffle to move the quantifier to govern just those.
\end{commentary}

\begin{quote}
\begin{description}
\item[Step A:] By $\existential$-shuffle, $\#_i$ is moved to each disjunct in $\CAPPHI_{i+1}$, resulting in: $\pardisjunction{\disjunction{\#_i\CAPPSI_1}{\#_i\CAPPSI_2}}{\disjunction{\ldots}{\#_i\CAPPSI_k}}$. For any $\CAPPSI_j$ not containing the variable in $\#_i$, $\#_i$ may be removed from that disjunct, by Q-deletion.
\item[Step B:] Each disjunct with a quantifier $\#_i\CAPPSI_j$ is of the form \\ $\#_i\parconjunction{\conjunction{\CAPTHETA_1}{\CAPTHETA_2}}{\conjunction{\ldots}{\CAPTHETA_m}}$ where each $\CAPTHETA$ is an ion (or a quantified subsentence governing a conjunction or disjunction, as will be made clear shortly). An equivalent conjunction is obtained by applying \Rule{$\wedge$-shuffle} so that each $\CAPTHETA$ with a variable matching that of $\#_i$ is moved to the left.
\item[Step C:] By the Q shuffle exchange rule, the $\#_i$ is moved in to govern just the leftmost conjuncts with a matching variable, resulting in each $\#_i\CAPPSI_j$ becoming: $\conjunction{\#_i\parconjunction{\CAPTHETA_1}{\CAPTHETA_2}}{\conjunction{\ldots}{\CAPTHETA_m}}$. With this transformation $\#_i$ binds all variables within its scope, and no other variables are in its scope.
\end{description}
\noindent{}The result is a formula $\CAPPHI_{i}$ where $\#_i$ binds all and only its variables.
\end{quote}

\noindent{}\textbf{Case 2}: $\#_i$ is a universal quantifier.
\begin{commentary}
	To push a universal quantifier in, the distribution exchange rule is first used to make the body of the sentence a conjunction.
	Then we push the universal in using \Rule{$\universal$-Shuffle} so that each conjunct is governed by a universal quantifer.
	Then, for each conjunct, we reorder the disjuncts using \Rule{$\vee$-Shuffle} to isolate the disjuncts with a matching variable, and use Q shuffle to move the quantifier to govern just those.
	After the quantifier is moved in, the distribution exchange rule is applied again to make the body of the sentence a disjunction again.
\end{commentary}

\begin{quote}
\begin{description}
\item[Step A:] Apply the distribution rule to $\CAPPHI_{i+1}$ until no conjunction is governed by a disjunction (with the exception of any conjunction within the scope of an already moved quantifier). The resulting formula, $\CAPPHI_{i+1}^*$, is a conjunction.
\item[Step B:] By $\universal$-shuffle, $\#_i$ is moved to each conjunct in $\CAPPHI_{i+1}^*$, resulting in: $\parconjunction{\conjunction{\#_i\CAPPSI_1}{\#_i\CAPPSI_2}}{\conjunction{\ldots}{\#_i\CAPPSI_k}}$. For any $\CAPPSI_j$ not containing the variable bound by $\#_i$, the quantifier may be removed, by Q-deletion.
\item[Step C:] Each conjunct with a quantifier $\#_i\CAPPSI_j$ is of the form \\ $\#_i\pardisjunction{\disjunction{\CAPTHETA_1}{\CAPTHETA_2}}{\disjunction{\ldots}{\CAPTHETA_m}}$ where each $\CAPTHETA$ is an ion (or a quantifier subsentence governing a disjunction or conjunction). An equivalent disjunction is obtained by by applying \Rule{$\vee$-shuffle} so that each $\CAPTHETA$ with a variable matching that of $\#_i$ is moved to the left.
\item[Step D:] By the Q shuffle exchange rule, the $\#_i$ is moved in to govern just the leftmost disjuncts with a matching variable, resulting in $\#_i\CAPPSI_j$ becoming: $\disjunction{\#_i\pardisjunction{\CAPTHETA_1}{\CAPTHETA_2}}{\disjunction{\ldots}{\CAPTHETA_m}}$. With this transformation $\#_i$ binds all variables within its scope, and no other variables are in its scope.
\item[Step E:] Apply the distribution rule to the resulting formula until no disjunction is governed by a conjunction (with the exception of any disjunction within the scope of an already moved quantifier).
\end{description}
\noindent{}The result is a formula $\CAPPHI_{i}$ where $\#_i$ binds all and only its variables.
\end{quote}

\noindent{}The result of these $n$ transformation is a \GQL{}1 sentence $\CAPPHI_{1}$ with each moved quantifier governing all and only the variables it binds.
Therefore the quantifiers of $\CAPPHI_{1}$ are all independent.
\end{PROOF}

\begin{THEOREM}{\LnpTC{MonadicDecisionTheorem} The \GQL{}1 Decision Theorem:}
\end{THEOREM}
\begin{PROOF}
Let\index{Monadic Decision Theorem, The} $\CAPPHI$ be a \GQL{}1 sentence.
Then by theorem \ref{MonadicGQLEquivTheorem} there is an equivalent sentence $\CAPPHI^*$ such that all its quantifiers are independent.
Use Q-shuffle to move the existential quantifers to the prenex position, and then move the universal quantifiers as well, resulting in an equivalent sentence $\CAPPHI^{**}$.
Then put the body of $\CAPPHI^{**}$ into DNF, resulting in $\CAPPHI^{***}$.
$\CAPPHI^{***}$ is in PDNF.
So for the reasons described previously, the method is guaranteed to halt on $\CAPPHI^{***}$.
Therefore there is a decision procedure for $\CAPPHI^{***}$, and hence also for $\CAPPHI$.
\end{PROOF}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{L\"owenheim-Skolem and Compactness}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

A number of results follow directly from the completeness of \GQD{} or the method we used to prove completeness. 
\begin{THEOREM}{\LnpTC{LowenheimSkolemTheorem} The Downward L\"owenheim-Skolem Theorem:}
If a sentence of \GQL{} is true in any model, then it is true in one whose domain consists of all or some of the natural numbers.
\end{THEOREM}
\begin{PROOF}
If $\CAPPHI$ is true in some model, then $\negation{\CAPPHI}$ is not a quantificational truth.
Thus, applying the method to $\negation{\CAPPHI}$ does not produce a contradiction, but produces a model of the natural numbers which falsifies $\negation{\CAPPHI}$ and hence makes $\CAPPHI$ true.
\end{PROOF}
It's important to note that there's really nothing special about the natural numbers.
When we devised the procedure for constructing a model of the ions in the master matrix list that results from the method (when no contradiction arises), we choose to use natural numbers for the universe. 
But it should be clear that we did this out of convenience (it's easy, after all, to associate constants with the natural numbers). 
We could have used any set of objects for the universe. 
What's important is that, whatever we used, the domain of the constructed model is at most countably infinite (i.e., it is at most the size of the natural numbers and no larger). 
Hence a more abstract version of the downward Lowenheim-Skolem Theorem simply says: If a sentence of \GQL{} is true in any model, then either it's true in only models with finite domains, or, if it's true at all in models with infinite domains, then there's an model with a \emph{countably} infinite domain in which it's true. 

This thorem was proved in a weaker form originally by Leopold L\"owenheim \citeyearpar{Lowenheim1915}, and the proof was improved by Thoralf Skolem \citeyearpar{Skolem1920,Skolem1922}. 
Notice that the theorem talks only about models, and we have proved it via a detour through derivations. 
As you might imagine, there are more direct proofs, including Skolem's \citetext{\citealp{Tarski1956}, \citealp{Vaught1974}, \citealp[ch.~3.1]{Hodges1997}, \citeyear[63]{Hodges2001}}.

Notice also that after our work on \GQL{}1, we know that for monadic sentences the method stops after a finite number of steps (if we arrange the prenex carefully) and so we can conclude that if a monadic sentence is true in any model then it is true in a finite one. 
\begin{THEOREM}{\LnpTC{MonadicIntSizeTheorem}}
If $\CAPPHI$ is a sentence of \GQL{}1 and has a model, then it has a finite model.
\end{THEOREM}

Our next corollary of completeness is the Compactness Theorem.
Although historically the completeness theorem was proved first and compactness followed as a corollary, today the compactness theorem takes center stage in many areas of logic (especially model theory). 
Like the L\"owenheim-Skolem Theorem, there are many different proofs of compactness that do not go through completeness or use any facts about derivations \citetext{see \citealt[321]{Kleene1967}, \citealt{Ebbinghaus1985}, \citealt[ch.~5.1]{Hodges1997}, \citealp[63]{Hodges2001}, \citeyear[29]{Hodges2001b}}. 
%answers the question of whether it's possible that an infinite set of sentences is intuitively contradictory but we cannot deduce the contradiction in our system because our derivations are finite?
%This is a specific version of the more general worry that if $\Delta$ is an infinite set then it might be that $\Delta\sdtstile{}{}\CAPPHI$ but not $\Delta\sststile{}{}\CAPPHI$. 
%We can prove that this doe not occur in our language by proving the following theorem.
\begin{THEOREM}{\LnpTC{Thm:CompactnessTheorem} The Compactness Theorem for \GQL{}:}
For all sets of sentences $\Delta$ of \GQL{}, if for every finite subset $\Delta'$ of $\Delta$ there exists a model $\IntA'$ that makes all the sentences in $\Delta'$ true, then there's some model $\IntA$ that makes all the sentences in $\Delta$ true. 
\end{THEOREM}
\begin{PROOF}
By the strong completeness theorem, for all sets $\Delta$ of \GQL{} sentences and \GQL{} sentence $\CAPPHI$, if $\Delta\sdtstile{}{}\CAPPHI$, then $\Delta\sststile{}{}\CAPPHI$.
Now assume that there's no model $\IntA$ that makes all the sentences in $\Delta$ true. 
Hence $\Delta\sdtstile{}{}\conjunction{\Al}{\negation{\Al}}$.
So by strong completeness, $\Delta\sststile{}{}\conjunction{\Al}{\negation{\Al}}$.
By definition, this implies that there's some finite subset $\Delta'$ of $\Delta$ such that $\conjunction{\Al}{\negation{\Al}}$ can be derived from $\Delta'$. 
Hence there is no model $\IntA$ that makes all the sentences in $\Delta'$ true. 
Hence it's not the case that for every finite subset $\Delta'$ of $\Delta$ there exists a model $\IntA'$ that makes all the sentences in $\Delta'$ true. 
\end{PROOF}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Exercises}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\notocsubsection{Misc. Problems}{Misc Problems}
\begin{enumerate}
\item Let's say that any derivation rule \Rule{R} that has the following property is \niidf{sound}:\index{derivation!rule!sound} if we add a line to a derivation $\Derivation{D}$ with sentence $\CAPPHI$ sanctioned by rule \Rule{R}, then $\Delta\sdtstile{}{}\CAPPHI$, where $\Delta$ is the set of unboxed assumptions for the new line. 
(Compare this with what it is for a rule to be truth-preserving, def. \pncmvref{Derivation Rule Soundness}, which is different.)
Then the proof of theorem \mvref{Main GSL Soundness Lemma} basically shows that \GSD{} is sound by showing that all the basic rules of \GSD{} are sound. 
We know that \GSDP{} is sound because \GSD{} is sound and (by theorem \pmvref{GSD Shortcut Theorem3}) anything you can derive in \GSDP{} can be derived in \GSD{}. 
But we could also show that \GSDP{} is sound directly (without appealing to theorem \ref{GSD Shortcut Theorem3}) by showing that the shortcut rules used in \GSDP{} themselves are sound. 
Of course, this follows from theorem \pmvref{GSD Shortcut Theorem2} and the fact that the basic rules are sound, but again we can show it directly. 
But again we can show it without going through the basic rules.
Show directly (without appealing to theorem \ref{GSD Shortcut Theorem2}) that the following rules are sound (see tables \pmvref{GSDplus1} and \pmvref{GSDplus2}): 
\begin{multicols}{2}
\begin{enumerate}
\item \Rule{M.T.}
\item \Rule{A.C.}
\item \Rule{$\HORSESHOE$/$\VEE$-Exch.}
\item \Rule{Contraposition}
\end{enumerate}
\end{multicols} 
\item Recall that $\HORSESHOE$ elimination can only be used on a conditional that is the main connective of a sentence. Show that if we do not make this restriction, then the rule is unsound. In other words, give a derivation which violates only that restriction (a derivation where you use $\HORSESHOE$ elimination on a horseshoe that's not the main connective) and which ends with a proof of a sentence that is \emph{not} a logical truth (not truth-functionally true) from the empty set of assumptions.
\end{enumerate}

\notocsubsection{Quantifier Exchange Rule Soundness}{Quantifier Exchange Rule Soundness}

Prove the soundness of the following exchange rules.

\begin{enumerate}
\item \Rule{$\universal$-Shuffle}
\item \Rule{$\existential$-Shuffle}
\item \Rule{Q-Deletion}
\item \Rule{$\wedge$-Shuffle}
\item \Rule{$\vee$-Shuffle}
\end{enumerate}

\renewcommand{\arraystretch}{1.5}
\begin{longtable}[c]{ p{1in} l l } %p{2.2in} p{2in}
\toprule
\textbf{Name} & \textbf{Given} & \textbf{May Add} \\ 
\midrule
\endfirsthead
\multicolumn{3}{c}{\emph{Continued from Previous Page}}\\
\toprule
\textbf{Name} & \textbf{Given} & \textbf{May Add} \\ 
\midrule
\endhead
\bottomrule
\caption{Additonal Exchange Rules for \GQD{}}\\[-.15in]
\multicolumn{3}{c}{\emph{Continued next Page}}\\
\endfoot
\bottomrule
\caption{Additonal Exchange Rules for \GQD{}}\\
\endlastfoot
\Rule{$\universal$-Shuffle} & $\universal\variable{\alpha}\parconjunction{\CAPPHI_1}{\conjunction{\ldots}{\CAPPHI_n}}$ & $\conjunction{\universal\variable{\alpha}\CAPPHI_1}{\conjunction{\ldots}{\universal\variable{\alpha}\CAPPHI_n}}$ \\
\Rule{$\existential$-Shuffle} & $\existential\variable{\alpha}\pardisjunction{\CAPPHI_1}{\disjunction{\ldots}{\CAPPHI_n}}$ & $\par\disjunction{\existential\variable{\alpha}\CAPPHI_1}{\disjunction{\ldots}{\existential\variable{\alpha}\CAPPHI_n}}$ \\
\Rule{Q-Deletion} & $\#\variable{\alpha}\CAPPHI$ & $\CAPPHI$, iff $\alpha$ does  \\[-.25cm]
\nopagebreak
 &  &  not occur in $\CAPPHI$  \\
\Rule{$\wedge$-Shuffle} & $\conjunction{\CAPPHI_1}{\conjunction{\ldots}{\conjunction{\CAPPHI_k}{\conjunction{\ldots}{\CAPPHI_n}}}}$ & $\conjunction{\CAPPHI_k}{\conjunction{\CAPPHI_1}{\conjunction{\ldots}{\CAPPHI_n}}}$ \\
\Rule{$\vee$-Shuffle} & $\disjunction{\CAPPHI_1}{\disjunction{\ldots}{\disjunction{\CAPPHI_k}{\disjunction{\ldots}{\CAPPHI_n}}}}$ & $\disjunction{\CAPPHI_k}{\disjunction{\CAPPHI_1}{\disjunction{\ldots}{\CAPPHI_n}}}$ \\
\end{longtable}

%\theendnotes
