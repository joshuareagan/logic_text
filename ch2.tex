
%\addtocontents{toc}{\protect\thispagestyle{empty}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Sentential Logic}\label{sententiallogic}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\AddToShipoutPicture*{\BackgroundPicA}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Language \GSL{}}\label{The Language GSL}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Sentences of \GSL{}}\label{Sentences of GSL}
Our first task is to define the syntax of the basic formal language \GSL{}.\footnote{Work on modern sentential logic originated with George Boole \citeyearpar{Boole1854} and Augustus De Morgan \citeyearpar{DeMorgan1847,DeMorgan1860}. 
	As Christine Ladd-Franklin notes \citeyearpar[17]{LaddFranklin1883} before giving her own, variations quickly followed from William S. Jevons, Ernst Schr\"oder, Hugh McColl, and Charles S. Peirce.} 
This language is variously called \idf{sentential logic} or \niidf{propositional logic}\index{propositional logic|see{sentential logic}}. 
We use the former name because it's easier to get a grasp on what a sentence is.
Our choice allows us to sidestep the philosophical debate over what a proposition is.\footnote{For historical and contemporary discussions of propositions, see \citealt{Frege1892}, \citealt[13,47]{Russell1903}, \citealt[26]{Church1956}, \citealt[ch.~1]{Quine1986}, \citealt[ch.~3]{Schiffer1987}, \citealt{Grandy1993}, \citealt{Bealer1998b}, \citealp{King2007}, \citealt{Soames2010}.}

As stated in the previous chapter, each formal language\index{language} requires (1) a list of basic symbols, and (2) a specification of which sequences of those symbols count as sentences\index{sentence}.
These determine the proper grammar or syntax of the language. 

\begin{majorILnc}{\LnpDC{Basic Symbols of GSL}} The \df{basic symbols} of \GSL{} are of three kinds:\footnote{The commas and ellipses are \emph{not} symbols of \GSL{}.}
\begin{cenumerate}
\item Logical Connectives: $\NEGATION$, $\WEDGE$, $\VEE$, $\HORSESHOE$, $\TRIPLEBAR$
\item Punctuation Symbols: (, )
\item Sentence Letters: $\Al,\Bl, \ldots, \Tl, \Al_1,\Bl_1, \ldots, \Tl_1, \Al_2, \Bl_2, \ldots$  
\end{cenumerate}
\end{majorILnc} 
\noindent{}Logical connectives are sometimes called logical symbols, logical operators, logical terms, or logical functors.\footnote{%
	In other textbooks there are sometimes different symbols used for these connectives. 
	Along with $\NEGATION$, $\neg$ and $-$ are used for negation, $\&$ and $\cdot$ for conjunction, $\supset$ and $\Rightarrow$ for conditionals, and $\equiv$ for biconditionals. $\VEE$ is almost universally the symbol for disjunction.
} 
One could draw important distinctions between symbols, terms, and operators, but the names are just as often used interchangeably.
The \emph{sentence letters} are italicized capital letters of the Roman alphabet from \mention{$\Al$} to \mention{$\Tl$}.
To give ourselves an infinite supply, any of these letters with a subscripted positive integer is also a sentence letter.
E.g. $\Cl$ and a subscripted $7$ can be combined to get the new sentence letter $\Cl_7$.
Remember that $\Cl_7$ and $\Cl$ are different sentences.

The following list gives the name of each connective symbol:

\begin{cenumerate}
	\item $\NEGATION$: ``tilde'',
	\item $\WEDGE$: ``wedge'',
	\item $\VEE$: ``vee'',
	\item $\HORSESHOE$: ``arrow'',
	\item $\TRIPLEBAR$: ``double-arrow''.
\end{cenumerate}

\begin{majorILnc}{\LnpDC{Recursive definition of Sentences of GSL}} The \nidf{sentences} \underdf{of \GSL{}}{sentence} are given by the following recursive definition:
\begin{description}
\item[Base Clause:] Every sentence letter is a sentence.
\item[Generating Clauses:] \hfill
\begin{cenumerate}
\item If $\CAPPHI$ is a sentence, then so is $\negation{\CAPPHI}$.\footnote{Remember from Chapter 1 that $\CAPPHI$ and $\CAPTHETA$ are used as metavariables. In this definition they stand for sentences of \GSL{}.}
\item If $\CAPPHI$ and $\CAPTHETA$ are sentences, then so are both $\parhorseshoe{\CAPPHI}{\CAPTHETA}$ and $\partriplebar{\CAPPHI}{\CAPTHETA}$.
\item If all of $\CAPPHI_1,\CAPPHI_2,\ldots,\CAPPHI_{\integer{n}}$ are sentences (where $\integer{n}$ is an integer $\geq2$), then so are $\parconjunction{\CAPPHI_1}{\conjunction{\CAPPHI_2}{\conjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$ and $\pardisjunction{\CAPPHI_1}{\disjunction{\CAPPHI_2}{\disjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$.
\end{cenumerate}
\item[Closure Clause:] No other string is an \GSL{} sentence.
\end{description}
\end{majorILnc}

\noindent{}Here are some example \GSL{} sentences:
	
\begin{multicols}{2}
	\begin{smenumerate}
	\item $\Bl$
	\item $\negation{\Bl}$
	\item $\parhorseshoe{\negation{\Bl}}{\Cl}$
	\item $\negation{\partriplebar{\negation{\Bl}}{\Cl}}$
	\item $\pardisjunction{\Al}{\disjunction{\Cl}{\Dl}}$
	\item $\pardisjunction{\parhorseshoe{\Al}{\El}}{\disjunction{\Cl}{\disjunction{\negation{\Dl}}{\Gl}}}$
	\item $\parconjunction{\pardisjunction{\Al}{\Bl}}{\pardisjunction{\Cl}{\Dl}}$
	\item $\negation{\parconjunction{\Al}{\negation{\parhorseshoe{\Bl}{\Cl}}}}$
	\end{smenumerate}
\end{multicols}

Sentence letters are sometimes called \underidf{atomic}{sentence} sentences.
Sentences of the form $\negation{\CAPPHI}$ are \idf{negations}.
Sentences of the form $\parhorseshoe{\CAPPHI}{\CAPTHETA}$ are \idf{conditionals}, and those of the form $\partriplebar{\CAPPHI}{\CAPTHETA}$ are \idf{biconditionals}. 
The left-hand side of the conditional, $\CAPPHI$, is traditionally called the \idf{antecedent}\index{LHS} and the right-hand side, $\CAPTHETA$, the \idf{consequent}\index{RHS}. 
We often use the alternative terminology \CAPS{lhs} (left-hand side) and \CAPS{rhs} (right-hand side).
Sentences of the form $\parconjunction{\CAPPHI_1}{\conjunction{\CAPPHI_2}{\conjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$ are \idf{conjunctions} and their component sentences (e.g. $\CAPPHI_1$) are \idf{conjuncts}.
Sentences of the form $\pardisjunction{\CAPPHI_1}{\disjunction{\CAPPHI_2}{\disjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$ are \idf{disjunctions} and their component sentences are \idf{disjuncts}.\footnote{
	Many logic books treat conjunction and disjunction as binary (2-place), e.g., \mention{$\pardisjunction{\Al}{\Bl}$}. According to our definition \mention{$\pardisjunction{\disjunction{\Al}{\Bl}}{\Cl}$} is also a perfectly good sentence. Textbooks that treat disjunctions as binary require an extra set of parentheses to generate an equivalent sentence: e.g., \mention{$\pardisjunction{\pardisjunction{\Al}{\Bl}}{\Cl}$}. This is also an acceptable sentence of \GSL{}, but the extra parentheses don't add interesting information. We prefer the definitions of conjunction and disjunction given above because they're closer to natural English and they allow us to avoid unnecessary parentheses.
}

The base and generating clauses tell us which strings are sentences, but they don't say which strings aren't.
How do we know, for example, that \mention{$(\Bl(\HORSESHOE{}\Al$} isn't an \GSL{} sentence?
That's what the closure clause is for.
It explicitly excludes strings that cannot be constructed with the base and generating clauses.

Note that $\negation{\CAPPHI}$, $\parhorseshoe{\CAPPHI}{\CAPTHETA}$, etc. in the generating clauses are \textbf{not \GSL{} sentences}.
That's because metavariables aren't included in the symbols of \GSL{}.
These \idf{sentence schemas} are strings that can be made into sentences by substituting sentences for metavariables.
For example, the substitution $\CAPPHI=\;$\mention{$\Al$}, $\CAPTHETA=\;$\mention{$\partriplebar{\Cl}{\Dl}$} in the schema $\parhorseshoe{\CAPPHI}{\CAPTHETA}$ results in the sentence \mention{$\parhorseshoe{\Al}{\partriplebar{\Cl}{\Dl}}$}.\footnote{When Greek letters \mention{$\CAPPHI$}, \mention{$\CAPPSI$}, \mention{$\CAPTHETA$}, etc. are used it should usually be assumed that they range over \GSL{} sentences and not mere strings of \GSL{} symbols. 
In exceptional cases we intend for them to range over all strings of \GSL{} symbols, as we did in the definition just given of \GSL{} sentences.}

For any sequence of \GSL{} symbols it is possible to \emph{prove} whether it is a sentence.

\begin{majorILnc}{\LnpEC{Example of Recursive definition of GSL sentences}}
$\parconjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$ is a sentence of \GSL{}. 

\noindent{}The base clause of \ref{Recursive definition of Sentences of GSL} defines each of $\Al$, $\Dl$, $\Bl$, and $\Gl$ as sentences. 
From $\Dl$ and $\Bl$, and by generating clause (2), $\parhorseshoe{\Dl}{\Bl}$ is a sentence. 
From $\Gl$ and generating clause (1), $\negation{\Gl}$ is a sentence. 
From $\Al$ and $\parhorseshoe{\Dl}{\Bl}$, and generating clause (3), $\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}$ is a sentence. 
And, finally, from $\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}$ and $\negation{\Gl}$, and generating clause (3), $\parconjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$ is a sentence. 
\end{majorILnc}

\subsection{Official and Unofficial Sentences of \GSL{}}\label{Unofficial Sentences of GSL}

Definition \ref{Recursive definition of Sentences of GSL} is the definition of an \emph{official} sentence of \GSL{}.
For convenience we often work with \emph{un}official sentences. 
\begin{majorILnc}{\LnpDC{Unofficial Sentence of GSL}}
A string of symbols is an \nidf{unofficial} sentence\index{sentence!unofficial (of \GSL{})|textbf} \Iff we can obtain it from an official sentence by
\begin{cenumerate}
\item deleting outer parentheses, or
\item replacing one or more pairs of official round parentheses ( ) with square brackets [ ] or curly brackets \{ \}.
\end{cenumerate}
\end{majorILnc}
\noindent{}Thus \mention{$\conjunction{\Al}{\conjunction{\Bl}{\Cl}}$} is an unofficial sentence, as are
\begin{multicols}{2}
\begin{smenumerate}
\item\label{usex1} $\negation{\pardisjunction{[\Al\wedge\Bl]}{[\Cl\wedge\Dl]}}$
\item $\conjunction{\parconjunction{\Al}{\Bl}}{\Cl}$
\item $\horseshoe{\parconjunction{\Al}{\Bl}}{\Cl}$
\item $\parconjunction{\Al}{[\Bl\rightarrow\Cl]}$
\item $\disjunction{\negation{\Al}}{\Cl}$
\item $[\parconjunction{\Al}{\Bl}\wedge\Cl]$
\item $\conjunction{\{\Al\wedge\Bl\}}{\Cl}$
\item\label{usexL} $\conjunction{\Al}{[\Bl\rightarrow\Cl]}$
\end{smenumerate}
\end{multicols}
\noindent{}From an unofficial sentence we can unambiguously reconstruct the related official sentence. 
Throughout the rest of this text we usually drop outer parentheses, but we will consistently use the standard parentheses ( ). 
The reader should feel free to use brackets [ ] or curly parentheses \{ \} as is helpful. 

\subsection{A Comment on Use and Mention}\label{use mention comment}

Most of the time when you see Greek letters in the text, as in definition \mvref{Recursive definition of Sentences of GSL}, we are \emph{using} them, not mentioning them. 
Thus it's appropriate that in definition \ref{Recursive definition of Sentences of GSL} we did not put them in single quotes.\index{single quotes}
By contrast, we generally \emph{mention} official and unofficial \GSL{} sentences rather than use them.
Because we mention \GSL{} sentences so often it would be tedious to put them in quotes. 
Therefore we refrain from doing so unless there is some special reason to do so.  
We are also less strict when mentioning the basic symbols of \GSL{}.\footnote{This is the usual convention. See e.g. \citealt[7]{Hodges2001}.}

\subsection{Other Properties of Sentences}\label{Other Properties of GSL Sentences}
Next we define four important properties and related features of sentences: subsentence, order, main connective, and construction tree. 
\begin{majorILnc}{\LnpDC{Subsentences}}
The following clauses define when one sentence is a \df{subsentence} of another:
\begin{cenumerate}
\item\label{ss1} Every sentence is a subsentence of itself.
\item $\CAPPHI$ is a subsentence of $\negation{\CAPPHI}$.
\item $\CAPPHI$ and $\CAPTHETA$ are subsentences of $\parhorseshoe{\CAPPHI}{\CAPTHETA}$ and $\partriplebar{\CAPPHI}{\CAPTHETA}$.
\item\label{ss4} Each of $\CAPPHI_1,\CAPPHI_2,\ldots,\CAPPHI_{\integer{n}}$ is a subsentence of $\parconjunction{\CAPPHI_1}{\conjunction{\CAPPHI_2}{\conjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$\\ and $\pardisjunction{\CAPPHI_1}{\disjunction{\CAPPHI_2}{\disjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$.
\item\label{ss5} (Transitivity) If $\CAPPHI$ is a subsentence of $\CAPTHETA$ and $\CAPTHETA$ is a subsentence of $\CAPPSI$, then $\CAPPHI$ is a subsentence of $\CAPPSI$.
\item\label{ss6} That's all. 
\end{cenumerate}
\end{majorILnc}
\begin{majorILnc}{\LnpEC{SubSentenceExampleA}}
	The sentence $\parhorseshoe{\Bl}{\Cl}$ has 3 subsentences:
	\begin{cenumerate}
		\item $\parhorseshoe{\Bl}{\Cl}$
		\item $\Bl$
		\item $\Cl$
	\end{cenumerate}
\end{majorILnc}
\noindent{}Subsentences are counted by token, not type. Hence the similar $\parhorseshoe{\Bl}{\Bl}$ also has three subsentences; the two tokens of $\Bl$ are counted separately.
\begin{majorILnc}{\LnpEC{SubSentenceExampleB}}
$\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$ has 8 subsentences:
\begin{multicols}{2}
\begin{cenumerate}
\item $\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$
\item $\disjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}$
\item $\horseshoe{\Dl}{\Bl}$
\item $\Al$
\item $\Dl$
\item $\Bl$
\item $\negation{\Gl}$
\item $\Gl$
\end{cenumerate}
\end{multicols}
\end{majorILnc}
\begin{majorILnc}{\LnpDC{Proper Subsentences}}
	A sentence $\CAPPHI$ is a \df{proper subsentence} of $\CAPPSI$ \Iff $\CAPPHI$ is a subsentence of but isn't identical to $\CAPPSI$.
\end{majorILnc}
\noindent{}Each sentence is a subsentence of itself, but no sentence is a proper subsentence of itself.
\begin{majorILnc}{\LnpDC{Order}}
The following clauses define the \df{order} of every \GSL{} sentence.\footnote{\citetext{\citealt{Post1921}, \citealt[11]{Hodges2001}}} Let $\ORD{\CAPPHI}$ be the order of $\CAPPHI$. Then: 
\begin{cenumerate}
\item If $\CAPPHI$ is an atomic sentence (a sentence letter), then $\ORD{\CAPPHI}=1$.
\item For any sentence $\CAPPHI$, $\ORD{\negation{\CAPPHI}}=\ORD{\CAPPHI}+1$.
\item For any sentences $\CAPPHI$ and $\CAPTHETA$, $\ORD{\parhorseshoe{\CAPPHI}{\CAPTHETA}}$ is one greater than the max of $\ORD{\CAPPHI}$ and $\ORD{\CAPTHETA}$. Likewise, $\ORD{\partriplebar{\CAPPHI}{\CAPTHETA}}$ is one greater than the max of $\ORD{\CAPPHI}$ and $\ORD{\CAPTHETA}$.
\item For any sentences $\CAPPHI_1,\ldots,\CAPPHI_\integer{n}$, $\ORD{\parconjunction{\CAPPHI_1}{\conjunction{\ldots}{\CAPPHI_\integer{n}}}}$ is one greater than the max of $\ORD{\CAPPHI_1}$, $\ldots$, $\ORD{\CAPPHI_\integer{n}}$.
\item For any sentences $\CAPPHI_1,\ldots,\CAPPHI_\integer{n}$, $\ORD{\pardisjunction{\CAPPHI_1}{\disjunction{\ldots}{\CAPPHI_\integer{n}}}}$ is one greater than the max of $\ORD{\CAPPHI_1}$, $\ldots$, $\ORD{\CAPPHI_\integer{n}}$. 
\item That's all.
\end{cenumerate}
\end{majorILnc}
\begin{majorILnc}{\LnpEC{OrderExampleA}}
What is the order of $\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$?
The order of an atomic sentence is 1, so $\Al$, $\Dl$, $\Bl$, $\Gl$ each have order 1.
The order of $\horseshoe{\CAPPHI}{\CAPPSI}$ is $1$ plus the maximum of the orders of $\CAPPHI$ and $\CAPPSI$; thus the order of $\horseshoe{\Dl}{\Bl}$ is 2.  
Because $\ORD{\negation{\CAPPHI}}=\ORD{\CAPPHI}+1$, $\ORD{(\negation{\Gl})}=\ORD{(\Gl)}+1=2$. 
Because the order of a disjunction $\disjunction{\CAPPHI_\integer{1}}{\disjunction{\ldots}{\CAPPHI_{\integer{n}}}}$ is $1$ plus the maximum order of the disjuncts, the order of $\disjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}$ is 3.
The same goes for conjunctions, so the order of $\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$ is 4.
\end{majorILnc}
\begin{majorILnc}{\LnpDC{GSL Main connective}}
The \nidf{main connective}\index{main connective!of GSL|textbf} is the connective token (or tokens) that occur(s) in the sentence but in no proper subsentence.  
\end{majorILnc}
\begin{majorILnc}{\LnpEC{GSLMainConnectiveExampleA}}
The main connective in each of the following sentences has been underlined.
\begin{multicols}{2}
\begin{cenumerate}
\item $(\Al\VEE(\Dl\HORSESHOE\Bl))\, \underline{\WEDGE}\, \negation{\Gl}$
\item $\Ll\, \underline{\VEE}\, \Kl\, \underline{\VEE}\, \Hl $
\item $\Ll\, \underline{\VEE}\, \parhorseshoe{\Al}{\Bl}\, \underline{\VEE}\, \Hl $
\item $\underline{\NEGATION}(\Ll\VEE\Kl\VEE\Hl)$
\item $(((\Dl\!\HORSESHOE\!\El)\VEE\Al)\underline{\WEDGE}(\NEGATION\Bl\WEDGE\NEGATION(\Cl\!\TRIPLEBAR\!\Hl)))$
\item $(\NEGATION\Bl\, \underline{\WEDGE}\, \NEGATION(\Cl\TRIPLEBAR\Hl))$
\end{cenumerate}
\end{multicols}
\end{majorILnc}

\begin{majorILnc}{\LnpDC{Construction Tree}}
The \df{construction tree} for a sentence is a diagram of how the sentence is generated through the recursive clauses of the definition of \GSL{} sentences. We put atomic sentences as leaves at the top, and the generating clauses specify how we can join nodes of the tree together (starting with the leaves at the top) into new nodes. The complete sentence is the node at the base of the tree. 
\end{majorILnc}
\begin{majorILnc}{\LnpEC{ConstructionTreeExampleA}}
Give the construction tree for $\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$.
\begin{center}
\begin{tikzpicture}[grow=up]
\tikzset{level distance=40pt}
\tikzset{level 1/.style={level distance=60pt}}
\tikzset{sibling distance=32pt}
\tikzset{every tree node/.style={align=center,anchor=north}}
	\Tree%http://angasm.org/papers/qtree/    http://www.ling.upenn.edu/advice/latex/qtree/qtreenotes.pdf
[.{$\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$}
  [.{$\negation{\Gl}$} %!{\qsetw{3in}}
  [.{$\Gl$}
  ]
  ]
  [.{$\disjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}$} 
    [.{$\horseshoe{\Dl}{\Bl}$} 
      [.{$\Bl$} 
      ]
      [.{$\Dl$} %!{\qsetw{2in}}
      ] 
    ]
    [.{$\Al$}
    ]    
  ]
]%
	%\caption{Example formula tree}
	%\label{fig:ExampleFormulaTree}
\end{tikzpicture}
\end{center}
\end{majorILnc}
\begin{majorILnc}{\LnpEC{ConstructionTreeExampleB}}
Give the construction tree for $((\Cl \WEDGE \Dl) \HORSESHOE \Al)\TRIPLEBAR (\Dl \VEE \Hl)$.
\begin{center}
\begin{tikzpicture}[grow=up]
\tikzset{level distance=42pt}
\tikzset{sibling distance=32pt}
\tikzset{every tree node/.style={align=center,anchor=north}}
	\Tree%http://angasm.org/papers/qtree/    http://www.ling.upenn.edu/advice/latex/qtree/qtreenotes.pdf
[.{$((\Cl \WEDGE \Dl) \HORSESHOE \Al)\TRIPLEBAR (\Dl \VEE \Hl)$}
  [.{$\Dl\VEE \Hl$} %!{\qsetw{3in}}
    [.{$\Hl$} %!{\qsetw{2in}}
    ]   
    [.{$\Dl$}
    ]  
  ]
  [.{$(\Cl\WEDGE \Dl)\HORSESHOE \Al$} 
    [.{$\Al$} %!{\qsetw{2in}}
    ]  
    [.{$\Cl\WEDGE \Dl$} 
      [.{$\Dl$} %!{\qsetw{2in}}
      ]     
      [.{$\Cl$} 
      ]
    ]
  ]
]%
	%\caption{Example formula tree}
	%\label{fig:ExampleFormulaTree}
\end{tikzpicture}
\end{center}
\end{majorILnc}
\noindent{}There are some helpful relationships between the construction tree of a sentence,  its order, its subsentences, and its main connective. 
The subsentences of a sentence are the nodes in the sentence's construction tree.
The order of a sentence is the number of nodes of its longest branch from root to leaf, i.e., the height of the tree. 
The main connective of a sentence is the connective added last (at the bottom) of the construction tree. 
\begin{majorILnc}{\LnpEC{ConstructionTreeExampleC}}
Consider again the construction tree for $\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$. 
Find the order of the sentence by counting the height of the branches of the tree. 
(We count up as we work our way down the branches.)
Note that the answer we get agrees with that computed in example \mvref{OrderExampleA}.
\begin{center}
\begin{tikzpicture}[grow=up]
\tikzset{level distance=40pt}
\tikzset{level 1/.style={level distance=60pt}}
\tikzset{sibling distance=40pt}
\tikzset{every tree node/.style={align=center,anchor=north}}
	\Tree%http://angasm.org/papers/qtree/    http://www.ling.upenn.edu/advice/latex/qtree/qtreenotes.pdf
[.{$\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$ \textbf{[4]}}
  [.{$\negation{\Gl}$ \textbf{[2]}} %!{\qsetw{3in}}
  [.{$\Gl$ \textbf{[1]}}
  ]
  ]
  [.{$\disjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}$ \textbf{[3]}} 
    [.{$\horseshoe{\Dl}{\Bl}$ \textbf{[2]}} 
      [.{$\Bl$ \textbf{[1]}} 
      ]
      [.{$\Dl$ \textbf{[1]}} %!{\qsetw{2in}}
      ] 
    ]
    [.{$\Al$ \textbf{[1]}}
    ]    
  ]
]%
	%\caption{Example formula tree}
	%\label{fig:ExampleFormulaTree}
\end{tikzpicture}
\end{center}
\end{majorILnc}

\subsection{How Many \GSL{} Sentences are There?}
There are at least as many sentence letters as there are natural numbers, and the sentence letters are a proper subset of the set of sentences. 
Are there more sentences than natural numbers?  
Below we prove there are not by matching up sentences with natural numbers.
\begin{THEOREM}{\LnpTC{Number of sentences}}
The number of \GSL{} sentences is equal to the number of natural numbers.
\end{THEOREM}
\begin{PROOF}
First, assign each sentence letter a natural number that only contains the digit \mention{$1$}, for example:
\begin{center}
\begin{tabular}{ c c c c c }
$\Al$ & $\Bl$ & $\Cl$ & $\Dl$ & $\ldots$ \\
1 & 11 & 111 & 1111 & $\ldots$ \\
\end{tabular}
\end{center}
Next, assign numbers to the other symbols of \GSL{}, for example:
\begin{center}
\begin{tabular}{ c c c c c c c }
$\NEGATION$ & $\WEDGE$ & $\VEE$ & $\HORSESHOE$ & $\TRIPLEBAR$ & ( & ) \\
2 & 3 & 4 & 5 & 6 & 7 & 8 \\
\end{tabular}
\end{center}
Given any sentence, replace its symbols with the associated numbers.
For example, \mbox{$\negation{\parconjunction{\Al}{\conjunction{\Bl}{\negation{\Dl}}}}$} gets mapped to 2713113211118.
For any sentence of \GSL{}, there is a unique natural number defined by this process. 
For any natural number we can determine if it represents an \GSL{} sentence, and if so which one.
\end{PROOF}

\noindent{}This is not the most efficient way of representing sentences with numbers, but it is a simple one that avoids the use of special properties (e.g., being a prime number).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Models}\label{Interpretations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\GSL{} is a formal language, so its sentences are mere strings of symbols without any inherent meaning---they don't ``say anything'' about the world.\footnote{
	We mentioned this property of formal languages in \ref{Formal Languages}.
}
As a consequence, sentences of \GSL{} lack an inherent truth value. That is, they are neither true nor false. 
Even so, nothing stops us from \emph{assigning} truth values to \GSL{} sentences. 
In this section we explain how to do so consistently.\footnote{
	You might ask why we don't first assign \GSL{} sentences meanings, then determine whether they are true or false based on those meanings. 
	There are difficulties associated with assigning meanings that would complicate our project unnecessarily. (We show how to \emph{interpret} \GSL{} sentences as having meanings in chapter \ref{Translations}.)
	One of the most important discoveries in logic was that for \GSL{} only truth values matter; all other details of meaning are irrelevant.
}

\subsection{Truth in a Model}\label{Truth in an Interpretation} 

Truth values are assigned to sentences by models.

\begin{majorILnc}{\LnpDC{Definition of GSL interpretation}}
A \df{model of an \GSL{} sentence $\CAPPHI$} is an assignment of a truth value, either $\True$ or $\False$, to each sentence letter in $\CAPPHI$.
\end{majorILnc}

\noindent{}We can think of a model of $\CAPPHI$ as a function from the set of sentence letters of $\CAPPHI$ to the set of truth values: $\{\TrueB, \FalseB\}$. 
We use the letter \mention{$\IntA$} (a fraktur-style \mention{m}) to represent such a function.
If a model $\IntA$ assigns a sentence letter $\CAPPSI$ the value \mention{$\True$}, $\IntA(\CAPPSI)=\TrueB$.
For the value \mention{$\False$}, $\IntA(\CAPPSI)=\FalseB$.\footnote{
	The definiton of \mention{model} we use assigns one of two truth values to each sentence letter, but that's not the only way to define them. Other definitions assign more than two.
	The assumption that there are only two truth values simplifies analysis and is widely shared, but whether two is enough is a matter of philosophical debate.
	Nevertheless, even if our definition of a model is a simplification, it is a historically fruitful one and helps us better understand logical consequence.  In chapter \ref{furtherdirections} we discuss formal languages with additional truth values.
}

To illustrate, a model for $\pardisjunction{\disjunction{\Al}{\Bl}}{\Cl}$ assigns a truth value to each of the sentence letters $\Al$, $\Bl$, and $\Cl$.
Any model for $\pardisjunction{\disjunction{\Al}{\Bl}}{\Cl}$ is therefore also a model for $\parconjunction{\conjunction{\Al}{\Bl}}{\Cl}$ and $\parconjunction{\parhorseshoe{\Al}{\Bl}}{\negation{\Cl}}$; they all have the same sentence letters.

We often speak informally of \emph{models} without making reference to any particular \GSL{} sentence.  It's useful to talk this way because any given model of $\CAPPHI$ is a model of any other \GSL{} sentence with the same sentence letters, or a subset of them.  If $\IntA$ makes assignments to $\Al$, $\Bl$, and $\Cl$, then $\IntA$ is a model of all the sentences that only contain sentence letters from that list.  Accordingly, we define a model for a \emph{set} of \GSL{} sentences.

\begin{majorILnc}{\LnpDC{Definition of Model for Set}}
	$\IntA$ is a \df{model of a set of sentences $\Delta$} \Iff $\IntA$ is a model for each sentence in $\Delta$.
\end{majorILnc}

Consider a model $\IntA$ that makes a truth value assignment to every sentence letter of \GSL{}.  No sentence letter lacks an assignment, so it follows that $\IntA$ is a model for the set of all \GSL{} sentences.  The following definition characterizes such models as \emph{models of \GSL{}}.

\begin{majorILnc}{\LnpDC{Definition of Model for SL}}
	$\IntA$ is a \df{model of \GSL{}} \Iff $\IntA$ is a model of every sentence of \GSL{}.\footnote{
		This is the definition of ``model'' in many logic textbooks.
		We prefer to include models that make assignments to only a subset of sentence letters.
	}
\end{majorILnc}

Models can be uniform; for example, there is a model that assigns $\True$ to every sentence letter.
Or they can be given according to an arbitrary pattern, such as the model that alternately assigns $\True$ or $\False$ to a list of sentence letters.
A model can even assign truth values at random. 
\emph{Every} possible function from sentence letters to truth values is a model.

A model of $\CAPPHI$ only assigns truth values to the sentence letters of $\CAPPHI$.
It does not directly assign a truth value to any of the complex (i.e. non-atomic) sentences of \GSL{}.
The truth value of a complex sentence $\CAPPHI$ depends upon two things: (1) the main connective of $\CAPPHI$, and (2) the truth values of the proper subsentences of $\CAPPHI$.
Each logical connective is associated with a truth function.
While the truth assignments to the sentence letters vary by model, the truth functions of the connectives do not.\footnote{We discuss \emph{truth functions} further in section \ref{Truth Functions Truth Tables and Boolean Operators}.}

\begin{majorILnc}{\LnpDC{True on a GSL interpretation}} The following clauses define whether an \GSL{} sentence $\CAPTHETA$ is \nidf{$\True$} or \nidf{$\False$} on a model $\IntA$ for $\CAPTHETA$. The relevant clause is determined by which main connective $\CAPTHETA$ has, if any:
\begin{cenumerate}
\item $\CAPTHETA$ is a sentence letter. $\CAPTHETA$ is $\True$ on $\IntA$ \Iff $\IntA$ assigns $\True$ to it, i.e. $\IntA(\CAPTHETA)=\TrueB$.
\item $\CAPTHETA$ is of the form $\negation{\CAPPHI}$. $\CAPTHETA$ is $\True$ on $\IntA$ \Iff $\CAPPHI$ is $\False$ on $\IntA$.
\item\label{GSL true conjunction} $\CAPTHETA$ is of the form $\parconjunction{\CAPPHI_1}{\conjunction{\CAPPHI_2}{\conjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$.   $\CAPTHETA$ is $\True$ on $\IntA$ \Iff each of the conjuncts $\CAPPHI_1, \CAPPHI_2, \ldots, \CAPPHI_n$ is $\True$ on $\IntA$.
\item $\CAPTHETA$ is of the form $\pardisjunction{\CAPPHI_1}{\disjunction{\CAPPHI_2}{\disjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$. $\CAPTHETA$ is $\True$ on $\IntA$ \Iff at least one of the disjuncts $\CAPPHI_1, \CAPPHI_2, \ldots, \CAPPHI_n$ is $\True$ on $\IntA$.
\item\label{GSL true horseshoe} $\CAPTHETA$ is of the form $\horseshoe{\CAPPHI}{\CAPPSI}$. $\CAPTHETA$ is $\True$ on $\IntA$ \Iff the \CAPS{lhs} $\CAPPHI$ is $\False$ or the \CAPS{rhs} $\CAPPSI$ is $\True$ on $\IntA$ (or both).
\item $\CAPTHETA$ is of the form $\triplebar{\CAPPHI}{\CAPPSI}$. $\CAPTHETA$ is $\True$ on $\IntA$ \Iff $\CAPPHI$ and $\CAPPSI$ have the same truth value on $\IntA$.
\item A sentence is $\False$ on $\IntA$ \Iff it's not $\True$ on $\IntA$.
\end{cenumerate}
\end{majorILnc}

For every model $\IntA$ for sentence $\CAPPHI$ this definition (i.e. the definition of truth) fixes a unique truth value for $\CAPPHI$.\footnote{If a model $\IntA$ is \emph{not} a model for some \GSL{} sentence $\CAPPHI$ then $\IntA$ does \emph{not} fix a truth value for $\CAPPHI$.}

Although there are an infinite number of \GSL{} sentences letters to which a model can assign truth values, the only ones that matter for any given sentence are, unsurprisingly, the sentence letters that the sentence contains.\footnote{
	We prove this later in the chapter.
}
For example, when assessing the value of $\horseshoe{\Al}{\Bl}$ on $\IntA$ only the assignments to $\Al$ and $\Bl$ are relevant; assignments to other letters are irrelevant. It follows that if two models $\IntA_1$ and $\IntA_2$ assign the same truth values to $\Al$ and $\Bl$, respectively, then they fix the same truth value for $\horseshoe{\Al}{\Bl}$. 

If $\IntA$ makes assignments to $\Al$ and $\Bl$ but no other sentence letters, we say that $\IntA$ is a \emph{minimal model} of $\horseshoe{\Al}{\Bl}$. More generally:

\begin{majorILnc}{\LnpDC{Definition of Minimal SL Model}}
	$\IntA$ is a \df{minimal model of $\CAPPHI$} \Iff $\IntA$ makes assignments to every sentence letter in $\CAPPHI$ but to no other sentence letters.
\end{majorILnc}

\noindent{}There are only four minimal models for the sentence $\horseshoe{\Al}{\Bl}$, because there are only $4$ combinations of truth values that can be assigned to $\Al$ and $\Bl$. The number of distinct minimal models for a sentence $\CAPPHI$ is $2^n$, where $n$ is the number of sentence letters (counted by type) in $\CAPPHI$.

There are several ways to compute the truth value of an \GSL{} sentence in a model.
We demonstrate some informal ones in the following examples, and then develop a systematic method in section \mvref{Proceduresfortesting}. 

\begin{majorILnc}{\LnpEC{GSLTVExampleA}}
	Give the truth value of $\disjunction{\Al}{\negation{\Bl}}$ on a model $\IntA$ such that $\IntA(\Al)=\FalseB$ and $\IntA(\Bl)=\FalseB$.
	
	\begin{PROOF}	
		Given that $\IntA(\Bl)=\FalseB$, it follows by the negation clause of the definition of truth that $\negation{\Bl}$ is true on $\IntA$. 
		And since $\negation{\Bl}$ is true on $\IntA$, it follows by the disjunction clause of the definition of truth that $\disjunction{\Al}{\negation{\Bl}}$ is too.
	\end{PROOF}

	\begin{commentary}
		One way to compute the truth value of this sentence in $\IntA$ is to read off the values of the atomic subsentences and use definition \ref{True on a GSL interpretation} (the definition of truth in \GSL{}) to determine the value of successively larger subsentences, until finally you get the value of the whole sentence.
	\end{commentary}
		
\end{majorILnc}

\begin{majorILnc}{\LnpEC{GSLTVExampleB}}
	Give the truth value of $\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$ on a model $\IntA$ such that $\IntA(\Al)=\FalseB$, $\IntA(\Dl)=\TrueB$, $\IntA(\Bl)=\TrueB$, and $\IntA(\Gl)=\TrueB$.
	
	\begin{PROOF}
		Since $\IntA(\Gl)=\TrueB$, it follows by the negation clause of the definition of truth that $\negation{\Gl}$ is $\False$ on $\IntA$. 
		So, by the conjunction clause of the definition of truth, $\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$ is false too.
	\end{PROOF}

	\begin{commentary}
		When computing the truth value for a complicated sentence it can help to be strategic about which subsentences to look at first. Often you don't need to determine the value of every subsentence. The main connective can be an important clue about where to start. The sentence $\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$ is a conjunction, which is false on a model if any one of its conjuncts is.
	\end{commentary}
	
	We can use a construction tree to make sure we compute the truth values of the subsentences in an appropriate order.
	The idea is to start at the top of the construction tree, the truth values of which are given by the model, and work our way down the branches. 
	Let's illustrate with $\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$ on $\IntA$:
	\begin{center}
		\begin{tikzpicture}[grow=up]
		\tikzset{level distance=40pt}
		\tikzset{level 1/.style={level distance=60pt}}
		\tikzset{sibling distance=32pt}
		\tikzset{every tree node/.style={align=center,anchor=north}}
		\Tree%http://angasm.org/papers/qtree/    http://www.ling.upenn.edu/advice/latex/qtree/qtreenotes.pdf
		[.{$\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$ \textbf{[$\FalseB$]}}
		[.{$\negation{\Gl}$ \textbf{[$\FalseB$]}} %!{\qsetw{3in}}
		[.{$\Gl$ \textbf{[$\TrueB$]}}
		]
		]
		%[.{$\Gl$ /$\TrueB$\\ $\negation{\Gl}$ /$\FalseB$} %!{\qsetw{3in}}
		%%   [.{$\Gl$ /$\TrueB$}
		%%   ]
		%]
		[.{$\disjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}$ \textbf{[$\TrueB$]}} 
		[.{$\horseshoe{\Dl}{\Bl}$ \textbf{[$\TrueB$]}} 
		[.{$\Bl$ \textbf{[$\TrueB$]}} 
		]
		[.{$\Dl$ \textbf{[$\TrueB$]}} %!{\qsetw{2in}}
		] 
		]
		[.{$\Al$ \textbf{[$\FalseB$]}}
		]    
		]
		]%
		%\caption{Example formula tree}
		%\label{fig:ExampleFormulaTree}
		\end{tikzpicture}
	\end{center}
\end{majorILnc}
\begin{majorILnc}{\LnpEC{GSLTVExampleC}}
	Compute the truth value of the sentence $((\Cl \WEDGE \Dl) \HORSESHOE \Al)\TRIPLEBAR (\Dl \VEE \Hl)$ on a model $\IntA$ such that $\IntA(\Cl)=\TrueB$, $\IntA(\Dl)=\TrueB$, $\IntA(\Al)=\FalseB$, and $\IntA(\Hl)=\TrueB$.

	\begin{center}
		\begin{tikzpicture}[grow=up]
		\tikzset{level distance=42pt}
		\tikzset{sibling distance=32pt}
		\Tree%http://angasm.org/papers/qtree/    http://www.ling.upenn.edu/advice/latex/qtree/qtreenotes.pdf
		[.{$((\Cl \WEDGE \Dl) \HORSESHOE \Al)\TRIPLEBAR (\Dl \VEE \Hl)$ \textbf{[$\FalseB$]}}
		[.{$\Dl\VEE \Hl$ \textbf{[$\TrueB$]}} %!{\qsetw{3in}}
		[.{$\Hl$ \textbf{[$\TrueB$]}} %!{\qsetw{2in}}
		]  
		[.{$\Dl$ \textbf{[$\TrueB$]}}
		]
		]
		[.{$(\Cl\WEDGE \Dl)\HORSESHOE \Al$ \textbf{[$\FalseB$]}} 
		[.{$\Al$ \textbf{[$\FalseB$]}} %!{\qsetw{2in}}
		]   
		[.{$\Cl\WEDGE \Dl$ \textbf{[$\TrueB$]}}
		[.{$\Dl$ \textbf{[$\TrueB$]}} %!{\qsetw{2in}}
		]     
		[.{$\Cl$ \textbf{[$\TrueB$]}} 
		]
		]
		]
		]%
		%\caption{Example formula tree}
		%\label{fig:ExampleFormulaTree}
		\end{tikzpicture}
	\end{center}
\end{majorILnc}
%\begin{majorILnc}{\LnpEC{GSLTVExampleC}}
%
%\end{majorILnc}
 
\subsection{Truth Functions and Truth Tables}\label{Truth Functions Truth Tables and Boolean Operators}
A truth function is any function $f:\{\TrueB,\FalseB\}\times\ldots\times\{\TrueB,\FalseB\}\Rightarrow\{\TrueB,\FalseB\}$, i.e., from sequences of truth values to truth values.  The definition of truth in a model (\ref{True on a GSL interpretation}) associates each logical connective of \GSL{} with a truth function. 
For example, the truth function for $\horseshoe{}{}$ is:
\begin{center} 
	$f(\TrueB,\TrueB)=\TrueB$ \\
	$f(\TrueB,\FalseB)=\FalseB$ \\
	$f(\FalseB,\TrueB)=\TrueB$ \\
	$f(\FalseB,\FalseB)=\TrueB$ \\
\end{center}
Or, for short:
\begin{center} 
	$f(v_1,v_2)=
	\begin{cases}
	\FalseB{} & \text{ if } v_1=\TrueB\text{ and }v_2=\FalseB \\
	\TrueB{} & \text{ otherwise}
	\end{cases}$
\end{center}
A truth function can also be given as a \emph{truth table}.
The truth table for $\horseshoe{}{}$ is:
\begin{center}
	\begin{tabular}[t]{c | c c}
		$\HORSESHOE$ & $\TrueB$ & $\FalseB$ \\
		\hline
		& & \\[-.25cm]
		$\TrueB$ & $\TrueB$ & $\FalseB$ \\
		$\FalseB$ & $\TrueB$ & $\TrueB$  
	\end{tabular}
\end{center}
or can be written alternatively as:
\begin{center}
	\begin{tabular}[t]{c c c}
		$\CAPPHI$ & $\CAPPSI$ & $\horseshoe{\CAPPHI}{\CAPPSI}$ \\
		\hline 
		& & \\[-.25cm]
		$\TrueB$ & $\TrueB$ & $\TrueB$ \\
		$\TrueB$ & $\FalseB$ & $\FalseB$ \\
		$\FalseB$ & $\TrueB$ & $\TrueB$ \\
		$\FalseB$ & $\FalseB$ & $\TrueB$ \\
	\end{tabular}
\end{center}

\subsection{Logical Truth: TFT, TFF, \& TFC}\label{TFT TFF TFI}

A randomly chosen sentence will probably be true on some models and false on others. 
However, some sentences are true on all models. 
One example of such is the sentence $\disjunction{\Al}{\negation{\Al}}$.
Others are false on all models, e.g. $\conjunction{\Al}{\negation{\Al}}$.
\begin{majorILnc}{\LnpDC{GSL TFT}}
A sentence $\CAPPHI$ of \GSL{} is \nidf{truth functionally true}\index{truth!truth functional|textbf} (\CAPS{tft})\index{TFT|see{truth, truth functional}} \Iff it is $\True$ on all models for $\CAPPHI$.
\end{majorILnc}

\begin{majorILnc}{\LnpEC{TFTExampleA}}
	Prove that $\disjunction{\Al}{\negation{\Al}}$ is \CAPS{tft}.
	\begin{PROOF}
		A model $\IntA$ for $\disjunction{\Al}{\negation{\Al}}$ has to assign either $\TrueB$ or $\FalseB$ to $\Al$. 
		If it assigns $\TrueB$ to $\Al$, then $\disjunction{\Al}{\negation{\Al}}$ is true on $\IntA$.
		Otherwise it assigns $\FalseB$ to $\Al$, in which case $\negation{\Al}$ is true on $\IntA$.
		It follows that $\disjunction{\Al}{\negation{\Al}}$ is true on $\IntA$.
		Either way, the sentence is true on $\IntA$.
		This holds in all models $\IntA$, so $\disjunction{\Al}{\negation{\Al}}$ is \CAPS{tft}.		
	\end{PROOF}
\end{majorILnc}

\begin{majorILnc}{\LnpEC{TFTExampleB}}
	Prove that $\horseshoe{\Bl}{\parhorseshoe{\Cl}{\Bl}}$ is \CAPS{tft}.
	\begin{PROOF}
		Any model $\IntA$ will assign either $\TrueB$ or $\FalseB$ to $\Bl$. 
		If it assigns $\FalseB$ to $\Bl$, then $\horseshoe{\Bl}{\parhorseshoe{\Cl}{\Bl}}$ is true on $\IntA$, because, according to the def. of truth for $\HORSESHOE$, a conditional is true if the \CAPS{lhs} is false.
		If $\IntA$ assigns $\TrueB$ to $\Bl$, then $\horseshoe{\Cl}{\Bl}$ is true on $\IntA$, again because of the def. of truth for $\HORSESHOE$. 
		But if $\horseshoe{\Cl}{\Bl}$ is true on $\IntA$, it follows that $\horseshoe{\Bl}{\parhorseshoe{\Cl}{\Bl}}$ is true on $\IntA$. 
	\end{PROOF}
\end{majorILnc}%

\begin{majorILnc}{\LnpDC{GSL TFF}}
A sentence $\CAPPHI$ of \GSL{} is \nidf{truth functionally false}\index{falsehood!truth functional|textbf} (\CAPS{tff})\index{TFF|see{falsehood, truth functional}} \Iff it is $\False$ on all models for $\CAPPHI$.
\end{majorILnc}

\begin{majorILnc}{\LnpEC{TFTExampleC}}
	Prove that $\conjunction{\Al}{\negation{\Al}}$ is \CAPS{tff}. 
	\begin{PROOF}
		A model $\IntA$ for $\conjunction{\Al}{\negation{\Al}}$ has to assign either $\TrueB$ or $\FalseB$ to $\Al$. 
		If it assigns $\TrueB$ to $\Al$, then $\negation{\Al}$ is false on $\IntA$.
		So $\conjunction{\Al}{\negation{\Al}}$ is false on $\IntA$.
		But if $\IntA$ assigns $\FalseB$ to $\Al$, then $\conjunction{\Al}{\negation{\Al}}$ is false on $\IntA$. 
		Either way, the sentence is false on $\IntA$.
		This holds in all models $\IntA$, so $\conjunction{\Al}{\negation{\Al}}$ is \CAPS{tff}.
	\end{PROOF}
\end{majorILnc}

\begin{majorILnc}{\LnpEC{TFTExampleD}}
	Prove that $\conjunction{\negation{\Cl}}{\bparconjunction{\parhorseshoe{\Bl}{\Cl}}{\Bl}}$ is \CAPS{tff}.
	\begin{PROOF}
		Assume that the sentence \emph{isn't} \CAPS{tff}.
		Then there is some model $\IntA$ that makes it true.
		By def. of truth for $\WEDGE$, both $\negation{\Cl}$ and $\conjunction{\parhorseshoe{\Bl}{\Cl}}{\Bl}$ are true on $\IntA$.
		Since $\negation{\Cl}$ is true on $\IntA$, $\Cl$ is false on $\IntA$.
		Since $\conjunction{\parhorseshoe{\Bl}{\Cl}}{\Bl}$ is true on $\IntA$, then both $\horseshoe{\Bl}{\Cl}$ and $\Bl$ are true on $\IntA$.
		Thus $\Cl$ is true on $\IntA$ too.
		But $\IntA$ can't assign both $\FalseB$ and $\TrueB$ to $\Cl$.
		So there cannot be any model $\IntA$ that makes $\conjunction{\negation{\Cl}}{\bparconjunction{\parhorseshoe{\Bl}{\Cl}}{\Bl}}$ true.
		Therefore it's \CAPS{TFF}.
	\end{PROOF}

	\begin{commentary}
		This is an \emph{indirect proof}.
		To use an indirect proof, start by assuming the opposite of what you want to prove.
		Then show how that assumption leads to a contradiction.
		No contradiction can be true.
		So, if an assumption leads to a contradiction then it must be false.
		The opposite of the assumption must therefore be true.
		\commentaryspace
		Another name for indirect proof is \mention{\emph{reductio ad absurdum}} (sometimes just \mention{\emph{reductio}} or \mention{RAA}).  
		For many problems and theorems, RAA is the easiest method to use.
		It is called \mention{\emph{reductio ad absurdum}} because it `reduces' the initial assumption to a contradiction, an absurdity.
	\end{commentary}
\end{majorILnc}

\begin{majorILnc}{\LnpDC{GSL TFI}}
A sentence $\CAPPHI$ of \GSL{} is \nidf{truth functionally contingent}\index{indeterminate!truth functional|textbf} (\CAPS{tfc})\index{TFI|see{indeterminate, truth functional}} \Iff it is $\True$ on one model for $\CAPPHI$ and $\False$ on another. 
\end{majorILnc}

\begin{majorILnc}{\LnpEC{TFTExampleE}}
In example \mvref{GSLTVExampleA} we saw that the sentence $\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$ is false on one model.
To see that it can also be true, and thus that the sentence is \CAPS{tfc}, consider the following model: $\IntA(\Al)=\FalseB$, $\IntA(\Dl)=\TrueB$, $\IntA(\Bl)=\TrueB$, and $\IntA(\Gl)=\TrueB$.
Convince yourself that $\IntA$ makes $\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$ true. 
\end{majorILnc}

\noindent{}Every sentence of \GSL{} is either \CAPS{tft}, \CAPS{tff}, or \CAPS{tfc}.

Although the definitions of \CAPS{tft}, \CAPS{tff}, and \CAPS{tfc} are specific to \GSL{}---the models to which each definition refers are models of \GSL{}---we can use essentially the same definitions for \emph{any} formal language, as long as there is some notion of a model for that language. 
We can think of sentences which fit these definitions as being (respectively) \niidf{logically true}\index{logical!truth}\index{truth!logical}, \niidf{logically false}\index{logical!falsehood}\index{falsehood!logical}, and \niidf{logically contingent}\index{logical!indeterminate}\index{indeterminate!logical}. Hereafter we'll sometimes use the more general term \mention{logical truth} instead of \mention{truth functional truth}.\footnote{
	A logical truth is sometimes said to be \niidf{valid}, or said to be a \niidf{tautology}.\index{sentence!valid|see{truth, logical}}\index{tautology|see{truth, logical}} 
	We avoid using these terms for logical truths.
}

\subsection{Procedures for Testing TFT, TFF, \& TFC}\label{Proceduresfortesting}

In the above examples (\ref{TFTExampleA}--\ref{TFTExampleD}) we used the definition for truth (definition \mvref{True on a GSL interpretation}) to show whether a given \GSL{} sentence was \CAPS{tft}, \CAPS{tff}, or \CAPS{tfc}. 
But there are more systematic methods for classifying \GSL{} sentences. 

Perhaps the most well known method involves using truth tables.%
\footnote{%
	Peirce \citeyearpar{Peirce1902} was the first to use truth tables. See Hodges \citeyearpar[5]{Hodges2001}.
} 
Later in this chapter we prove theorem \mvref{thm:localityoftruth}, which says that the truth of a given \GSL{} sentence $\CAPPHI$ can be determined by a \emph{minimal model}.
Remember that a minimal model for $\CAPPHI$ assigns truth values only to the sentence letters appearing in $\CAPPHI$.
One way to test whether $\CAPPHI$ is \CAPS{tft}, \CAPS{tff}, or \CAPS{tfc} is to write down all the possible assignments of truth values to the sentence letters of $\CAPPHI$, then compute the truth value of $\CAPPHI$ for each assignment. 
The number of possible assignments (minimal models) is finite. 
For a sentence $\CAPPHI$ with $\integer{n}$ sentence letters (counted by type) there are $2^{\integer{n}}$ possible assignments. 
If $\CAPPHI$ is true in all assignments, then $\CAPPHI$ is \CAPS{tft}.  
If it's false in all of them, then $\CAPPHI$ is \CAPS{tff}. 
And if it is true in some assignments and false in others, then $\CAPPHI$ is \CAPS{tfc}. 

Consider the sentence $\conjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$.
Because this sentence has 4 sentence letters its table has $2^4=16$ rows. 
First write the 4 sentence letters on a top row.
Then fill out the assignments by starting at the far right sentence letter ($\Gl$) and putting alternating $\TrueB$'s and $\FalseB$'s below it until all 16 rows are filled. (See table \ref{truthtableexample}.) 
\begin{table}[!ht]
\begin{center}
\begin{tabular}{ c c c c c}
$\Al$ & $\Bl$ & $\Dl$ & $\Gl$ & $\parconjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$ \\
\hline
$ $ & $ $ & & & \\[-.25cm]
$\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ & $\FalseB$ \\
$\TrueB$ & $\TrueB$ & $\TrueB$ & $\FalseB$& $\TrueB$ \\
$\TrueB$ & $\TrueB$ & $\FalseB$ & $\TrueB$ & $\FalseB$ \\
$\TrueB$ & $\TrueB$ & $\FalseB$ & $\FalseB$  & $\TrueB$ \\
$\TrueB$ &  $\FalseB$& $\TrueB$ & $\TrueB$	&$\FalseB$ \\
$\TrueB$ & $\FalseB$ & $\TrueB$ & $\FalseB$	& $\TrueB$  \\
$\TrueB$ &$\FalseB$  & $\FalseB$& $\TrueB$	&$\FalseB$ \\
$\TrueB$ & $\FalseB$ &$\FalseB$	& $\FalseB$	& $\TrueB$ \\
$\FalseB$	& $\TrueB$ & $\TrueB$ & $\TrueB$	& $\FalseB$ \\
$\FalseB$	& $\TrueB$ & $\TrueB$ & $\FalseB$	& $\TrueB$ \\
$\FalseB$	& $\TrueB$ & $\FalseB$&	$\TrueB$ &$\FalseB$ \\
$\FalseB$	& $\TrueB$ & $\FalseB$& $\FalseB$	& $\TrueB$ \\
$\FalseB$	& $\FalseB$	& $\TrueB$ & $\TrueB$	&$\FalseB$ \\
$\FalseB$	& $\FalseB$	& $\TrueB$ & $\FalseB$	& $\FalseB$ \\
$\FalseB$	& $\FalseB$	& $\FalseB$& $\TrueB$	& $\FalseB$ \\
$\FalseB$	& $\FalseB$& $\FalseB$& $\FalseB$	& $\TrueB$ \\
\end{tabular}
\end{center}
\caption{Sample Truth Table}
\label{truthtableexample}
\end{table}
Next, move to the second-to-the-right sentence letter ($\Dl$) and alternate by 2 $\TrueB$'s and 2 $\FalseB$'s for 16 rows. 
Move one more sentence letter to the left ($\Bl$) and alternate $\TrueB$'s and $\FalseB$'s 4 at a time. 
Finally, alternate by 8 at a time for the left-most sentence letter ($\Al$).
This completes the 16 rows so that each row is a unique assignment of truth values to the sentence letters.
All 16 possible assignments are guaranteed to to be present.
In general the pattern is to start at the far right column alternating $\TrueB$ and $\FalseB$, then move to the left doubling the number of $\TrueB$'s and $\FalseB$'s that appeared in the previous column. 

Then we write the sentence to the right of the sentence letters and under it put, in the respective rows, its truth value for each assignment. 
Once the truth value of the sentence is computed for all rows it's a trivial matter to determine from the table whether the sentence is \CAPS{tft}, \CAPS{tff}, or \CAPS{tfc}. 
If $\TrueB$ is under the sentence in every row, then it's \CAPS{tft}. 
If $\FalseB$ is in every row, then it's \CAPS{tff}.
And if each of $\TrueB$ and $\FalseB$ appear in at least one row, then it's \CAPS{tfc}. 
Table \ref{truthtableexample} shows that $\parconjunction{\cpardisjunction{\Al}{\parhorseshoe{\Dl}{\Bl}}}{\negation{\Gl}}$ is \CAPS{tfc}.

The process of filling out a truth table is entirely \mention{mechanical.}
We can carry out the process by following purely formal rules.
Once we have a truth table for some \GSL{} sentence, we can again use purely formal rules to determine whether it's \CAPS{tft}, \CAPS{tff}, or \CAPS{tfc}.
No creativity is necessary to determine whether any given sentence is, e.g., \CAPS{tft}.

\begin{majorILnc}{\LnpEC{TFTExampleA2}}
We saw in example \mvref{TFTExampleA} that $\conjunction{\Al}{\negation{\Al}}$ is \CAPS{tff}. 
The following truth table confirms this. 
\begin{center}
\begin{tabular}{ c c }
$\Al$ & $\conjunction{\Al}{\negation{\Al}}$ \\
\hline
$ $ & $ $ \\[-.25cm]
$\TrueB$ & $\FalseB$ \\
$\FalseB$ & $\FalseB$ \\
\end{tabular}
\end{center}
\end{majorILnc}
\begin{majorILnc}{\LnpEC{TFTExampleD2}}
In example \mvref{TFTExampleD} we saw that $\horseshoe{\Bl}{\parhorseshoe{\Cl}{\Bl}}$ is \CAPS{tft}.
This is confirmed by the following truth table. 
\begin{center}
\begin{tabular}{ c c c }
$\Bl$ & $\Cl$ & $\horseshoe{\Bl}{\parhorseshoe{\Cl}{\Bl}}$ \\
\hline
$ $ & $ $ & $ $ $ $ \\[-.25cm]
$\TrueB$ & $\TrueB$ & $\TrueB$ \\
$\TrueB$ & $\FalseB$& $\TrueB$ \\
$\FalseB$ & $\TrueB$ & $\TrueB$ \\
$\FalseB$ & $\FalseB$  & $\TrueB$ \\
\end{tabular}
\end{center}
\end{majorILnc}
\begin{majorILnc}{\LnpEC{TFTExampleF2}}
The sentence $\conjunction{\negation{\Cl}}{\bparconjunction{\parhorseshoe{\Bl}{\Cl}}{\Bl}}$ is \CAPS{tff}.
The following truth table proves it.  
\begin{center}
\begin{tabular}{ c c c }
$\Bl$ & $\Cl$ & $\conjunction{\negation{\Cl}}{\bparconjunction{\parhorseshoe{\Bl}{\Cl}}{\Bl}}$ \\
\hline
$ $ & $ $ & \\[-.25cm]
$\TrueB$ & $\TrueB$ & $\FalseB$ \\
$\TrueB$ & $\FalseB$& $\FalseB$ \\
$\FalseB$ & $\TrueB$ & $\FalseB$ \\
$\FalseB$ & $\FalseB$  & $\FalseB$ \\
\end{tabular}
\end{center}
\end{majorILnc} 

While truth tables are a convenient method for answering many questions about \GSL{} sentences, two warnings are in order.
First, for complex sentences the size of the truth table can be very large.
The number of rows needed for a truth table grows exponentially with the number of sentence letters.
Second, while truth tables are useful in \GSL{}, there is nothing comparable for the more sophisticated formal languages we cover in later chapters.
The sooner you learn to analyze sentences directly, rather than relying on a truth table, the better.
For example, consider the sentence $\disjunction{\parhorseshoe{\El}{\parconjunction{\Bl}{\negation{\pardisjunction{\Cl}{\Dl}}}}}{\parhorseshoe{\Al}{\Al}}$.
You \emph{could} evaluate this sentence with a 32 line truth table.
But it's much easier to prove that $\parhorseshoe{\Al}{\Al}$ is \CAPS{tft}, and then to show that it follows that the whole sentence is \CAPS{tft}.

The various formal derivation systems used in logic provide another class of procedures for testing \GSL{} sentences for \CAPS{tft} and \CAPS{tff}.
In chapter \ref{Derivations} we develop one such system.\footnote{
	We use a natural deduction system\index{natural deduction}.
	Natural deduction systems do not provide a procedure for testing whether sentences are \CAPS{tfc}.
	Some derivation systems---e.g. semantic tableaux systems---do. 
	A comprehensive introductory treatment of semantic tableaux (called truth trees by the author) is given in Nicholas J.J. Smith's \citeyearpar{Smith2012} textbook \emph{Logic: The Laws of Truth}. 
	Smith also gives a more detailed and thorough introduction to truth tables. 
	Other derivation systems, such as Hilbert-style axiomatic systems, and Gentzen-style sequent calculi, don't on their own provide direct means of testing for \CAPS{tfc} sentences. 
}
We also develop an algorithm in chapter \ref{completenesschapter} that can be used with our derivation system as a testing procedure for \CAPS{tfc} sentences.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Entailment and other Relations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Entailment}\label{Entailment}
Now we turn to the notion of entailment. 
We write that a set of sentences $\Delta$ entails a single sentence $\CAPTHETA$ as follows: \mention{\:$\Delta\sdtstile{}{}\CAPTHETA\:$}.
The symbol \mention{$\:\sdtstile{}{}\:$}, called the double turnstile,\index{double turnstile}\index{$\sdtstile{}{}$} is \emph{not} a symbol of \GSL{}. 
Like the Greek letters it is a symbol of MathEnglish.

\begin{majorILnc}{\LnpDC{GSL Generalized Further Entailment}}
	If $\Delta$ is a set of \GSL{} sentences and $\CAPTHETA$ is an \GSL{} sentence, then the following are equivalent ways to define when $\Delta$ entails $\CAPTHETA$:
	\begin{cenumerate}
		\item $\Delta\sdtstile{}{}\CAPTHETA$ \Iff every model for $\Delta$ and $\CAPTHETA$ that makes all sentences in $\Delta$ $\True$ also makes $\CAPTHETA$ $\True$.
		\item $\Delta\sdtstile{}{}\CAPTHETA$ \Iff every model for $\Delta$ and $\CAPTHETA$ either makes at least one sentence in $\Delta$ $\False$ or makes $\CAPTHETA$ $\True$.
	\end{cenumerate}
\end{majorILnc}

\noindent{}Each of the following is a consequence of the definition of entailment for the case in which $\Delta$ is of finite size $n$:

\begin{cenumerate}
		\item $\CAPPHI_1,\CAPPHI_2,\CAPPHI_3,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\CAPTHETA$ \Iff every model for $\CAPPHI_1$, $\CAPPHI_2$, $\CAPPHI_3$, $\ldots$, $\CAPPHI_{\integer{n}}$, and $\CAPTHETA$ that makes all of $\CAPPHI_1$, $\CAPPHI_2$, $\CAPPHI_3$, $\ldots$ $\CAPPHI_{\integer{n}}$ $\True$ also makes $\CAPTHETA$ $\True$.
		\item $\CAPPHI_1,\CAPPHI_2,\CAPPHI_3,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\CAPTHETA$ \Iff every model for $\CAPPHI_1$, $\CAPPHI_2$, $\CAPPHI_3$, $\ldots$, $\CAPPHI_{\integer{n}}$, and $\CAPTHETA$ either makes at least one of $\CAPPHI_1$, $\CAPPHI_2$, $\CAPPHI_3$, $\ldots$ $\CAPPHI_{\integer{n}}$ $\False$ or makes $\CAPTHETA$ $\True$.
\end{cenumerate}

\noindent{}Each of the following is another consequence, for the case in which $\Delta$ contains just one sentence:

\begin{cenumerate}
\item A sentence $\CAPPHI$ {entails} another sentence $\CAPTHETA$ \Iff every model for $\CAPPHI$ and $\CAPTHETA$ that makes $\CAPPHI$ $\True$ also makes $\CAPTHETA$ $\True$.
\item A sentence $\CAPPHI$ {entails} another sentence $\CAPTHETA$ \Iff there is no model for $\CAPPHI$ and $\CAPTHETA$ that makes $\CAPPHI$ $\True$ and $\CAPTHETA$ $\False$.
\end{cenumerate}

\noindent{}Finally, $\Delta$ can be the empty set or an infinite set.
When $\Delta$ is empty and $\Delta\:\sdtstile{}{}\CAPTHETA$ we can write: $\:\sdtstile{}{}\CAPTHETA$.

\begin{THEOREM}{\LnpTC{entailmentTFT theorem}}
	For all \GSL{} sentences $\CAPTHETA$, $\:\sdtstile{}{}\CAPTHETA$ \Iff $\CAPTHETA$ is \CAPS{tft}.
\end{THEOREM} 
\begin{PROOF}
	($\Rightarrow$) Assume that $\:\sdtstile{}{}\CAPTHETA$.
	Then, by the definition of $\sdtstile{}{}$, every model for $\CAPTHETA$ either makes a sentence to the left of the turnstile $\False$ or makes $\CAPTHETA$ true. 
	But there are no sentences to the left of the turnstile.
	So, every model for $\CAPTHETA$ makes $\CAPTHETA$ true.
	Thus $\CAPTHETA$ is \CAPS{tft}.

	($\Leftarrow$) Assume that $\CAPTHETA$ is \CAPS{tft}.
	Then there is no model that makes $\CAPTHETA$ false.
	Let $\Delta$ be the empty set.
	Then there is no model that makes all sentences in $\Delta$ true and $\CAPTHETA$ false.
	So, by the definition of $\sdtstile{}{}$, $\Delta\:\sdtstile{}{}\CAPTHETA$.
	And since $\Delta$ is empty, $\:\sdtstile{}{}\CAPTHETA$.

	Therefore $\:\sdtstile{}{}\CAPTHETA$ \Iff $\CAPTHETA$ is \CAPS{tft}.
\end{PROOF}
\begin{commentary}
	The statement of this theorem is a biconditional, i.e. a sentence of the form $\Al$ iff $\Bl$.
	The typical method for proving biconditionals is to divide the proof into two parts.
	In the first part, indicated by \mention{($\Rightarrow$)}, assume $\Al$ and show that $\Bl$ follows.
	In the second part, indicated by \mention{($\Leftarrow$)}, assume $\Bl$ and show that $\Al$ follows.
	After both parts are demonstrated, then conclude that $\Al$ iff $\Bl$.
\end{commentary}

\begin{majorILnc}{\LnpEC{GSLEntailmentExA}}
Prove $\parconjunction{\Al}{\Bl}\sdtstile{}{}\Bl$. 
\end{majorILnc}
\begin{PROOF}
Let $\IntA$ be a model that makes $\parconjunction{\Al}{\Bl}$ true. 
By the definition of truth for $\WEDGE$---clause 3, \mvref{True on a GSL interpretation}---both $\Al$ and $\Bl$ are true in $\IntA$ as well. 
Thus any model that makes $\parconjunction{\Al}{\Bl}$ true also makes $\Bl$ true.
Therefore, by the definition of $\sdtstile{}{}$, $\parconjunction{\Al}{\Bl}\sdtstile{}{}\Bl$.
\end{PROOF}
\begin{commentary}
	One method for proving an entailment is to assume a model that makes all sentences to the left of the turnstile true, and then to show that the sentence on the right must therefore also be true.
\end{commentary}

\begin{majorILnc}{\LnpEC{GSLEntailmentExB}}
Show that $\Bl\sdtstile{}{}\pardisjunction{\Al}{\Bl}$. We leave this as an exercise the reader.
\end{majorILnc}
\begin{majorILnc}{\LnpEC{GSLEntailmentExC}}
Show that for all $\CAPPHI$ there is some $\CAPTHETA$ such that $\CAPPHI\sdtstile{}{}\CAPTHETA$. That is, that every \GSL{} sentence entails at least one \GSL{} sentence.
\end{majorILnc}
\begin{PROOF}
	Let $\CAPPHI$ be any \GSL{} sentence.
	Then let $\CAPTHETA=\CAPPHI$.
	Then there is no model that makes $\CAPPHI$ true and $\CAPTHETA$ false, since they are the same sentence.
	Therefore, by the definition of $\sdtstile{}{}$, $\CAPPHI\sdtstile{}{}\CAPTHETA$.
	Nothing particular was assumed about $\CAPPHI$, so the argument holds for all \GSL{} sentences.
\end{PROOF}
\begin{commentary}
	We must show that no matter what \GSL{} sentence $\CAPPHI$ you pick, there's always some \GSL{} sentence $\CAPTHETA$ entailed by it.
	But this is easy: every \GSL{} sentence entails itself.
	Thus, no matter what \GSL{} sentence you pick there's always at least one sentence entailed by it.
\end{commentary}

\begin{majorILnc}{\LnpEC{GSLEntailmentExD}}
Show that there is some $\CAPTHETA$ such that for all $\CAPPHI$, $\CAPPHI\sdtstile{}{}\CAPTHETA$. That is, show there's some \GSL{} sentence that's entailed by all \GSL{} sentences.
\end{majorILnc}
\begin{PROOF}
	Let $\CAPTHETA$ be $\pardisjunction{\Al}{\negation{\Al}}$. 
	It was shown previously that $\pardisjunction{\Al}{\negation{\Al}}$ is \CAPS{tft}.
	Then, by the definition of \CAPS{tft}, $\CAPTHETA$ is true on all models.
	So there is no model such that $\CAPPHI$ is true and $\CAPTHETA$ is false.
	Thus, by the definition of $\sdtstile{}{}$, $\CAPPHI\sdtstile{}{}\CAPTHETA$.
	This argument holds for all $\CAPPHI$.
\end{PROOF}

\begin{majorILnc}{\LnpEC{GSLEntailmentExE}}
Show that there is some $\CAPPHI$ such that, for all $\CAPTHETA$, $\CAPPHI\sdtstile{}{}\CAPTHETA$. We leave the proof as an exercise for the reader.
\end{majorILnc}

\subsection{Procedures for Testing Entailment}\label{TestingEntailment}

In the previous examples (\ref{GSLEntailmentExA}--\ref{GSLEntailmentExE}) we used the definition of entailment to prove entailment claims. 
But there are other methods for checking whether a given entailment holds.
Truth tables provide a simple, mechanical procedure.

To test whether a set of sentences $\Delta$ entails a sentence $\CAPTHETA$, we first write down all the sentence letters of $\CAPTHETA$ and $\Delta$. 
We put these on the left side of the truth table and under them (following the procedure outlined in section \pmvref{Proceduresfortesting}) we write all the possible assignments of truth values. 
Then, to the right of the sentence letters, we write each of the sentences from $\Delta$ (in separate columns), and to the right of those we write $\CAPTHETA$. 
Under $\CAPTHETA$ and each of the sentences from $\Delta$ we write the truth value of that sentence based on the assignment of truth values listed in that row. 
$\Delta$ entails $\CAPTHETA$ iff there is no row in the truth table in which all the sentences in $\Delta$ are true and $\CAPTHETA$ is false.
Any rows of the truth table that do not make all of the \CAPS{lhs} sentences true are irrelevant.
After marking one of the \CAPS{lhs} sentences as false we can omit the rest of the row.
\begin{majorILnc}{\LnpEC{GSLEntailmentExA2}}
In example \ref{GSLEntailmentExA} we saw that $\parconjunction{\Al}{\Bl}\sdtstile{}{}\Bl$. 
We show this with a truth table.  
\begin{center}
\begin{tabular}{ c c c c }
$\Al$ & $\Bl$ & $\parconjunction{\Al}{\Bl}$ & $\Bl$ \\
\hline
$ $ & $ $ & & \\[-.25cm]
$\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ \\
$\TrueB$ & $\FalseB$& $\FalseB$ & $\FalseB$ \\
$\FalseB$ & $\TrueB$ & $\FalseB$ & $\TrueB$ \\
$\FalseB$ & $\FalseB$  & $\FalseB$ & $\FalseB$ \\
\end{tabular}
\end{center}
\end{majorILnc}
\begin{majorILnc}{\LnpEC{GSLEntailmentExB2}}
In example \ref{GSLEntailmentExB} we said that $\Bl\sdtstile{}{}\pardisjunction{\Al}{\Bl}$. 
The following truth table shows this. 
\begin{center}
\begin{tabular}{ c c c c }
$\Al$ & $\Bl$ & $\Bl$ & $\pardisjunction{\Al}{\Bl}$ \\
\hline
$ $ & $ $ & & \\[-.25cm]
$\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ \\
$\TrueB$ & $\FalseB$& $\FalseB$ & $\TrueB$ \\
$\FalseB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ \\
$\FalseB$ & $\FalseB$  & $\FalseB$ & $\FalseB$ \\
\end{tabular}
\end{center}
\end{majorILnc}
\begin{majorILnc}{\LnpEC{GSLEntailmentExAA}}
We conclude with a more complicated example. 
Here we show that $\disjunction{\Al}{\Bl},\horseshoe{\negation{\Cl}}{\negation{\Al}},\horseshoe{\Bl}{\Cl}\sdtstile{}{}\Cl$.
\begin{center}
\begin{tabular}{ c c c c c c c }
$\Al$ & $\Bl$ & $\Cl$ & $\disjunction{\Al}{\Bl}$ & $\horseshoe{\negation{\Cl}}{\negation{\Al}}$ & $\horseshoe{\Bl}{\Cl}$ & $\Cl$ \\
\hline
$ $ & $ $ & & & & & \\[-.25cm]
$\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$\\
$\TrueB$ & $\TrueB$ & $\FalseB$& $\TrueB$ & $\FalseB$ & $\FalseB$ &  $\FalseB$\\
$\TrueB$ & $\FalseB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ &  $\TrueB$\\
$\TrueB$ & $\FalseB$ & $\FalseB$  & $\TrueB$ & $\FalseB$ & $\TrueB$ & $\FalseB$\\
$\FalseB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$\\
$\FalseB$ & $\TrueB$ & $\FalseB$& $\TrueB$ & $\TrueB$ & $\FalseB$ & $\FalseB$\\
$\FalseB$ & $\FalseB$ & $\TrueB$ & $\FalseB$ & $\TrueB$ & $\TrueB$ & $\TrueB$\\
$\FalseB$ & $\FalseB$ & $\FalseB$  & $\FalseB$ & $\TrueB$ & $\TrueB$ & $\FalseB$\\
\end{tabular}
\end{center}
\end{majorILnc}

\subsection{Basic Results on Entailment}\label{Basic Results on Entailment} 
A simple, but important theorem involves moving sentences from one side of the turnstile to the other.
\begin{THEOREM}{\LnpTC{Exponentiation of Entailment} \GSL{} Exportation Theorem:} For all \GSL{} sentences $\CAPPHI$ and $\CAPTHETA$, $\CAPPHI\sdtstile{}{}\CAPTHETA$ \Iff $\:\sdtstile{}{}\horseshoe{\CAPPHI}{\CAPTHETA}$.
\end{THEOREM}
\begin{commentary}
	The statement of this theorem is a biconditional, so we prove it as we proved the last biconditional theorem.
	There are two parts.
	First, we assume that the left-hand side, $\CAPPHI\sdtstile{}{}\CAPTHETA$, is true, and show that $\:\sdtstile{}{}\horseshoe{\CAPPHI}{\CAPTHETA}$ follows from it. 
	Second, we assume that $\:\sdtstile{}{}\horseshoe{\CAPPHI}{\CAPTHETA}$ is true, and show that $\CAPPHI\sdtstile{}{}\CAPTHETA$ follows.
	That is sufficient to demonstrate that $\CAPPHI\sdtstile{}{}\CAPTHETA$ \Iff $\:\sdtstile{}{}\horseshoe{\CAPPHI}{\CAPTHETA}$.
\end{commentary}
\begin{PROOF}
$(\Rightarrow)$ Assume that $\CAPPHI\sdtstile{}{}\CAPTHETA$.
Then, by the definition of $\:\sdtstile{}{}$ it follows that on every model on which $\CAPPHI$ is true, $\CAPTHETA$ is also true.
According to the definition of truth for $\HORSESHOE$, $\IntA$ makes $\parhorseshoe{\CAPPHI}{\CAPTHETA}$ false only if it makes $\CAPPHI$ true and $\CAPTHETA$ false.
But we have already shown that there is no such model.
It follows that $\parhorseshoe{\CAPPHI}{\CAPTHETA}$ is \CAPS{tft} (def. of \CAPS{tft}, \pmvref{GSL TFT}).
And according to theorem \mvref{entailmentTFT theorem}, it follows that the entailment $\:\sdtstile{}{}\parhorseshoe{\CAPPHI}{\CAPTHETA}$ holds.

$(\Leftarrow)$ Assume that $\:\sdtstile{}{}\parhorseshoe{\CAPPHI}{\CAPTHETA}$.
By the definition of $\:\sdtstile{}{}$, since $\:\sdtstile{}{}\parhorseshoe{\CAPPHI}{\CAPTHETA}$ it follows that $\parhorseshoe{\CAPPHI}{\CAPTHETA}$ is \CAPS{tft}.  So, by the definition of \CAPS{tft}, $\parhorseshoe{\CAPPHI}{\CAPTHETA}$ is true on every model $\IntA$.
By the definition of truth of $\HORSESHOE$, it follows that there is no model that makes $\CAPPHI$ true and $\CAPTHETA$ false.  So, by the definition of $\:\sdtstile{}{}$, that means that $\CAPPHI\sdtstile{}{}\CAPTHETA$.
\end{PROOF}

There are a number of other theorems that are similar to, and expand upon, theorem \ref{Exponentiation of Entailment}. Here we state them and leave the proofs to the reader.
\begin{THEOREM}
{\LnpTC{expo generalizations}}
\begin{cenumerate}
\item If $\CAPPHI_1$, $\CAPPHI_2$, $\ldots$, $\CAPPHI_{\integer{n}}$ and $\CAPPSI$ are \GSL{} sentences, then
\begin{itemize}
\item[] $\CAPPHI_1,\CAPPHI_2,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\CAPPSI$ \Iff $\CAPPHI_2,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\parhorseshoe{\CAPPHI_1}{\CAPPSI}$
\item[] $\CAPPHI_1,\CAPPHI_2,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\CAPPSI$ \Iff $\CAPPHI_1,\CAPPHI_3,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\parhorseshoe{\CAPPHI_2}{\CAPPSI}$
\item[] \hspace{1in} $\vdots$
\item[] $\CAPPHI_1,\CAPPHI_2,\ldots,\CAPPHI_{n}\sdtstile{}{}\CAPPSI$ \Iff $\CAPPHI_1,\ldots,\CAPPHI_{n-1}\sdtstile{}{}\parhorseshoe{\CAPPHI_{\integer{n}}}{\CAPPSI}$
\end{itemize} 
\item If $\CAPPHI_1$, $\CAPPHI_2$, $\ldots$, $\CAPPHI_{\integer{n}}$ and $\CAPPSI$ are \GSL{} sentences, then
\begin{itemize}
\item[] $\CAPPHI_1,\CAPPHI_2,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\CAPPSI$ \Iff $\CAPPHI_1,\ldots,\CAPPHI_{n-1}\sdtstile{}{}\parhorseshoe{\CAPPHI_{\integer{n}}}{\CAPPSI}$
\item[] $\CAPPHI_1,\CAPPHI_2,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\CAPPSI$ \Iff $\CAPPHI_1,\ldots,\CAPPHI_{n-2}\sdtstile{}{}\parhorseshoe{\CAPPHI_{n-1}}{\parhorseshoe{\CAPPHI_{\integer{n}}}{\CAPPSI}}$
\item[] \hspace{1in} $\vdots$
\item[] $\CAPPHI_1,\CAPPHI_2,\ldots,\CAPPHI_{n}\sdtstile{}{}\CAPPSI$ \Iff $\sdtstile{}{}\parhorseshoe{\CAPPHI_1}{\parhorseshoe{\ldots}{\parhorseshoe{\CAPPHI_{n-1}}{\parhorseshoe{\CAPPHI_{\integer{n}}}{\CAPPSI}}}}$
\end{itemize}
\item If $\CAPPHI$ and $\CAPPSI$ are \GSL{} sentences and $\Delta$ is a set of \GSL{} sentences containing $\CAPPHI$ (i.e, $\CAPPHI\in\Delta$) and $\Delta^*$ is $\Delta$ with $\CAPPHI$ removed, then $\Delta\sdtstile{}{}\CAPPSI$ \Iff $\Delta^*\sdtstile{}{}\parhorseshoe{\CAPPHI}{\CAPPSI}$.
\item If $\CAPPHI$ and $\CAPPSI$ are \GSL{} sentences, then $\CAPPHI\sdtstile{}{}\CAPPSI$ \Iff $\CAPPHI,\negation{\CAPPSI}\sdtstile{}{}\parconjunction{\Al}{\negation{\Al}}$.
\item If $\CAPPHI_1,\ldots,\CAPPHI_{\integer{n}}$ and $\CAPPSI_1,\ldots,\CAPPSI_{\integer{n}}$ are all \GSL{} sentences, then
\begin{itemize}
\item[] $\CAPPHI_1,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\pardisjunction{\CAPPSI_1}{\disjunction{\ldots}{\CAPPSI_{\integer{n}}}}$ \Iff $\CAPPHI_1,\ldots,\CAPPHI_{\integer{n}},\negation{\CAPPSI_1}\sdtstile{}{}\pardisjunction{\CAPPSI_2}{\disjunction{\ldots}{\CAPPSI_{\integer{n}}}}$
\item[] $\CAPPHI_1,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\pardisjunction{\CAPPSI_1}{\disjunction{\ldots}{\CAPPSI_{\integer{n}}}}$ \Iff $\CAPPHI_1,\ldots,\CAPPHI_{\integer{n}},\negation{\CAPPSI_2}\sdtstile{}{}\pardisjunction{\CAPPSI_1}{\disjunction{\CAPPSI_3}{\disjunction{\ldots}{\CAPPSI_{\integer{n}}}}}$
\item[] \hspace{1in} $\vdots$
\item[] $\CAPPHI_1,\ldots,\CAPPHI_{\integer{n}}\sdtstile{}{}\pardisjunction{\CAPPSI_1}{\disjunction{\ldots}{\CAPPSI_{\integer{n}}}}$ \Iff $\CAPPHI_1,\ldots,\CAPPHI_{\integer{n}},\negation{\CAPPSI_{\integer{n}}}\sdtstile{}{}\pardisjunction{\CAPPSI_1}{\disjunction{\ldots}{\CAPPSI_{n-1}}}$
\end{itemize} 
\end{cenumerate}
\end{THEOREM}

\subsection{Other Relations}\label{Other Relations}

There are a number of other important relations between \GSL{} sentences:

\begin{majorILnc}{\LnpDC{GSL TFE}}
Two sentences $\CAPTHETA$ and $\CAPPHI$ are \index{equivalent sentences!truth functional|textbf} \nidf{truth functionally equivalent} (\CAPS{tfe}) \Iff for all models $\IntA$ for $\CAPTHETA$ and $\CAPPHI$, $\CAPTHETA$ and $\CAPPHI$ have the same truth value on $\IntA$.
\end{majorILnc}

\begin{THEOREM}{\LnpTC{tfe entailment}}
$\CAPTHETA$ and $\CAPPHI$ are \CAPS{tfe} \Iff $\CAPTHETA\sdtstile{}{}\CAPPHI$ and $\CAPPHI\sdtstile{}{}\CAPTHETA$.
\begin{PROOF}
	($\Rightarrow$) Assume that $\CAPTHETA$ and $\CAPPHI$ are \CAPS{tfe}.
	Then, by the definition of \CAPS{tfe}, there is no model on which $\CAPTHETA$ and $\CAPPHI$ have different truth values.
	So there is no model on which $\CAPTHETA$ is true and $\CAPPHI$ is false.
	Then, by the definition of $\entails$, $\CAPTHETA\entails\CAPPHI$.
	And there is no model on which $\CAPPHI$ is true and $\CAPTHETA$ is false.
	Then, by the definition of $\entails$, $\CAPPHI\entails\CAPTHETA$.

	($\Leftarrow$) Assume that $\CAPTHETA\sdtstile{}{}\CAPPHI$ and $\CAPPHI\sdtstile{}{}\CAPTHETA$.
	Since $\CAPTHETA\sdtstile{}{}\CAPPHI$, then by the definition of $\entails$ every model that makes $\CAPTHETA$ true also makes $\CAPPHI$ true.
	And since $\CAPPHI\sdtstile{}{}\CAPTHETA$, then by the definition of $\entails$ every model that makes $\CAPPHI$ true also makes $\CAPTHETA$ true.
	Since each sentence is true when the other is, and a sentence is false \Iff it's not true, $\CAPTHETA$ and $\CAPPHI$ must be the same value on all models.
	So they are \CAPS{tfe}
\end{PROOF}
\end{THEOREM}

\begin{majorILnc}{\LnpDC{GSL Contradictory}}
Two sentences $\CAPTHETA$ and $\CAPPHI$ are \nidf{truth functionally contradictory}\index{contradictory!truth functional|textbf} \Iff for all models $\IntA$ for $\CAPTHETA$ and $\CAPPHI$, $\CAPTHETA$ and $\CAPPHI$ have opposite truth values on $\IntA$.
\end{majorILnc}

\begin{THEOREM}{\LnpTC{tf contradictory entailment}}
	$\CAPTHETA$ and $\CAPPHI$ are truth functionally contradictory \Iff $\CAPTHETA$ is \CAPS{tfe} to $\negation{\CAPPHI}$.
	\begin{PROOF}
		($\Rightarrow$) Assume that $\CAPTHETA$ and $\CAPPHI$ are truth functionally contradictory.
		Then $\CAPTHETA$ and $\CAPPHI$ have opposite truth values on all models.
		By the definition of truth for $\negation{}$, $\CAPPHI$ and $\negation{\CAPPHI}$ have opposite truth values on all models.
		So on a model that makes $\CAPTHETA$ true, $\CAPPHI$ is false and $\negation{\CAPPHI}$ is true.
		And on a model that makes $\CAPTHETA$ false, $\CAPPHI$ is true and $\negation{\CAPPHI}$ is false.
		It follows that $\CAPTHETA$ and $\negation{\CAPPHI}$ have the same value on all models.
		Thus, by the definition of \CAPS{tfe}, $\CAPTHETA$ is \CAPS{tfe} to $\negation{\CAPPHI}$.
	
		($\Leftarrow$) Assume that $\CAPTHETA$ is \CAPS{tfe} to $\negation{\CAPPHI}$.
		Then by the definition of \CAPS{tfe} $\CAPTHETA$ and $\negation{\CAPPHI}$ have the same truth value on all models.
		By the definition of truth for $\negation{}$, $\CAPPHI$ and $\negation{\CAPPHI}$ have opposite truth values on all models.
		So on a model that makes $\CAPTHETA$ true, $\CAPPHI$ is true and $\negation{\CAPPHI}$ is false.
		And on a model that makes $\CAPTHETA$ false, $\CAPPHI$ is false and $\negation{\CAPPHI}$ is true.
		It follows that $\CAPTHETA$ and $\CAPPHI$ have opposite values on all models.
		Thus, $\CAPTHETA$ is truth functionally contradictory to $\CAPPHI$.

	\end{PROOF}
\end{THEOREM}

\begin{majorILnc}{\LnpDC{GSL Contrary}}
Two sentences $\CAPTHETA$ and $\CAPPHI$ are \nidf{truth functionally contrary}\index{contraries!truth functional|textbf} \Iff there is no model on which both are $\True$. 
\end{majorILnc}

\begin{majorILnc}{\LnpEC{tf contrary entailment}}
	$\CAPTHETA$ and $\CAPPHI$ are truth functionally contrary \Iff $\CAPTHETA,\CAPPHI\sdtstile{}{}\conjunction{\Al}{\negation{\Al}}$.
\end{majorILnc}
\begin{PROOF} ($\Rightarrow$) Assume that $\CAPTHETA$ and $\CAPPHI$ are truth functionally contrary.
	Then there is no model on which $\CAPTHETA$ and $\CAPPHI$ are both truth.
	It follows that there is no model that makes both $\CAPTHETA$ and $\CAPPHI$ true and $\conjunction{\Al}{\negation{\Al}}$ false.
	Thus, by the definition of $\entails$, $\CAPTHETA,\CAPPHI\sdtstile{}{}\conjunction{\Al}{\negation{\Al}}$.

	($\Leftarrow$) This direction is left as an exercise for the reader.
\end{PROOF}

\begin{majorILnc}{\LnpDC{GSL subcontrary}}
Two sentences $\CAPTHETA$ and $\CAPPHI$ are \nidf{truth functionally subcontrary}\index{subcontraries!truth functional|textbf} \Iff there is no model on which both are $\False$. 
\end{majorILnc}

\begin{THEOREM}{\LnpTC{tf subcontrary entailment}}
	$\CAPTHETA$ and $\CAPPHI$ are truth functionally subcontrary \Iff $\sdtstile{}{}\disjunction{\CAPTHETA}{\CAPPHI}$. This proof is left as an exercise for the reader.
\end{THEOREM}

\begin{majorILnc}{\LnpDC{GSL Independence}}
Two sentences $\CAPTHETA$ and $\CAPPHI$ are \nidf{truth functionally independent}\index{independent sentences!truth functional|textbf} \Iff there are four models:
\begin{cenumerate}
\item A model in which both $\CAPTHETA$ and $\CAPPHI$ are $\True$; 
\item A model in which both $\CAPTHETA$ and $\CAPPHI$ are $\False$;
\item A model in which $\CAPTHETA$ is $\True$ and $\CAPPHI$ is $\False$; and
\item A model in which $\CAPTHETA$ is $\False$ and $\CAPPHI$ is $\True$.
\end{cenumerate}
\end{majorILnc}

\noindent{}It follows truth functionally independent sentences are not truth functionally equivalent, contradictory, contrary, or subcontrary.

\begin{majorILnc}{\LnpEC{TFE Ex 4}}
Each pair of contradictory sentences is also contrary, but sentences can be contrary without being contradictory.
\end{majorILnc}
\begin{PROOF}
$\conjunction{\Cl}{\Dl}$ and $\conjunction{\Cl}{\negation{\Dl}}$ are contrary but not contradictory.

(Contrary:) If $\conjunction{\Cl}{\Dl}$ is true in a model $\IntA$, then $\Cl$ and $\Dl$ are each true on $\IntA$. 
So $\negation{\Dl}$ is false in $\IntA$, and $\conjunction{\Cl}{\negation{\Dl}}$ is false in $\IntA$.
If $\conjunction{\Cl}{\negation{\Dl}}$ is true in $\IntA$, then both $\Cl$ and $\negation{\Dl}$ are true on $\IntA$.
$\Dl$ is false in $\IntA$, and hence $\conjunction{\Cl}{\Dl}$ is false in $\IntA$.
Thus, by def. \ref{GSL Contrary}, the pair is contrary.

(Not Contradictory:) Any model $\IntA$ that assigns $\FalseB$ to $\Cl$ makes both $\conjunction{\Cl}{\Dl}$ and $\conjunction{\Cl}{\negation{\Dl}}$ false.
By def. \ref{GSL Contradictory}, the pair is not contradictory.
\end{PROOF}
\begin{majorILnc}{\LnpEC{TFE Ex 5}}
Contradictory sentences are also subcontrary, but sentences can be subcontrary without being contradictory. 
\end{majorILnc}
\begin{PROOF}
$\Dl$ and $\disjunction{\Cl}{\negation{\Dl}}$ are subcontrary but not contradictory.

(Subcontrary:) Assume that $\Dl$ is false on a model $\IntA$.
It follows that $\negation{\Dl}$ is true on $\IntA$ and so is $\disjunction{\Cl}{\negation{\Dl}}$. 
Alternatively, assume that $\disjunction{\Cl}{\negation{\Dl}}$ is false on $\IntA$.  Then both $\Cl$ and $\negation{\Dl}$ are false on $\IntA$.
So $\Dl$ is true on $\IntA$.
By def. \ref{GSL subcontrary}, the pair is subcontrary.

(Not Contradictory:) Any model that assigns $\TrueB$ to both $\Dl$ and $\Cl$ makes both $\Dl$ and $\disjunction{\Cl}{\negation{\Dl}}$ true. 
So by def. \ref{GSL Contradictory}, the pair isn't contradictory.
\end{PROOF}
\begin{majorILnc}{\LnpEC{TFE Ex 6}}
If two sentences are both contrary and subcontrary, they are contradictory. 
\end{majorILnc}
\begin{PROOF}
If two sentences are contrary, then by definition \ref{GSL Contrary} any model $\IntA$ that makes one true makes the other false. 
If two sentences are subcontrary, then by definition \ref{GSL subcontrary} any model $\IntA$ that makes one false makes the other true. 
Because every model either makes a sentence true or makes it false, no model assigns two sentences that are contrary and subcontrary the same truth value. 
So by definition \ref{GSL Contradictory}, two sentences that are contrary and subcontrary are also contradictory. 
\end{PROOF}
\begin{majorILnc}{\LnpEC{TFE Ex 1}}
$\disjunction{\Al}{\parconjunction{\Bl}{\Dl}}$ and $\conjunction{\pardisjunction{\Al}{\Bl}}{\pardisjunction{\Al}{\Dl}}$ are \CAPS{tfe}.
\end{majorILnc}
\begin{PROOF}
($\Rightarrow$) Assume that $\disjunction{\Al}{\parconjunction{\Bl}{\Dl}}$ is true on some $\IntA$. 
By the def. of truth of $\VEE$, either $\Al$ is true on $\IntA$ or $\conjunction{\Bl}{\Dl}$ is true on $\IntA$.
(Case 1) $\Al$ is true on $\IntA$.
Then both $\disjunction{\Al}{\Bl}$ and $\disjunction{\Al}{\Dl}$ are true on $\IntA$.
So, $\conjunction{\pardisjunction{\Al}{\Bl}}{\pardisjunction{\Al}{\Dl}}$ is true on $\IntA$.
(Case 2) $\conjunction{\Bl}{\Dl}$ is true on $\IntA$
Then then both $\Bl$ and $\Dl$ are true on $\IntA$, and so both $\disjunction{\Al}{\Bl}$ and $\disjunction{\Al}{\Dl}$ are true on $\IntA$.
Hence, $\conjunction{\pardisjunction{\Al}{\Bl}}{\pardisjunction{\Al}{\Dl}}$ is true on $\IntA$. 

In either case, $\conjunction{\pardisjunction{\Al}{\Bl}}{\pardisjunction{\Al}{\Dl}}$ is true on $\IntA$.
Thus, $\disjunction{\Al}{\parconjunction{\Bl}{\Dl}}\sdtstile{}{}\conjunction{\pardisjunction{\Al}{\Bl}}{\pardisjunction{\Al}{\Dl}}$.

($\Leftarrow$) We leave it to the reader to show that $\conjunction{\pardisjunction{\Al}{\Bl}}{\pardisjunction{\Al}{\Dl}}\sdtstile{}{}\disjunction{\Al}{\parconjunction{\Bl}{\Dl}}$. 
It then follows by theorem \ref{tfe entailment} that the two sentences are \CAPS{tfe}.
\end{PROOF}
\begin{majorILnc}{\LnpEC{TFE Ex 2}}
For any \GSL{} sentences $\CAPPHI$ and $\CAPTHETA$, $\horseshoe{\CAPPHI}{\CAPTHETA}$ and $\disjunction{\negation{\CAPPHI}}{\CAPTHETA}$ are \CAPS{tfe}.
\end{majorILnc}
\begin{PROOF}
($\Rightarrow$) Assume that $\horseshoe{\CAPPHI}{\CAPTHETA}$ is true on some model $\IntA$.
Then on $\IntA$ either $\CAPPHI$ is false or $\CAPTHETA$ is true. 
Hence either $\negation{\CAPPHI}$ or $\CAPTHETA$ is true on $\IntA$. 
It follows that $\disjunction{\negation{\CAPPHI}}{\CAPTHETA}$ is true on $\IntA$. 
Hence by the definition of $\:\sdtstile{}{}$, $\horseshoe{\CAPPHI}{\CAPTHETA}\sdtstile{}{}\disjunction{\negation{\CAPPHI}}{\CAPTHETA}$.

($\Leftarrow$) We leave it to the reader to show that $\disjunction{\negation{\CAPPHI}}{\CAPTHETA}\sdtstile{}{}\horseshoe{\CAPPHI}{\CAPTHETA}$.
It then follows by theorem \ref{tfe entailment} that the two sentences are \CAPS{tfe}.
\end{PROOF}
\begin{majorILnc}{\LnpEC{TFE Ex 3}}
For any \GSL{} sentence $\CAPPHI$, $\negation{\negation{\CAPPHI}}$ and $\CAPPHI$ are \CAPS{tfe}.
\end{majorILnc}
\begin{PROOF}
The proof is left to the reader.
\end{PROOF}

\subsection{Procedures for Testing Other Relations} 

As before we can use truth tables to test for the following relationships: truth-functional equivalence, truth-functional contradictory, truth-functional contrary, truth-functional subcontrary, and truth-functional independence. 
We can test for truth-functional equivalence by putting both $\CAPPHI$ and $\CAPTHETA$ in a truth table and checking whether they have the same truth value in every row. 
\begin{majorILnc}{\LnpEC{TFE Ex 1 2}}
In example \mvref{TFE Ex 1} we saw that $\disjunction{\Al}{\parconjunction{\Bl}{\Dl}}$ and $\conjunction{\pardisjunction{\Al}{\Bl}}{\pardisjunction{\Al}{\Dl}}$ are \CAPS{tfe}. 
We can also prove this with a truth table. 
\begin{center}
\begin{tabular}{ c c c c c }
$\Al$ & $\Bl$ & $\Dl$ & $\disjunction{\Al}{\parconjunction{\Bl}{\Dl}}$ & $\conjunction{\pardisjunction{\Al}{\Bl}}{\pardisjunction{\Al}{\Dl}}$ \\
\hline
$ $ & $ $ & & & \\[-.25cm]
$\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ \\
$\TrueB$ & $\TrueB$ & $\FalseB$& $\TrueB$ & $\TrueB$ \\
$\TrueB$ & $\FalseB$ & $\TrueB$ & $\TrueB$ & $\TrueB$\\
$\TrueB$ & $\FalseB$ & $\FalseB$  & $\TrueB$ & $\TrueB$\\
$\FalseB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$\\
$\FalseB$ & $\TrueB$ & $\FalseB$& $\FalseB$ & $\FalseB$\\
$\FalseB$ & $\FalseB$ & $\TrueB$ & $\FalseB$ & $\FalseB$\\
$\FalseB$ & $\FalseB$ & $\FalseB$  & $\FalseB$ & $\FalseB$\\
\end{tabular}
\end{center}
\end{majorILnc}
\begin{majorILnc}{\LnpEC{TFE Ex 2 2}}
In example \mvref{TFE Ex 2} we saw that for any \GSL{} sentences $\CAPPHI$ and $\CAPTHETA$, $\horseshoe{\CAPPHI}{\CAPTHETA}$ and $\disjunction{\negation{\CAPPHI}}{\CAPTHETA}$ are \CAPS{tfe}. 
We confirm with a truth table:
\begin{center}
\begin{tabular}{ c c c c c }
$\CAPPHI$ & $\CAPTHETA$ & $\horseshoe{\CAPPHI}{\CAPTHETA}$ & $\disjunction{\negation{\CAPPHI}}{\CAPTHETA}$ & \\
\hline
$ $ & $ $ & & & \\[-.25cm]
$\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ \\
$\TrueB$ & $\FalseB$& $\FalseB$ & $\FalseB$ \\
$\FalseB$ & $\TrueB$ & $\TrueB$ & $\TrueB$\\
$\FalseB$ & $\FalseB$  & $\TrueB$ & $\TrueB$\\
\end{tabular}
\end{center}
In this example we're not looking at \GSL{} sentences; instead we have sentence schemas. 
But for reasons to be discussed below this procedure still works: this truth table shows that for any two sentences $\CAPPHI$ and $\CAPTHETA$, $\horseshoe{\CAPPHI}{\CAPTHETA}$ and $\disjunction{\negation{\CAPPHI}}{\CAPTHETA}$ are \CAPS{tfe}.
\end{majorILnc}
While truth tables provide guaranteed answers to these questions, students should not become reliant on this method. 
For one thing, this method doesn't work for more complex languages, and it is important to practice with \GSL{} structures the reasoning skills and methods needed in later chapters. 
Secondly, truth tables can quickly become very large and tedious, and often simple reasoning suffices. 
More generally, truth tables give an answer but often don’t give insight.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Recursive Proofs}\label{Recursive Proofs}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The Method of Recursive Proof}
Many logic concepts are characterized by recursive definitions.  
To prove a theorem about a recursively defined concept, we usually want to employ a method called \df{recursive proof}. 
The structure of a recursive proof mirrors the structure of a recursive definition.

\begin{majorILnc}{\LnpDC{Definition of Recursive Proof}}
	Let $\Delta$ be some set whose members are defined recursively. A \df{recursive proof} that all members of $\Delta$ have some property $\CAPPHI$ proceeds as follows:
	\begin{description}
		\item[Base Step:] Show that everything identified by the base clause of the recursive definition has $\CAPPHI$.  
		\item[Inheritance Step:] Show that $\CAPPHI$ is inherited; i.e., show that if the previous elements from which new elements are generated (or found) by the generating clause have $\CAPPHI$ then the new ones have $\CAPPHI$ too.
		\item[Closure Step:] Finally, show that the base and inheritance steps are sufficient to show that all elements of $\Delta$ have $\CAPPHI$. 
		
	\end{description}
\end{majorILnc}
The inheritance step usually has two parts. The first part is a \emph{recursive assumption}.
We \emph{assume} that some previous elements---the elements from which new ones are generated by the generating clause---already have the property in question.
Typically we make this assumption by selecting metavariables to represent the previous elements.
We are entitled to this assumption because we know that there are some previous elements.
At the very least the elements identified in the base clause have the property.
Second, we prove that the new, generated elements must also have the property in question.

How much we need to write in the closure step varies from proof to proof. 
Sometimes we simply note that the closure condition (``that's all'') ensures nothing has been left out. 
Other times, if the proof is more complicated, we might also reiterate what we have just shown. 

\subsection{Recursive Proof and Mathematical Induction}
Many important mathematical concepts are defined recursively. 
We saw the recursive definition of natural numbers in the previous chapter. 
If we want to \emph{prove} something about all natural numbers, we can use mathematical induction\index{principle of mathematical induction}.
\emph{Mathematical induction} is a method of proof in which one shows (i) that some property holds of the first natural number, and (ii) that for any natural number $n$ having that property, the successor of $n$ also has that property.
Mathematical induction is one sort of recursive proof:
\begin{description}
	\item[Base Step:] $0$ has property $\CAPPHI$. 
	\item[Inheritance Step:] Whenever $\integer{n}$ has property $\CAPPHI$, its successor, $n+1$, also has $\CAPPHI$.
\end{description}
Therefore, we conclude that
\begin{description}
	\item[Closure Step:] All natural numbers have property $\CAPPHI$.
\end{description}

Let's go through an example of mathematical induction.
This first proof isn't exciting but it illustrates how recursive proofs work.

\begin{majorILnc}{\LnpEC{English Recursive Proof 1}} 
	There is no largest natural number $n$. 
	
	\begin{PROOF}	\begin{cenumerate}
			\item Base Step: The number $0$ isn't the largest; $1$ is larger.
			\item Inheritance Step: Assume that $n$ isn't the largest natural number. (This is the recursive assumption.)
			Is $n+1$ the largest natural number? No. $n+1$ can't be the largest because $n+1<n+2$.  
			\item Closure Step: Therefore no natural number $n$ is the largest.
	\end{cenumerate}
\end{PROOF}
\end{majorILnc}

\noindent{}Two things can give people trouble with recursive proofs.
One is that the base case is often easy or trivial. 
Make sure you have done it correctly, but don't worry if it seems too easy. 

Second, some students initially think that the recursive assumption in the inheritance step assumes what we are trying to prove.
But in a correct proof that isn't so.
Think of the recursive assumption this way: \emph{if} some elements have property $\CAPPHI$, then we can show that other elements also have $\CAPPHI$.
We know that some elements have the property in question: those identified in the base step.
The recursive assumption merely provides a label for these previously identified elements bearing the property in question.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Recursive Proofs in SL}\label{recursive proofs in SL}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Recursive Proof Examples in SL}

Let's use recursive proofs to establish two simple results about \GSL{} sentences.  

\begin{majorILnc}{\LnpEC{Recursive Proof Ex 1}} 
Prove that every (official) sentence has exactly as many left parentheses as right.
\begin{PROOF}
\begin{description}
	\item[Base Step:] All atomic sentences have zero left parentheses and zero right parentheses. 
	Clearly $0=0$.
	\item[Inheritance Step:] \hfill{}

	\begin{description}

		\item[Recursive Assumption:] Suppose $\CAPPHI$ and $\CAPTHETA,\CAPTHETA_1,\CAPTHETA_2,\ldots,\CAPTHETA_{\integer{n}}$ are sentences of order $k$ or less, each with exactly as many left parentheses as right.
		Sentences of order $k+1$ can be constructed as follows:

		\item[Negation:] Adding a negation sign to $\CAPPHI$ does not change the number of parentheses. Since, by recursive assumption (RA), $\CAPPHI$ has the same number of left and right parentheses, so does $\negation{\CAPPHI}$.

		\item[Conditional/Biconditional:] By RA, each of $\CAPPHI$ and $\CAPTHETA$ has matching numbers of left and right parentheses.
		It follows that the number of left parentheses in both sentences matches the number of right parentheses in both.
		The sentences $\parhorseshoe{\CAPPHI}{\CAPTHETA}$ and $\partriplebar{\CAPPHI}{\CAPTHETA}$ have an additional pair of parentheses, one left and one right, and this preserves the property of having the same number of left and right parentheses.

		\item[Disjunction/Conjunction:] By RA, each of $\CAPTHETA_1,\CAPTHETA_2,\ldots,\CAPTHETA_{\integer{n}}$ has a matching number of left and right parentheses.
		It follows that the number of left parentheses in all of them matches the number of right parentheses in all of them.
		The sentences $\parconjunction{\CAPTHETA_1}{\conjunction{\CAPTHETA_2}{\conjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}$ and $\pardisjunction{\CAPTHETA_1}{\disjunction{\CAPTHETA_2}{\disjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}$ have one additional pair of parentheses, one left and one right, the addition of which preserves the property that the number of left parentheses is the same as the number of right parentheses.
	\end{description}

	\item[Closure Step:] The above steps cover all the ways of generating an \GSL{} sentence. In each case the number of left parentheses equals the number of right parentheses.
\end{description}
\end{PROOF}
\end{majorILnc}

\begin{commentary}
	This recursive proof is structured to match the definition of an \GSL{} sentence, which is typical of proofs that all \GSL{} sentences have some property.
	The definition of a sentence has a base clause for sentence letters, and generating clauses for all the ways to construct a sentence of order $k+1$ from subsentences that have order $k$ or less.
	Accordingly, the recursive assumption is nearly always of the form ``Sentences of order $k$ or less have such and such property.''
	The goal in the rest of the inheritance step is to show that all the ways of constructing a sentence of order $k+1$ preserve that property.
\end{commentary}

\begin{majorILnc}{\LnpEC{Recursive Proof Ex 2}} 
Prove that in every official \GSL{} sentence the number of left parentheses is greater than or equal to the number of arrows.
\begin{PROOF}
Let $\LP\CAPPHI$ be the number of left parentheses in $\CAPPHI$ and $\HHH\CAPPHI$ be the number of arrows in $\CAPPHI$.
\begin{description}
\item[Base Step:] In the base case $\CAPPHI$ is atomic, so $\LP\CAPPHI=0$ and $\HHH\CAPPHI=0$.  Thus, $\LP\CAPPHI=\HHH\CAPPHI$ and so $\LP\CAPPHI\geq\HHH\CAPPHI$.
\item[Inheritance Step:] \hfill{}
\begin{description}
\item[Recursive Assumption:] Let $\CAPTHETA$, $\CAPTHETA_1$, $\CAPTHETA_2$, $\ldots$ $\CAPTHETA_{\integer{n}}$ be sentences of order $k$ or less. 
Assume that $\LP\CAPTHETA\geq\HHH\CAPTHETA$, $\LP\CAPTHETA_1\geq\HHH\CAPTHETA_1$, $\LP\CAPTHETA_2\geq\HHH\CAPTHETA_2$, $\ldots$ $\LP\CAPTHETA_{\integer{n}}\geq\HHH\CAPTHETA_{\integer{n}}$. Sentences of order $k+1$ can be constructed as follows: 
\item[Negation:] $\LP\negation{\CAPTHETA}=\LP\CAPTHETA$ and $\HHH\negation{\CAPTHETA}=\HHH\CAPTHETA$. By assumption $\LP\CAPTHETA\geq\HHH\CAPTHETA$, so $\LP\negation{\CAPTHETA}\geq\HHH\negation{\CAPTHETA}$ too.
\item[Conditional:] $\LP\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2}=\LP\CAPTHETA_1+\LP\CAPTHETA_2+1$ and $\HHH\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2}=\HHH\CAPTHETA_1+\HHH\CAPTHETA_2+1$. Because $\LP\CAPTHETA_1\geq\HHH\CAPTHETA_1$ and $\LP\CAPTHETA_2\geq\HHH\CAPTHETA_2$, clearly $\LP\CAPTHETA_1+\LP\CAPTHETA_2+1\geq\HHH\CAPTHETA_1+\HHH\CAPTHETA_2+1$ too. So $\LP\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2}\geq\HHH\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2}$.
\item[Biconditional:] $\LP\partriplebar{\CAPTHETA_1}{\CAPTHETA_2}=\LP\CAPTHETA_1+\LP\CAPTHETA_2+1$ and $\HHH\partriplebar{\CAPTHETA_1}{\CAPTHETA_2}=\HHH\CAPTHETA_1+\HHH\CAPTHETA_2$. 
Because $\LP\CAPTHETA_1\geq\HHH\CAPTHETA_1$ and $\LP\CAPTHETA_2\geq\HHH\CAPTHETA_2$, clearly $\LP\CAPTHETA_1+\LP\CAPTHETA_2+1\geq\HHH\CAPTHETA_1+\HHH\CAPTHETA_2$ too. 
So $\LP\partriplebar{\CAPTHETA_1}{\CAPTHETA_2}\geq\HHH\partriplebar{\CAPTHETA_1}{\CAPTHETA_2}$.
\item[Disjunction:] We have that $\LP\pardisjunction{\CAPTHETA_1}{\disjunction{\CAPTHETA_2}{\disjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}=\LP\CAPTHETA_1+\LP\CAPTHETA_2+\ldots+\LP\CAPTHETA_{\integer{n}}+1$ and $\HHH\pardisjunction{\CAPTHETA_1}{\disjunction{\CAPTHETA_2}{\disjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}=\HHH\CAPTHETA_1+\HHH\CAPTHETA_2+\ldots+\HHH\CAPTHETA_{\integer{n}}$. 
Because $\LP\CAPTHETA_1\geq\HHH\CAPTHETA_1$, $\LP\CAPTHETA_2\geq\HHH\CAPTHETA_2$, $\ldots$ $\LP\CAPTHETA_{\integer{n}}\geq\HHH\CAPTHETA_{\integer{n}}$, we have that $\LP\CAPTHETA_1+\LP\CAPTHETA_2+\ldots+\LP\CAPTHETA_{\integer{n}}+1\geq\HHH\CAPTHETA_1+\HHH\CAPTHETA_2+\ldots+\HHH\CAPTHETA_{\integer{n}}$. 
So, $\LP\pardisjunction{\CAPTHETA_1}{\disjunction{\CAPTHETA_2}{\disjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}\geq\HHH\pardisjunction{\CAPTHETA_1}{\disjunction{\CAPTHETA_2}{\disjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}$ too.
\item[Conjunction:] The argument is the same as that for disjunction, but with each \mention{$\VEE$} replaced with \mention{$\!\WEDGE\!$}.
\end{description}
\item[Closure Step:] These are all the ways of constructing \GSL{} sentences, and in every case the number of left parentheses is greater than or equal to the number of arrows.\end{description}
\end{PROOF}
\end{majorILnc}%

\subsection{Minimal Model Theorem}\label{minimal model theorem} 

Earlier we made the following claim: to determine whether some sentence $\CAPPHI$ is true on a model, you only need to check the assignments to the sentence letters in $\CAPPHI$.
Now we prove it.

\begin{THEOREM}{\LnpTC{thm:localityoftruth}}
	If two models for $\CAPPHI$, $\As{}{1}$ and $\As{}{2}$, make the same assignments to all the sentence letters contained in $\CAPPHI$, then $\CAPPHI$ is true on $\As{}{1}$ \Iff $\CAPPHI$ is true on $\As{}{2}$.
\end{THEOREM}
\begin{PROOF}
	\begin{description}
		\item[Base Step:]  Let $\CAPTHETA$ be a \GSL{} sentence of order 1.  It follows that $\CAPTHETA$ must be a lone sentence letter.  If $\As{}{1}$ and $\As{}{2}$ make the same assignments for all the sentence letters, then $\CAPTHETA$, which is just one sentence letter, is true on $\As{}{1}$ \Iff $\CAPTHETA$ is true on $\As{}{2}$.
		
		\item[Inheritance Step:] \hfill{}
		\begin{description}
			\item[Recursive Assumption:] Let $\CAPPHI$ and $\CAPTHETA_1,\CAPTHETA_2,\ldots,\CAPTHETA_{\integer{n}}$ be sentences of order $k$ or less. Assume that $\CAPPHI$ is true on $\As{}{1}$ \Iff $\CAPPHI$ is true on $\As{}{2}$, $\CAPTHETA_1$ is true on $\As{}{1}$ \Iff $\CAPTHETA_1$ is true on $\As{}{2}$, $\ldots$, $\CAPTHETA_n$ is true on $\As{}{1}$ \Iff $\CAPTHETA_n$ is true on $\As{}{2}$.

			\item[Negation:] ($\Rightarrow$) Assume that $\negation{\CAPPHI}$ is true on $\As{}{1}$.
			Then, by the definition of truth, $\NEGATION$, $\CAPPHI$ is false on $\As{}{1}$.
			So, by RA, $\CAPPHI$ is false on $\As{}{2}$.
			It follows that $\negation{\CAPPHI}$ is true on $\As{}{2}$.

			($\Leftarrow$) Assume that $\negation{\CAPPHI}$ is true on $\As{}{2}$.
			Then, by the definition of truth, $\NEGATION$, $\CAPPHI$ is false on $\As{}{2}$.
			So, by RA, $\CAPPHI$ is false on $\As{}{1}$.
			It follows that $\negation{\CAPPHI}$ is true on $\As{}{1}$.
			\begin{commentary}
				Note that the ($\Leftarrow$) part is the same as the ($\Rightarrow$) part, but with $\As{}{1}$ and $\As{}{2}$ switched.
				For the rest of this proof we omit such redundant details.
			\end{commentary}		
			
			\item[Conditional:] ($\Rightarrow$) Assume that $\horseshoe{\CAPTHETA_1}{\CAPTHETA_2}$ is true on $\As{}{1}$.
			Then, by the definition of truth, $\HORSESHOE$, $\As{}{1}$ makes either $\CAPTHETA_1$ false or $\CAPTHETA_2$ true.
			(Case 1) $\As{}{1}$ makes $\CAPTHETA_1$ false.
			So, by RA, $\As{}{2}$ makes $\CAPTHETA_1$ false.
			(Case 2) $\As{}{1}$ makes $\CAPTHETA_2$ true.
			So, by RA, $\As{}{2}$ makes $\CAPTHETA_2$ true.
			In both cases $\As{}{2}$ makes $\horseshoe{\CAPTHETA_1}{\CAPTHETA_2}$ true.

			($\Leftarrow$) This is the same as ($\Rightarrow$), but with $\As{}{1}$ and $\As{}{2}$ switched.
			
			\item[Biconditional:] ($\Rightarrow$) Assume that $\triplebar{\CAPTHETA_1}{\CAPTHETA_2}$ is true on $\As{}{1}$.
			Then, by the definition of truth, $\TRIPLEBAR$, $\As{}{1}$ either makes both $\CAPTHETA_1$ and $\CAPTHETA_2$ true or it makes both $\CAPTHETA_1$ and $\CAPTHETA_2$ false.
			(Case 1) $\As{}{1}$ makes $\CAPTHETA_1$ and $\CAPTHETA_2$ true.
			So, by RA, $\As{}{2}$ makes $\CAPTHETA_1$ and $\CAPTHETA_2$ true.
			(Case 2) $\As{}{1}$ makes $\CAPTHETA_1$ and $\CAPTHETA_2$ false.
			So, by RA, $\As{}{2}$ makes $\CAPTHETA_1$ and $\CAPTHETA_2$ false.
			In both cases $\As{}{2}$ makes $\triplebar{\CAPTHETA_1}{\CAPTHETA_2}$ true.

    		($\Leftarrow$) This is the same as ($\Rightarrow$), but with $\As{}{1}$ and $\As{}{2}$ switched.

			\item[Disjunction:] ($\Rightarrow$) Assume that $\pardisjunction{\CAPTHETA_1}{\disjunction{\CAPTHETA_2}{\disjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}$ is true on $\As{}{1}$.
			Then, by the definition of truth, $\VEE$, there is at least one $\CAPTHETA_i$ that is true on $\As{}{1}$, where $1\leq i\leq n$.
			So, by RA, $\CAPTHETA_i$ is true on $\As{}{2}$.
			It follows that $\pardisjunction{\CAPTHETA_1}{\disjunction{\CAPTHETA_2}{\disjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}$ is true on $\As{}{2}$.

			($\Leftarrow$) This is the same as ($\Rightarrow$), but with $\As{}{1}$ and $\As{}{2}$ switched.

			\item[Conjunction:] ($\Rightarrow$) Assume that $\parconjunction{\CAPTHETA_1}{\conjunction{\CAPTHETA_2}{\conjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}$ is true on $\As{}{1}$.
			Then, by the definition of truth, $\WEDGE$, each $\CAPTHETA_i$ is true on $\As{}{1}$, where $1\leq i\leq n$.
			So, by RA, each $\CAPTHETA_i$ is true on $\As{}{2}$.
			It follows that $\parconjunction{\CAPTHETA_1}{\conjunction{\CAPTHETA_2}{\conjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}$ is true on $\As{}{2}$.

			($\Leftarrow$) This is the same as ($\Rightarrow$), but with $\As{}{1}$ and $\As{}{2}$ switched.

		\end{description}
		\item[Closure Step:] These are all the ways of constructing \GSL{} sentences. Therefore, if $\As{}{1}$ and $\As{}{2}$ make the same assignments for all the sentence letters in some $\CAPPHI$, then $\CAPPHI$ is true on $\As{}{1}$ \Iff $\CAPPHI$ is true on $\As{}{2}$.
	\end{description}
\end{PROOF}


\subsection{Main Connective Theorem}\label{additional recur examples} 

We defined the main connective of a sentence $\CAPPHI$ as the connective that isn't in any proper subsentence of $\CAPPHI$ (\ref{GSL Main connective}).  Atomic sentences don't have any connectives, and so don't have main connectives.  Most non-atomic sentences have just one main connective, but there is an exception: conjunctions (or disjunctions) with more than two conjuncts (disjuncts). For example, all three of the \mention{$\WEDGE$} tokens in the following sentence are the main connectives: $\parconjunction{\conjunction{\Bl}{\Al}}{\conjunction{\Hl}{\Gl}}$.  Let's call sentences that have multiple tokens of \mention{$\WEDGE$} as main connectives \mention{extended conjunctions}, and those that have multiple tokens of \mention{$\VEE$} as main connectives \mention{extended disjunctions}.  With this terminology established, we turn to another recursive proof.

\begin{THEOREM}{\LnpTC{Recur Main Connective} Main Connective Theorem:} 
For\index{main connective!theorem} every \GSL{} sentence $\CAPPHI$, one of the following holds: (i) $\CAPPHI$ has no main connective; (ii) $\CAPPHI$ has exactly one main connective token; or (iii) $\CAPPHI$ is an extended conjunction (or disjunction) with $n-1$ main connective tokens, where $n$ is the number of conjuncts (disjuncts).
\end{THEOREM}
\begin{PROOFOF}{Thm. \ref{Recur Main Connective}, Main Connective Theorem}
\begin{description}
\item[Base Step:] 
Every \GSL{} sentence of order $1$ is just a sentence letter. Therefore it has no main connective.
 
\item[Inheritance Step:] \hfill{}

\begin{description}

\item[Recursive Assumption:] Let $\CAPPHI$ and $\CAPTHETA_1,\CAPTHETA_2,\ldots,\CAPTHETA_{\integer{n}}$ be sentences of order $k$ or less. Assume that one of (i)-(iii) holds of each of these sentences. Now consider the ways in which a sentence of order $k+1$ can be constructed from them:

\item[Negation:] Every connective in $\CAPPHI$ is in a proper subsentence of $\negation{\CAPPHI}$.
The only connective not in a proper subsentence of $\negation{\CAPPHI}$ is \mention{$\NEGATION$}.
So \mention{$\NEGATION$} is the main connective.
Thus $\negation{\CAPPHI}$ has precisely one main connective, thereby meeting condition (ii).

\item[Conditional/Biconditional:] All the connectives in each of $\CAPTHETA_1$ and $\CAPTHETA_2$ is in a proper subsentence of $\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2}$.
The only connective not in a proper subsentence of $\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2}$ is \mention{$\HORSESHOE$}.
So \mention{$\HORSESHOE$} is the main connective.
Thus $\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2}$ has precisely one main connective, thereby meeting condition (ii).
The same reasoning holds of $\partriplebar{\CAPTHETA_1}{\CAPTHETA_2}$, except that it has \mention{$\TRIPLEBAR$} as its main connective.

\item[Conjunction/Disjunction:] Consider a conjunction, $\parconjunction{\CAPTHETA_1}{\conjunction{\CAPTHETA_2}{\conjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}$. If $n=2$ then the reasoning of the \mention{Conditional/Biconditional} clause holds, and there is only $1$ main connective. Otherwise $n>2$, in which case the conjunction is extended.
In that case, every connective in each of $\CAPTHETA_1,\CAPTHETA_2,\ldots,\CAPTHETA_n$ is in a proper subsentence of $\parconjunction{\CAPTHETA_1}{\conjunction{\CAPTHETA_2}{\conjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}$.
The only connectives not in a proper subsentence are the \mention{$\WEDGE$} tokens between each pair of $\CAPTHETA_i$ and $\CAPTHETA_i+1$ subsentences, where $1\leq i\leq n-1$.
So the main connectives are those $n-1$ \mention{$\WEDGE$} tokens.
Thus $\parconjunction{\CAPTHETA_1}{\conjunction{\CAPTHETA_2}{\conjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}$ has precisely $n-1$ main connectives, thereby meeting condition (iii).
The same reasoning holds of $\pardisjunction{\CAPTHETA_1}{\disjunction{\CAPTHETA_2}{\disjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}$, except that it has $n-1$ \mention{$\VEE$} tokens as its main connectives.

\end{description}

\item[Closure Step:] These are all the ways of constructing \GSL{} sentences. Therefore, every \GSL{} sentences has either no main connective, one main connective, or in the case of extended conjunctions or disjunctions with $n$ conjuncts/disjuncts, $n-1$ main connective tokens.

\end{description}
\end{PROOFOF}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[Disjunctive Normal Form]{Disjunctive Normal Form}\label{DNF and the TFE Replacement Theorem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Consider the sentences below.
Let's say we are given the truth values of their sentence letters.
Which sentences are easier to evaluate? 
Which are more difficult?
\begin{multicols}{2}
\begin{menumerate}
\item\label{dnf1} $\horseshoe{\negation{\bparhorseshoe{\Al}{\negation{\parconjunction{\Cl}{\Bl}}}}}{\parhorseshoe{\Al}{\Cl}}$
\item\label{dnf2} $\conjunction{\Al}{\conjunction{\Rl}{\conjunction{\Al}{\negation{\Rl}}}}$
\item\label{dnf3} $\negation{\cparhorseshoe{\negation{\bparhorseshoe{\Al}{\negation{\Rl}}}}{\parhorseshoe{\Al}{\Rl}}}$
\item\label{dnf4} $\disjunction{\bpardisjunction{\negation{\Al}}{\disjunction{\negation{\Cl}}{\negation{\Bl}}}}{\bpardisjunction{\negation{\Al}}{\Cl}}$
\end{menumerate}
\end{multicols}
\noindent{}Clearly \ref{dnf2} and \ref{dnf4} are simpler to figure out than \ref{dnf1} and \ref{dnf3}. 
In general, we find that the truth values of certain sentences are easier to calculate than others.
Say that we want to figure out the truth value of a difficult sentence and we know that it's \CAPS{tfe} to an easy sentence.
Then if we compute the truth value of the easy one we know the value of the difficult one.
This technique can be exploited to simplify the analysis of complicated \GSL{} sentences.
In the above list of sentences, \ref{dnf1} is TFE to \ref{dnf4} and \ref{dnf2} is TFE to \ref{dnf3}.

But how can we know whether some sentence is \CAPS{tfe} to a simpler, more transparent sentence?
It turns out that we can simplify a complicated sentence by a systematic series of steps, each of which replaces some subsentence with a simpler sentence that we know is \CAPS{tfe} to the subsentence being replaced.  

\subsection{The \CAPS{tfe} Replacement Theorem}\label{The TFE Replacement Theorem}

We want a method of transforming a complicated sentence to an equivalent but simpler one.
To that end we prove:

\begin{THEOREM}{\LnpTC{TFE Replacement} Truth Functional Equivalence Replacement:}
Let $\CAPPHI$ be a subsentence of $\CAPTHETA$, $\CAPPHI$ and $\CAPPHI^*$ be \CAPS{tfe}, and $\CAPTHETA^*$ be the result of replacing one occurrence of $\CAPPHI$ by $\CAPPHI^*$ in $\CAPTHETA$. Then $\CAPTHETA$ and $\CAPTHETA^*$ are \CAPS{tfe}.
\end{THEOREM}
% \noindent{}Before turning to the proof, recall from section \ref{Other Relations}, definition \mvref{GSL TFE} that two sentences $\CAPPHI$ and $\CAPPHI^*$ are truth functionally equivalent \Iff all models assign them the same truth value.  This is the same as saying they entail each other, i.e., that $\CAPPHI^*\sdtstile{}{}\CAPPHI$ and $\CAPPHI\sdtstile{}{}\CAPPHI^*$. 

\begin{PROOF}
\begin{description}
\item[Base Step:] Suppose that $\CAPTHETA$ is an atomic sentence. 
Then $\CAPTHETA=\CAPPHI$, since each atomic sentence has only itself as a subsentence.
It also follows that $\CAPTHETA^*=\CAPPHI^*$, since ``substitution'' is just replacement in this case.
Since $\CAPPHI$ and $\CAPPHI^*$ are \CAPS{tfe}, it follows that $\CAPTHETA^*$ and $\CAPTHETA$ are \CAPS{tfe}.

\item[Inheritance Step:] \hfill{}
\begin{description}

	\item[Recursive Assumption:] Let $\CAPPHI$ and $\CAPTHETA_1,\CAPTHETA_2,\ldots,\CAPTHETA_{\integer{n}}$ be \GSL{} sentences of order $k$ or less. And let $\CAPPHI^*$ and $\CAPTHETA_1^*,\CAPTHETA_2^*,\ldots,\CAPTHETA_{\integer{n}}^*$ be, respectively, \GSL{} sentences that are \CAPS{tfe} to them. Now consider the ways in which a substitution can be made into a sentence of order $k+1$.
	
	\item[Negation:] By RA, $\CAPPHI$ and $\CAPPHI^*$ are \CAPS{tfe}.
	Then a model $\IntA$ makes $\CAPPHI$ false \Iff it makes $\CAPPHI^*$ false.
	By the definition of truth, $\NEGATION$, $\IntA$ makes $\negation{\CAPPHI}$ true \Iff it makes $\CAPPHI$ false.
	Similarly, $\IntA$ makes $\negation{\CAPPHI^*}$ true \Iff it makes $\CAPPHI^*$ false.
	Then $\IntA$ makes $\negation{\CAPPHI}$ true \Iff it makes $\negation{\CAPPHI^*}$ true.
	Thus $\negation{\CAPPHI}$ and $\negation{\CAPPHI^*}$ are \CAPS{tfe}.

	\item[Conditional, \lhs Replacement:] ($\Rightarrow$) Assume that model $\IntA$ makes $\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2}$ true.
	Then, by the definition of truth, $\HORSESHOE$, $\m$ makes either $\CAPTHETA_1$ false or $\CAPTHETA_2$ true.
	$\CAPTHETA_1$ is to be replaced by $\CAPTHETA_1^*$.
	By RA, $\CAPTHETA_1$ is \tfe to $\CAPTHETA_1^*$.
	So $\m$ makes either $\CAPTHETA_1^*$ false or $\CAPTHETA_2$ true.
	Then $\m$ makes $\parhorseshoe{\CAPTHETA_1^*}{\CAPTHETA_2}$ true.
	By the definition of $\entails$, $\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2}\entails\parhorseshoe{\CAPTHETA_1^*}{\CAPTHETA_2}$.

	($\Leftarrow$) Assume that model $\m$ makes $\parhorseshoe{\CAPTHETA_1^*}{\CAPTHETA_2}$ true.
	Then, by the definition of truth, $\HORSESHOE$, $\m$ makes either $\CAPTHETA_1^*$ false or $\CAPTHETA_2$ true.
	By RA, $\CAPTHETA_1$ is \tfe to $\CAPTHETA_1^*$.
	So $\m$ makes either $\CAPTHETA_1$ false or $\CAPTHETA_2$ true.
	Then $\m$ makes $\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2}$ true.
	By the definition of $\entails$, $\parhorseshoe{\CAPTHETA_1^*}{\CAPTHETA_2}\entails\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2}$.

	Thus, by theorem \ref{tfe entailment}, $\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2}$ is \tfe to $\parhorseshoe{\CAPTHETA_1^*}{\CAPTHETA_2}$.
	\begin{commentary}
		Note that the ($\Leftarrow$) part is the same as the ($\Rightarrow$) part, but with $\CAPTHETA_1$ and $\CAPTHETA_1^*$ switched.
		For the rest of this proof we omit such redundant details.
	\end{commentary}

	\item[Conditional, \rhs Replacement:] ($\Rightarrow$) Assume that model $\IntA$ makes $\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2}$ true.
	Then, by the definition of truth, $\HORSESHOE$, $\m$ makes either $\CAPTHETA_1$ false or $\CAPTHETA_2$ true.
	$\CAPTHETA_2$ is to be replaced by $\CAPTHETA_2^*$.
	By RA, $\CAPTHETA_2$ is \tfe to $\CAPTHETA_2^*$.
	So $\m$ makes either $\CAPTHETA_1$ false or $\CAPTHETA_2^*$ true.
	Then $\m$ makes $\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2^*}$ true.
	By the definition of $\entails$, $\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2}\entails\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2^*}$.

	($\Leftarrow$) This is the same as ($\Rightarrow$), but with $\CAPTHETA_2$ and $\CAPTHETA_2^*$ switched.

	Thus, by theorem \ref{tfe entailment}, $\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2}$ is \tfe to $\parhorseshoe{\CAPTHETA_1}{\CAPTHETA_2^*}$.

	\item[Biconditional, \lhs Replacement:] ($\Rightarrow$) Assume that model $\IntA$ makes $\partriplebar{\CAPTHETA_1}{\CAPTHETA_2}$ true.
	Then, by the definition of truth, $\TRIPLEBAR$, $\m$ either makes $\CAPTHETA_1$ and $\CAPTHETA_2$ both true or makes $\CAPTHETA_1$ and $\CAPTHETA_2$ both false.
	$\CAPTHETA_1$ is to be replaced by $\CAPTHETA_1^*$.
	By RA, $\CAPTHETA_1$ is \tfe to $\CAPTHETA_1^*$.
	So $\m$ either makes $\CAPTHETA_1^*$ and $\CAPTHETA_2$ both true or makes $\CAPTHETA_1^*$ and $\CAPTHETA_2$ both false.
	Then $\m$ makes $\partriplebar{\CAPTHETA_1^*}{\CAPTHETA_2}$ true.
	By the definition of $\entails$, $\partriplebar{\CAPTHETA_1}{\CAPTHETA_2}\entails\partriplebar{\CAPTHETA_1^*}{\CAPTHETA_2}$.

	($\Leftarrow$) This is the same as ($\Rightarrow$), but with $\CAPTHETA_1$ and $\CAPTHETA_1^*$ switched.

	Thus, by theorem \ref{tfe entailment}, $\partriplebar{\CAPTHETA_1}{\CAPTHETA_2}$ is \tfe to $\partriplebar{\CAPTHETA_1^*}{\CAPTHETA_2}$.

	\item[Biconditional, \rhs Replacement:] The proof for this case is left for the reader.

	\item[Conjunction:] ($\Rightarrow$) Assume that model $\IntA$ makes $\parconjunction{\CAPTHETA_1}{\conjunction{\ldots}{\conjunction{\CAPTHETA_i}{\conjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}}$ true, where $\CAPTHETA_i$ is the conjunct to be replaced.
	Keep in mind that $i$ could also be $1$ or $n$, so $1\leq i\leq n$.
	Then, by the defition of truth, $\WEDGE$, each of $\CAPTHETA_1,\ldots,\CAPTHETA_i,\ldots,\CAPTHETA_n$ is true on $\m$.
	By RA, $\CAPTHETA_i$ is \tfe to $\CAPTHETA_i^*$.
	So, $\CAPTHETA_1,\ldots,\CAPTHETA_i^*,\ldots,\CAPTHETA_n$ is true on $\m$.
	Then $\m$ makes $\parconjunction{\CAPTHETA_1}{\conjunction{\ldots}{\conjunction{\CAPTHETA_i^*}{\conjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}}$ true.
	By the definition of $\entails$, $\parconjunction{\CAPTHETA_1}{\conjunction{\ldots}{\conjunction{\CAPTHETA_i}{\conjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}}\entails\parconjunction{\CAPTHETA_1}{\conjunction{\ldots}{\conjunction{\CAPTHETA_i^*}{\conjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}}$.

	($\Leftarrow$) This is the same as ($\Rightarrow$), but with $\CAPTHETA_i$ and $\CAPTHETA_i^*$ switched.

	Thus, by theorem \ref{tfe entailment}, $\parconjunction{\CAPTHETA_1}{\conjunction{\ldots}{\conjunction{\CAPTHETA_i}{\conjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}}$ and $\parconjunction{\CAPTHETA_1}{\conjunction{\ldots}{\conjunction{\CAPTHETA_i^*}{\conjunction{\ldots}{\CAPTHETA_{\integer{n}}}}}}$ are \tfe.
	
	\item[Disjunction:] The proof for this case is left for the reader.
\end{description}
\item[Closure Step:] Those are the only ways \GSL{} sentences can be formed; hence the theorem is proved.
\end{description}
\end{PROOF}
\begin{majorILnc}{\LnpEC{TFE Replacement Example}}
We can use this theorem to show that \ref{dnf1} and \ref{dnf4} above are equivalent, as are \ref{dnf2} and \ref{dnf3}. 
Consider \ref{dnf1} and \ref{dnf4}. 
(We leave \ref{dnf2} and \ref{dnf3} to the reader.)
For any formulas $\CAPPHI$ and $\CAPTHETA$, 
\begin{menumerate}
\item\label{dnf5} $\parhorseshoe{\CAPPHI}{\CAPTHETA}$ and $\pardisjunction{\negation{\CAPPHI}}{\CAPTHETA}$ are \CAPS{tfe} (See ex. \pmvref{TFE Ex 2})
\item\label{dnf6} $\negation{\negation{\CAPPHI}}$ and $\CAPPHI$ are \CAPS{tfe} (See ex. \pmvref{TFE Ex 3})
\item\label{dnf7} $\negation{\parconjunction{\CAPTHETA}{\CAPPHI}}$ and $\pardisjunction{\negation{\CAPTHETA}}{\negation{\CAPPHI}}$ are \CAPS{tfe} (See \ref{HW Entailment 4} and \ref{HW Entailment 12}, section \ref{Entailment Problems for GSL})
\item\label{dnf8} $\pardisjunction{\CAPPHI}{\disjunction{\CAPTHETA}{\CAPPSI}}$ and $\pardisjunction{\CAPPHI}{\pardisjunction{\CAPTHETA}{\CAPPSI}}$ are \CAPS{tfe} (Obvious)
\end{menumerate}
By making substitutions starting with \ref{dnf1} that the theorem says result in successive truth functionally equivalent sentences, we can get from \ref{dnf1} to \ref{dnf4} and thereby have shown that \ref{dnf4} is truth functionally equivalent to \ref{dnf1}.
\begin{menumerate}
\item $\horseshoe{\negation{\bparhorseshoe{\Al}{\negation{\parconjunction{\Cl}{\Bl}}}}}{\parhorseshoe{\Al}{\Cl}}$ [\ref{dnf1}]
\item $\disjunction{\negation{\negation{\bparhorseshoe{\Al}{\negation{\parconjunction{\Cl}{\Bl}}}}}}{\parhorseshoe{\Al}{\Cl}}$ [\ref{dnf5}]
\item $\disjunction{\bparhorseshoe{\Al}{\negation{\parconjunction{\Cl}{\Bl}}}}{\parhorseshoe{\Al}{\Cl}}$ [\ref{dnf6}]
\item $\disjunction{\bpardisjunction{\negation{\Al}}{\negation{\parconjunction{\Cl}{\Bl}}}}{\pardisjunction{\negation{\Al}}{\Cl}}$ [\ref{dnf5}]
\item $\disjunction{\bpardisjunction{\negation{\Al}}{\pardisjunction{\negation{\Cl}}{\negation{\Bl}}}}{\pardisjunction{\negation{\Al}}{\Cl}}$ [\ref{dnf7}]
\item $\disjunction{\bpardisjunction{\negation{\Al}}{\disjunction{\negation{\Cl}}{\negation{\Bl}}}}{\pardisjunction{\negation{\Al}}{\Cl}}$ [\ref{dnf8}]
\end{menumerate}
\end{majorILnc}

\subsection{Disjunctive Normal Form}\label{Disjunctive Normal Form}

Sentences in disjunctive normal form are especially easy to evaluate.  
\begin{majorILnc}{\LnpDC{DNF Definition}}
A \GSL{} sentence is in \df{disjunctive normal form} (\CAPS{dnf})\index{DNF|see{disjunctive normal form}} \Iff
\begin{cenumerate}
\item it contains no conditional ($\HORSESHOE$) or biconditional ($\TRIPLEBAR$),
\item negations ($\NEGATION$) only govern sentence letters, and
\item no conjunction ($\WEDGE$) contains a disjunction ($\VEE$) as a subsentence.
\end{cenumerate}
\end{majorILnc}
\noindent{}A typical example of a sentence in \CAPS{dnf} is $\disjunction{\parconjunction{\Ql}{\negation{\Rl}}}{\parconjunction{\negation{\Pl}}{\Rl}}$.  The truth conditions for this sentence are transparent.  The sentence $\disjunction{\parconjunction{\Ql}{\negation{\Rl}}}{\parconjunction{\negation{\Pl}}{\Rl}}$ is true on a model $\IntA$ when either $\IntA(\Ql)=\TrueB$ and $\IntA(\Rl)=\FalseB$, or $\IntA(\Pl)=\FalseB$ and $\IntA(\Rl)=\TrueB$.  Some less typical examples are:
\begin{menumerate}
\item $\Ql$
\item $\negation{\Rl}$
\item $\conjunction{\Ql}{\negation{\Rl}}$
\item $\disjunction{\negation{\Ql}}{\Rl}$
\end{menumerate}
\CAPS{dnf} is important because we can prove the following theorem.
\begin{THEOREM}{\LnpTC{Disjunctive Normal Form Theorem} The Disjunctive Normal Form Theorem:}
Every sentence of \GSL{} is truth functionally equivalent to an \GSL{} sentence which is in \CAPS{dnf}.
\end{THEOREM}
\begin{PROOF}
The proof relies on three lemmas, each of which can be established rigorously by recursive proof.  We leave the details of these lemmas to the reader.

Here we provide a process showing how to turn any given sentence into one that's in \CAPS{dnf}. We proceed in three stages, corresponding to the three lemmas that are necessary for a proof.
\begin{description}
\item[Step A:] If a subsentence of $\CAPPHI$ has a conditional or biconditional as its main connective, i.e., is of the form $\parhorseshoe{\CAPPSI}{\CAPTHETA}$ or $\partriplebar{\CAPTHETA}{\CAPPSI}$, replace the subsentence by $\pardisjunction{\negation{\CAPPSI}}{\CAPTHETA}$ or $\disjunction{\parconjunction{\CAPPSI}{\CAPTHETA}}{\parconjunction{\negation{\CAPPSI}}{\negation{\CAPTHETA}}}$ respectively. 
Repeat as necessary to obtain a sentence $\CAPPHI'$ without conditionals or biconditionals.
\item[Step B:] \hfill{}
\begin{cenumerate}
\item Replace any subsentence of the form $\negation{\negation{\CAPPSI}}$ in $\CAPPHI'$ with $\CAPPSI$.
\item Replace any subsentence of the form $\negation{\parconjunction{\CAPPSI}{\CAPTHETA}}$ in $\CAPPHI'$ with $\pardisjunction{\negation{\CAPPSI}}{\negation{\CAPTHETA}}$. 
\item Replace $\negation{\pardisjunction{\CAPPSI}{\CAPTHETA}}$ in $\CAPPHI'$ with $\parconjunction{\negation{\CAPPSI}}{\negation{\CAPTHETA}}$. 
%(These last two are known as DeMorgan's laws after the logician who first explicitly formulated them.)
\end{cenumerate} 
Repeat as necessary to obtain $\CAPPHI''$ in which negations govern nothing but sentence letters.
\item[Step C:] The only thing that could prevent $\CAPPHI''$ from being in \CAPS{dnf} is that some conjunctions govern some disjunctions, i.e., there is a subsentence  $\conjunction{\CAPTHETA}{\pardisjunction{\CAPPSI_1}{\disjunction{\CAPPSI_2}{\disjunction{\ldots}{\CAPPSI_{\integer{n}}}}}}$, or the reverse $\conjunction{\pardisjunction{\CAPPSI_1}{\disjunction{\CAPPSI_2}{\disjunction{\ldots}{\CAPPSI_{\integer{n}}}}}}{\CAPTHETA}$. 
Those subsentences can be replaced by the equivalent $\disjunction{\parconjunction{\CAPPSI_1}{\CAPTHETA}}{\disjunction{\parconjunction{\CAPPSI_2}{\CAPTHETA}}{\disjunction{\ldots}{\parconjunction{\CAPPSI_{\integer{n}}}{\CAPTHETA}}}}$. 
Repeat as necessary.
\end{description}
\end{PROOF}

\noindent{}A recursive proof would be more rigorous---it would have a clause for each \GSL{} connective, and would explain in each clause how to construct from each subsentence another \CAPS{tfe} subsentence that is in \CAPS{dnf}. 

\CAPS{dnf} sentences allow us see some of the advantages of formal languages.  For instance, we can construct a simple, mechanical process that will tell us when a \CAPS{dnf} sentence is \CAPS{tff}.

Let $\CAPPHI$ be some \CAPS{dnf} sentence of the form $\disjunction{\CAPTHETA_1}{\disjunction{\CAPTHETA_2}{\disjunction{\ldots}{\CAPTHETA_n}}}$.
We can see that $\CAPPHI$ is \CAPS{tff} \Iff every disjunct $\CAPTHETA_i$ is \CAPS{tff}.
Because each $\CAPTHETA_i$ is a conjunction with negated and unnegated sentence letters as the conjuncts, there is only one way that it can be \CAPS{tff}.  A $\CAPTHETA_i$ is \CAPS{tff} \Iff it has some sentence letter $\CAPPSI$ as one conjunct and $\negation{\CAPPSI}$ as another.

It follows that we can use the following process to determine whether a \CAPS{dnf} sentence $\CAPPHI$ is \CAPS{tff}. Check every disjunct of $\CAPPHI$ to see if it has some $\CAPPSI$ and $\negation{\CAPPSI}$ as conjuncts.  If so, then $\CAPPHI$ is \CAPS{tff}; otherwise it isn't.  For example, consider the following \CAPS{dnf} sentence:

\begin{center}
\noindent{}$\disjunction{\parconjunction{\Ql}{\conjunction{\Rl}{\negation{\Ql}}}}{\disjunction{\parconjunction{\negation{\Ql}}{\conjunction{\Rl}{\Rl}}}{\parconjunction{\Ol}{\conjunction{\Rl}{\negation{\Ol}}}}}$
\end{center}

\noindent{}The first disjunct, $\parconjunction{\Ql}{\conjunction{\Rl}{\negation{\Ql}}}$, is \CAPS{tff} because it has $\Ql$ and $\negation{\Ql}$ as conjuncts; the third disjunct, $\parconjunction{\Ol}{\conjunction{\Rl}{\negation{\Ol}}}$, is also \CAPS{tff}.  But the second disjunct, $\parconjunction{\negation{\Ql}}{\conjunction{\Rl}{\Rl}}$, isn't \CAPS{tff}. So, the whole sentence isn't \CAPS{tff}.

If we were to replace the second disjunct with $\parconjunction{\negation{\Ql}}{\conjunction{\Rl}{\negation{\Rl}}}$, so that the new whole sentence is:

\begin{center}
	\noindent{}$\disjunction{\parconjunction{\Ql}{\conjunction{\Rl}{\negation{\Ql}}}}{\disjunction{\parconjunction{\negation{\Ql}}{\conjunction{\Rl}{\negation{\Rl}}}}{\parconjunction{\Ol}{\conjunction{\Rl}{\negation{\Ol}}}}}$
\end{center}

\noindent{}\ldots then the result \emph{is} \CAPS{tff}, because each disjunct has a sentence letter and its negation as conjuncts.

We now provide a mechanical method that determines whether \emph{any} \GSL{} sentence $\CAPPHI$ is \CAPS{tff}.  First, we use the process in \ref{Disjunctive Normal Form Theorem} to construct an equivalent \CAPS{dnf} sentence, $\CAPPHI^*$.  Then we use the method given above to determine whether $\CAPPHI^*$ is \CAPS{tff}.  Because they are equivalent, $\CAPPHI^*$ is \CAPS{tff} \Iff $\CAPPHI$ is \CAPS{tff}.  No creativity is needed to apply this method---each individual step requires nothing more than following simple instructions.

We extend this method to determine whether any \GSL{} sentence is \CAPS{tft}.
We take advantage of the fact that if you put a negation in front of a \CAPS{tft} sentence $\CAPPHI$, the resulting sentence, $\negation{\CAPPHI}$, is \CAPS{tff}.  So, all that is necessary to see whether $\CAPPHI$ is \CAPS{tft} is to negate $\CAPPHI$, put $\negation{\CAPPHI}$ into \CAPS{dnf}, and then to see whether the final result is \CAPS{tff}.
If so, then $\CAPPHI$ is \CAPS{tft}.
If not, then it isn't.
As before, this process is entirely mechanical or \emph{formal}.
Note that, along with the truth table method in section \ref{Proceduresfortesting}, we now have two different formal methods for determining logical truth in \GSL{}.
In later chapters our methods are closer to the \CAPS{dnf} approach.

Finally, these two methods can be combined to make a mechanical test of whether some sentence $\CAPPHI$ is \CAPS{tfc}.
If $\CAPPHI$ is neither \CAPS{tft} nor \CAPS{tff} then it is \CAPS{tfc}.

Any given sentence of \GSL{} is truth functionally equivalent to more than one \CAPS{dnf} sentence. 
A sentence has \CAPS{dnf}s that differ slightly for at least two reasons.
First, for any sentence $\CAPPHI$ and sentence letter $\CAPPSI$, if $\CAPPHI$ is in \CAPS{dnf}, then $\disjunction{\CAPPHI}{\parconjunction{\CAPPSI}{\negation{\CAPPSI}}}$ is \CAPS{tfe} to $\CAPPHI$ and also in \CAPS{dnf}.
Second, sometimes a sentence in \CAPS{dnf} can be simplified. Thus 
\begin{menumerate}
\item $\disjunction{\parconjunction{\Ql}{\conjunction{\Rl}{\Ol}}}{\disjunction{\parconjunction{\Ql}{\conjunction{\Rl}{\Nl}}}{\parconjunction{\Ql}{\conjunction{\Rl}{\negation{\Ol}}}}}$
\end{menumerate} can be simplified to the \CAPS{dnf}
\begin{samepage}
\begin{menumerate}
\item $\disjunction{\parconjunction{\Ql}{\Rl}}{\parconjunction{\Ql}{\conjunction{\Rl}{\Nl}}}$
\end{menumerate} and further to 
\begin{menumerate}
\item $\parconjunction{\Ql}{\Rl}$.
\end{menumerate}
\end{samepage}

%\bigskip
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[Truth Functional Expressiveness]{Truth Functional Expressiveness}\label{Truth Functional Expressiveness} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


The definition of truth in a model (def. \pmvref{True on a GSL interpretation}) associates each of the logical connectives of \GSL{} with a truth function.\footnote{See section \ref{Truth Functions Truth Tables and Boolean Operators} for more details.}
We can think of the logical connectives of \GSL{} as truth functions---i.e., as having a meaning that's exhausted by the definition of truth. 
Do the five logical connectives of \GSL{} exhaust the range of possible logical connectives?

In one sense it's obvious they do not. 
For example, we could introduce a new connective, $\%$, choose some number of places for it, and give some clause that describes how the truth value of a sentence with $\%$ as the main connective depends on the truth value of the component parts. 
As long as this clause differs from any of those in the definition of truth, $\%$ is distinct from the five in \GSL{}.

But though the five logical connectives of \GSL{} obviously do not exhaust all the possible connectives, there's still a sense in which they might indirectly cover them all. 
Even if $\%$ is distinct from all the connectives of \GSL{}, maybe there's still some sentence schema that is truth functionally equivalent to $\%$, and that uses only (but not necessarily all of) the five connectives of \GSL{}. 
For example, say $\%$ is a 3-place connective, such that a sentence $\CAPTHETA_1$ $\%$ $\CAPTHETA_2$ $\%$ $\CAPTHETA_3$ is true on a model $\IntA$ \Iff at least two of the $\CAPTHETA$ are true on $\IntA$.  So, the sentence is true if $\CAPTHETA_1$ and $\CAPTHETA_2$ are true, or if $\CAPTHETA_1$ and $\CAPTHETA_3$ are true, or if $\CAPTHETA_2$ and $\CAPTHETA_3$ are true.  We can express this without \mention{$\%$}, using $\WEDGE$ for \mention{and} and $\VEE$ for \mention{or}:  $\disjunction{\parconjunction{\CAPTHETA_1}{\CAPTHETA_2}}{\disjunction{\parconjunction{\CAPTHETA_1}{\CAPTHETA_3}}{\parconjunction{\CAPTHETA_2}{\CAPTHETA_3}}}$.  Even though $\%$ is a connective that isn't in our language, we can use the connectives of \GSL{} to construct a truth functionally equivalent sentence. 


A logical connective $\%$ is \niidf{definable}\index{definability} in terms of some set of other logical connectives $\Delta$ \Iff the connectives in $\Delta$ can be put together to define the same truth function as $\%$. 
With this in mind, we can ask whether every logical connective is definable in terms of the five connectives of \GSL{}.
We can also ask if any of the connectives of \GSL{} are definable in terms of the others.
We answer the first of these questions with theorem \pmvref{Truth-functional Expressive Completeness of GSL}.
The second we consider now in the following examples.\footnote{See \citetext{\citealt{Post1921}, \citealt[17]{Hodges2001}}.}

\begin{majorILnc}{\LnpEC{GSL Connective ID 1}}
	Define conjunction using negation and disjunction.
\end{majorILnc}
\begin{PROOF}
	Any sentence $\conjunction{\CAPPHI_1}{\conjunction{\ldots}{\CAPPHI_{\integer{n}}}}$ is \CAPS{tfe} to the sentence $\negation{\pardisjunction{\negation{\CAPPHI_1}}{\disjunction{\ldots}{\negation{\CAPPHI_{\integer{n}}}}}}$.
\end{PROOF}

\begin{majorILnc}{\LnpEC{GSL Connective ID 2}}
	Define disjunction using negation and conjunction.
\end{majorILnc}
\begin{PROOF}
	Any sentence $\disjunction{\CAPPHI_1}{\disjunction{\ldots}{\CAPPHI_{\integer{n}}}}$ is \CAPS{tfe} to the sentence $\negation{\parconjunction{\negation{\CAPPHI_1}}{\conjunction{\ldots}{\negation{\CAPPHI_{\integer{n}}}}}}$.
\end{PROOF}

\begin{majorILnc}{\LnpEC{GSL Connective ID two and half}}
	Define conditional using negation and disjunction.
\end{majorILnc}
\begin{PROOF}
	Any sentence $\horseshoe{\CAPPHI_1}{\CAPPHI_2}$ is \CAPS{tfe} to the sentence $\disjunction{\negation{\CAPPHI_1}}{\CAPPHI_2}$.
\end{PROOF}

\begin{majorILnc}{\LnpEC{GSL Connective ID 3}}
	The pairs $\NEGATION$ and $\WEDGE$, and $\NEGATION$ and $\VEE$ are each adequate to define the remaining connectives in \GSL{}.
\end{majorILnc}
\begin{PROOF}
	By example \ref{GSL Connective ID 2}, with $\NEGATION$ and $\WEDGE$ we can define $\VEE$. 
	By example \ref{TFE Ex 2}, $\horseshoe{\CAPPHI}{\CAPTHETA}$ and $\disjunction{\negation{\CAPPHI}}{\CAPTHETA}$ are \CAPS{tfe}.
	So we can define $\HORSESHOE$ with $\NEGATION$ and $\WEDGE$. 
	As the reader can check, $\triplebar{\CAPPHI}{\CAPPSI}$ is \CAPS{tfe} to $\conjunction{\parhorseshoe{\CAPPHI}{\CAPPSI}}{\parhorseshoe{\CAPPSI}{\CAPPHI}}$.
	So we can define $\TRIPLEBAR$ with $\NEGATION$ and $\WEDGE$.
	
	We leave it to the reader to show that $\NEGATION$ and $\VEE$ are adequate to define the remaining connectives in \GSL{}.
\end{PROOF}

\noindent{}We don't need all five connectives, but for the sake of convenience we keep them all.  We also asked the following: 
Are the five operations we have enough? 
That is, are there other logical operations we can't express and should add notation for? 
It turns out that our connectives are adequate. 
There are no other logical operations we can't express.
Although it does not strictly depend on the \CAPS{dnf} theorem, the idea behind that theorem lets us prove this.
\begin{THEOREM}{\LnpTC{Truth-functional Expressive Completeness of GSL} The Truth-functional Expressive Completeness Theorem:}
Any truth-functional connective of any fixed number of arguments (ternary, quadernary, etc.) is already expressible in \GSL{}.
\end{THEOREM}
\begin{PROOF}
Any truth functional connective of a fixed number of arguments assigns $\TrueB$ or $\FalseB$ depending only on the values of the components, so it can be exactly described by a truth table. 
For example, consider the 4-place operation \% given by truth \mbox{table \ref{DNFtruthtable}} below.
\begin{table}[!ht]
\begin{center}
\begin{tabular}{ c c c c c}
$\CAPPHI_1$ & $\CAPPHI_2$ & $\CAPPHI_3$ & $\CAPPHI_4$ & $\text{\%}(\CAPPHI_1,\CAPPHI_2,\CAPPHI_3,\CAPPHI_4)$ \\
\hline
$ $ $ $ \\[-.25cm]
$\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ & $\TrueB$ \\
$\TrueB$ & $\TrueB$ & $\TrueB$ & $\FalseB$&$\FalseB$ \\
$\TrueB$ & $\TrueB$ & $\FalseB$ & $\TrueB$ & $\TrueB$ \\
$\TrueB$ & $\TrueB$ & $\FalseB$ & $\FalseB$  &$\FalseB$ \\
$\TrueB$ &  $\FalseB$& $\TrueB$ & $\TrueB$	&$\FalseB$ \\
$\TrueB$ & $\FalseB$ & $\TrueB$ & $\FalseB$	& $\TrueB$ \\
$\TrueB$ &$\FalseB$  & $\FalseB$& $\TrueB$	&$\FalseB$ \\
$\TrueB$ & $\FalseB$ &$\FalseB$	& $\FalseB$	&$\FalseB$ \\
$\FalseB$	& $\TrueB$ & $\TrueB$ & $\TrueB$	& $\TrueB$ \\
$\FalseB$	& $\TrueB$ & $\TrueB$ & $\FalseB$	&$\FalseB$ \\
$\FalseB$	& $\TrueB$ & $\FalseB$&	$\TrueB$ &$\FalseB$ \\
$\FalseB$	& $\TrueB$ & $\FalseB$& $\FalseB$	&$\FalseB$ \\
$\FalseB$	& $\FalseB$	& $\TrueB$ & $\TrueB$	&$\FalseB$ \\
$\FalseB$	& $\FalseB$	& $\TrueB$ & $\FalseB$	&$\FalseB$ \\
$\FalseB$	& $\FalseB$	& $\FalseB$& $\TrueB$	& $\TrueB$ \\
$\FalseB$	& $\FalseB$& $\FalseB$& $\FalseB$	&$\FalseB$ \\
\end{tabular}
\end{center}
\caption{Truth Table for \%}
\label{DNFtruthtable}
\end{table}
We could attempt to find a complicated sentence in terms of various
connectives that would express this, but it will be better for our purposes to construct
a \CAPS{dnf} equivalent systematically. We know from the first line that the expression $\text{\%}(\CAPPHI_1,\CAPPHI_2,\CAPPHI_3,\CAPPHI_4)$ is
true when all components are, that is, if $\parconjunction{\CAPPHI_1}{\conjunction{\CAPPHI_2}{\conjunction{\CAPPHI_3}{\CAPPHI_4}}}$ is true; we know from the third line it is true when the first two, $\CAPPHI_1$ and $\CAPPHI_2$, and fourth, $\CAPPHI_4$, are true and the third, $\CAPPHI_3$, false, i.e., $\parconjunction{\CAPPHI_1}{\conjunction{\CAPPHI_2}{\conjunction{\negation{\CAPPHI_3}}{\CAPPHI_4}}}$. We also know it is true when only the first, $\CAPPHI_1$, and third, $\CAPPHI_3$, are true, i.e., $\parconjunction{\CAPPHI_1}{\conjunction{\negation{\CAPPHI_2}}{\conjunction{\CAPPHI_3}{\negation{\CAPPHI_4}}}}$, when the first, $\CAPPHI_1$, is false and the other three, $\CAPPHI_2$, $\CAPPHI_3$, and $\CAPPHI_4$, are true i.e., $\parconjunction{\negation{\CAPPHI_1}}{\conjunction{\CAPPHI_2}{\conjunction{\CAPPHI_3}{\CAPPHI_4}}}$ and when all but the fourth, $\CAPPHI_4$, are false, i.e., $\parconjunction{\negation{\CAPPHI_1}}{\conjunction{\negation{\CAPPHI_2}}{\conjunction{\negation{\CAPPHI_3}}{\CAPPHI_4}}}$. Because each of these conjunctions is true exactly when the corresponding line is true the whole sentence will be true when any one of them is true, i.e., it is equivalent to the formula: 
\begin{menumerate} 
\item $\disjunction{\parconjunction{\CAPPHI_1}{\conjunction{\CAPPHI_2}{\conjunction{\CAPPHI_3}{\CAPPHI_4}}}}{\disjunction{\parconjunction{\CAPPHI_1}{\conjunction{\CAPPHI_2}{\conjunction{\negation{\CAPPHI_3}}{\CAPPHI_4}}}}{\parconjunction{\CAPPHI_1}{\conjunction{\negation{\CAPPHI_2}}{\conjunction{\CAPPHI_3}{\negation{\CAPPHI_4}}}}}}\:\VEE$\\ $\disjunction{\parconjunction{\negation{\CAPPHI_1}}{\conjunction{\CAPPHI_2}{\conjunction{\CAPPHI_3}{\CAPPHI_4}}}}{\parconjunction{\negation{\CAPPHI_1}}{\conjunction{\negation{\CAPPHI_2}}{\conjunction{\negation{\CAPPHI_3}}{\CAPPHI_4}}}}$
\end{menumerate}
We could simplify this sentence further, but that is not important for our purposes. 
We now can see how to read off from any truth table for any operation on any fixed number of sentences a \CAPS{dnf} representation that is equivalent. 
Our five connectives are enough. 
\end{PROOF}

%We know that we can define conjunction using negation and disjunction (ex. \pmvref{GSL Connective ID 1}), and we can define disjunction using conjunction and negation (ex. \pmvref{GSL Connective ID 2}).
Since either of the pairs \mention{$\NEGATION$} and \mention{$\!\WEDGE\!$}, or \mention{$\NEGATION$} and \mention{$\VEE$} are adequate to define the remaining connectives in \GSL{} (see ex. \pmvref{GSL Connective ID 1}) we can see that either of those pairs is adequate to define all truth-functional connectives.
We can even improve on that though, because there are two connectives either of which would be adequate all by itself. 
One is the Sheffer stroke\index{Sheffer stroke|see{NAND}}, named after the logician who first demonstrated its properties and the symbol he used, \mention{|}, but it is sometimes called NAND.\index{NAND} 
Its definition is that $(\CAPPHI_1|\CAPPHI_2|\ldots|\CAPPHI_{\integer{n}})$ is true \Iff at least one component is false. So, $(\CAPPHI_1|\CAPPHI_1)$ is equivalent to $\negation{\CAPPHI}$. 
And $(\negation{\CAPPHI_1}|\negation{\CAPPHI_2}|\ldots|\negation{\CAPPHI_{\integer{n}}})$ is true just in case at least one component is false. That means at least one $\CAPPHI_i$ is true, which is to say that the sentence is equivalent to a disjunction. 
The other connective that is adequate by itself is NOR,\index{NOR} which is defined to be true \Iff all the components are false. It is left to the reader as an optional exercise to show how to define the other connectives using NOR. 

Thus, to get a language just as expressive as \GSL{}, we only need one logical connective (either NAND or NOR), not five. 
If we had a taste for cutting down basic symbols, we could go further and generate an infinite set of sentence letters by using just one symbol, \mention{$\Al$}, and generating new sentence letters by concatenating prime marks \mention{$'$} to it. 
Then all we need are parentheses (though there are ways to do without these too). 
Such a language is sparse, but it is just as expressive as \GSL{}.  Most people would find such a language difficult to work with, but computers love them.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Exercises}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\notocsubsection{Recursive Definition Problems}{ex:Recursive Definitions Problems}

\begin{enumerate}
\item Although it's not framed as one, definition \mvref{Order} of order is a recursive definition. Rewrite it so that the base, generating, and closure clauses are explicit. 
\item Although we don't give a recursive definition, a recursive definition can be given for the unofficial \GSL{} sentences. (Definition \pmvref{Unofficial Sentence of GSL} is the definition we give.) Write down a recursive definition for unofficial \GSL{} sentences.
\end{enumerate}

\notocsubsection{Construction Trees}{ex:Construction Trees}
Write the construction tree for each of the following \GSL{} sentences.
\begin{multicols}{2}
\begin{enumerate}
\item $\negation{\negation{\negation{\Bl}}}$
\item $\negation{\pardisjunction{\Bl}{\parhorseshoe{\Al}{\Al}}}$
\item $\pardisjunction{\negation{\Bl}}{\parhorseshoe{\Al}{\Al}}$
\item $\parhorseshoe{\partriplebar{\parconjunction{\Al}{\Bl}}{\Al}}{\negation{\parhorseshoe{\Bl}{\Cl}}}$
\item $\parhorseshoe{\parconjunction{\partriplebar{\Al}{\Bl}}{\Al}}{\negation{\parhorseshoe{\Bl}{\Cl}}}$
\item $\parconjunction{\Pl}{\parconjunction{\Ql}{\Rl}}$
\item $\parconjunction{\parconjunction{\Pl}{\Ql}}{\Rl}$
\item $\parhorseshoe{\parconjunction{\Pl}{\negation{\Rl}}}{\negation{\Ql}}$
\item $\parconjunction{\Pl}{\parhorseshoe{\negation{\Rl}}{\negation{\Ql}}}$
\item $\negation{\pardisjunction{\parhorseshoe{\Pl}{\Ql}}{\parhorseshoe{\Pl}{\Ql}}}$
\end{enumerate}
\end{multicols}

\notocsubsection{Official and Unofficial Sentences}{ex:Official and Unofficial Sentences} 
Which of these are official sentences? Which are unofficial? Which are neither official nor unofficial sentences? If
neither, how could you make it either an official or unofficial sentence? Note: there
might be multiple different ways to make it an official or unofficial sentence. Finally, if it's a sentence (official or unofficial), then give its order and the number of subsentences in it. 
\begin{multicols}{2}
\begin{enumerate}
\item {$\parhorseshoe{\Al}{\conjunction{\Bl}{\Cl}}$}
\item {$\parhorseshoe{\Al}{\bparhorseshoe{\Bl}{\Cl}}$}
\item {$\horseshoe{\Al}{\parconjunction{\Bl}{\conjunction{\Cl}{\Bl}}}$}
\item {$\parhorseshoe{\Al}{\parconjunction{\CAPTHETA}{\Cl}}$}
\item {$\parhorseshoe{\Al}{\parconjunction{\Bl}{\disjunction{\Cl}{\Dl}}}$}
\item {$\parhorseshoe{\Al}{\parconjunction{\Zl}{\Cl}}$}
\item {$\parhorseshoe{\negation{\Al}}{\parconjunction{\Bl_{374}}{\Cl}}$}
\item {$\parhorseshoe{\Al}{\parconjunction{\Bl}{\Cl}}$}
\item {$\parnegation{\parconjunction{\Bl}{\Cl}}$}
\item {$\bparconjunction{\Bl}{\conjunction{\negation{\negation{\Ml}}}{\Dl}}$}
\end{enumerate}
\end{multicols}

\notocsubsection{Truth in a Model}{ex:GSLTruth in an Interpretation}
Consider the model $\IntA_1$ such that $\IntA_1(\Al)=\TrueB$, $\IntA_1(\Bl)=\FalseB$, $\IntA_1(\Cl)=\TrueB$, $\IntA_1(\Dl)=\FalseB$, and $\IntA_1(\El)=\TrueB$; and the model $\IntA_2$ such that $\IntA_2(\Al)=\TrueB$, $\IntA_2(\Bl)=\TrueB$, $\IntA_2(\Cl)=\FalseB$, $\IntA_2(\Dl)=\FalseB$, and $\IntA_2(\El)=\FalseB$.
Give the truth values of each of the following \GSL{} sentences on each of these two models.
\begin{multicols}{2}
\begin{enumerate}
\item $\horseshoe{\pardisjunction{\Al}{\Bl}}{\parconjunction{\Cl}{\Dl}}$
\item $\horseshoe{\pardisjunction{\Al}{\Bl}}{\parconjunction{\Cl}{\negation{\Dl}}}$
\item $\horseshoe{\parconjunction{\Cl}{\Dl}}{\pardisjunction{\Al}{\Bl}}$
\item $\conjunction{\parhorseshoe{\Al}{\Cl}}{\El}$
\item $\negation{\conjunction{\parhorseshoe{\Bl}{\El}}{\Dl}}$
\item $\disjunction{\negation{\pardisjunction{\Al}{\Bl}}}{\parconjunction{\Al}{\conjunction{\Bl}{\parhorseshoe{\El}{\El}}}}$
\item $\disjunction{\Al}{\parhorseshoe{\Bl}{\parhorseshoe{\El}{\El}}}$
\item $\disjunction{\parconjunction{\Al}{\El}}{\disjunction{\parconjunction{\negation{\Dl}}{\Cl}}{\parconjunction{\Bl}{\negation{\Al}}}}$
\end{enumerate}
\end{multicols}

\notocsubsection{\CAPS{tft}, \CAPS{tff}, and \CAPS{tfc}}{ex:TFT, TFF, and TFI}
For each of the following say whether the sentence is \CAPS{tfc}, \CAPS{tff} or \CAPS{tft}. 
If it is \CAPS{tfc}, give a model which makes the sentence $\True$ and another model which makes it $\False$. 
If it is \CAPS{tff}, justify your answer without truth tables (i.e., explain why there is no model which makes the sentence $\True$). 
If it is \CAPS{tft}, again justify your answer without truth tables (i.e., explain why every model makes the sentence $\True$).

\begin{multicols}{2}
\begin{enumerate}
\item {$\horseshoe{\parhorseshoe{\Al}{\Bl}}{\pardisjunction{\negation{\Bl}}{\negation{\Al}}}$}
\item {$\horseshoe{\parconjunction{\Al}{\Bl}}{\partriplebar{\Al}{\Bl}}$}
\item {$\horseshoe{\pardisjunction{\negation{\Al}}{\negation{\Bl}}}{\negation{\parconjunction{\Al}{\Bl}}}$}
\item {$\disjunction{\Al}{\parhorseshoe{\Al}{\Bl}}$}
\item {$\horseshoe{\negation{\pardisjunction{\Al}{\Bl}}}{\parconjunction{\negation{\Al}}{\negation{\Bl}}}$}
\item {$\horseshoe{\negation{\partriplebar{\Al}{\Bl}}}{\partriplebar{\negation{\Al}}{\Bl}}$}
\item {$\horseshoe{\parconjunction{\Al}{\pardisjunction{\Bl}{\Cl}}}{\pardisjunction{\parconjunction{\Al}{\Bl}}{\Cl}}$}
\item {$\horseshoe{\negation{\Al}}{\parhorseshoe{\Al}{\Bl}}$}
\item {$\horseshoe{\parconjunction{\negation{\Al}}{\negation{\Bl}}}{\negation{\pardisjunction{\Al}{\Bl}}}$}
\item {$\horseshoe{\Al}{\parhorseshoe{\Al}{\Bl}}$}
\item {$\horseshoe{\partriplebar{\Al}{\Bl}}{\parconjunction{\Al}{\Bl}}$}
\item {$\horseshoe{\negation{\parhorseshoe{\Al}{\Bl}}}{\Al}$}
\item {$\horseshoe{\negation{\parconjunction{\Al}{\Bl}}}{\pardisjunction{\negation{\Al}}{\negation{\Bl}}}$}
\item {$\horseshoe{\Al}{\parhorseshoe{\Bl}{\Al}}$}
\item {$\horseshoe{\parhorseshoe{\Al}{\Bl}}{\parconjunction{\Al}{\negation{\Bl}}}$}
\item {$\negation{\pardisjunction{\Al}{\parhorseshoe{\Al}{\Bl}}}$}
\end{enumerate}
\end{multicols}


\notocsubsection{Entailment Problems for \GSL{}}{Entailment Problems for GSL}
For each of the following, without using truth tables show whether the entailment holds.

\begin{commentary}
There are a number of different methods for thinking through these problems.  
Remember that an entailment means that on all $\IntA$ if the \CAPS{lhs} is $\True$ then the \CAPS{rhs} is also $\True$.  One approach is to show that making the \CAPS{lhs} $\True$ forces the \CAPS{rhs} to be $\True$.  Another is to show that making the \CAPS{rhs} $\False$ forces the \CAPS{lhs} to be $\False$.  Both are examples of arguing that it is not possible for the \CAPS{lhs} to be $\True$ and the \CAPS{rhs} $\False$.  Another method is showing that all $\IntA$ either make the \CAPS{lhs} $\False$ or the \CAPS{rhs} $\True$.  If the entailment does not hold, you can show this by providing a counterexample.
\end{commentary}
\begin{multicols}{2}
\begin{enumerate}
\item {$\negation{\Al}\sdtstile{}{}\parhorseshoe{\Al}{\Bl}$}
\item {$\parhorseshoe{\Al}{\Bl}\sdtstile{}{}\pardisjunction{\negation{\Bl}}{\negation{\Al}}$}
\item {$\parconjunction{\negation{\Al}}{\negation{\Bl}}\sdtstile{}{}\:\negation{\pardisjunction{\Al}{\Bl}}$}
\item\label{HW Entailment 4} {$\pardisjunction{\negation{\Al}}{\negation{\Bl}}\sdtstile{}{}\:\negation{\parconjunction{\Al}{\Bl}}$}
\item {$\Al\sdtstile{}{}\parhorseshoe{\Al}{\Bl}$}
\item {$\negation{\partriplebar{\Al}{\Bl}}\sdtstile{}{}\partriplebar{\negation{\Al}}{\Bl}$} 
\vfill
\item {$\parconjunction{\Al}{\pardisjunction{\Bl}{\Cl}}\sdtstile{}{}\pardisjunction{\parconjunction{\Al}{\Bl}}{\Cl}$}
\item {$\negation{\pardisjunction{\Al}{\Bl}}\sdtstile{}{}\parconjunction{\negation{\Al}}{\negation{\Bl}}$}
\item {$\Al\sdtstile{}{}\parhorseshoe{\Bl}{\Al}$}
\item {$\parconjunction{\Al}{\Bl}\sdtstile{}{}\partriplebar{\Al}{\Bl}$}
\item {$\negation{\parhorseshoe{\Al}{\Bl}}\sdtstile{}{}\parhorseshoe{\Bl}{\Al}$}
\item\label{HW Entailment 12} {$\negation{\parconjunction{\Al}{\Bl}}\sdtstile{}{}\pardisjunction{\negation{\Al}}{\negation{\Bl}}$}
\item {$\negation{\parhorseshoe{\Al}{\Bl}}\sdtstile{}{}\Al$}
\item {$\partriplebar{\Al}{\Bl}\sdtstile{}{}\parconjunction{\Al}{\Bl}$}
\end{enumerate}
\end{multicols}

%\notocsubsection{Testing for Entailment}{ex:Testing for Entailment}
%For each problem in exercise \ref{Entailment Problems for GSL}, use truth tables to test whether the entailment holds. 

\notocsubsection{More Entailment Problems for \GSL{}}{ex:More Entailment Problems for GSL} 
Show whether, for any \GSL{} sentence $\CAPPHI$, $\CAPTHETA$, and $\CAPPSI$, each of the following statements is true.
%Show whether each of the following entailments hold, for any sentences got by substituting into the schemas.
\begin{enumerate}
\item {$\sdtstile{}{}\disjunction{\parhorseshoe{\CAPPHI}{\CAPTHETA}}{\parhorseshoe{\CAPTHETA}{\CAPPHI}}$}
\item {Either $\sdtstile{}{}\parhorseshoe{\CAPPHI}{\CAPTHETA}$, or $\sdtstile{}{}\parhorseshoe{\CAPTHETA}{\CAPPHI}$}
\item {If $\sdtstile{}{}\parhorseshoe{\CAPPHI}{\CAPTHETA}$ and $\sdtstile{}{}\CAPPHI$, then $\sdtstile{}{}\CAPTHETA$}
\item {If $\sdtstile{}{}\parhorseshoe{\CAPPHI}{\CAPTHETA}$ and $\sdtstile{}{}\:\negation{\CAPPHI}$, then $\sdtstile{}{}\:\negation{\CAPTHETA}$}
\item {$\sdtstile{}{}\disjunction{\parhorseshoe{\CAPPHI}{\CAPTHETA}}{\parhorseshoe{\CAPTHETA}{\CAPPSI}}$}
\item {If $\parconjunction{\CAPPHI}{\CAPTHETA}\sdtstile{}{}\CAPPSI$, then both $\CAPPHI\sdtstile{}{}\CAPPSI$ and $\CAPTHETA\sdtstile{}{}\CAPPSI$}
\item {If $\CAPPSI\sdtstile{}{}\parconjunction{\CAPPHI}{\CAPTHETA}$, then both $\CAPPSI\sdtstile{}{}\CAPTHETA$ and $\CAPPSI\sdtstile{}{}\CAPPHI$}
\end{enumerate}

\notocsubsection{Even More Entailment Problems: Truth-preservation Lemma}{exercises:truth-preservation lemma} 
Show that, for any \GSL{} sentence $\CAPPHI$, $\CAPTHETA$, and $\CAPPSI$, each of the following entailments holds.
Showing that these entailments hold will be helpful later, since they are needed in the proof of theorems \mvref{Soundess of Basic GSD Rules} and \mvref{Soundness of Std Shortcut Applications}.
\begin{multicols}{2}
\begin{enumerate}
\item $\CAPPHI\sdtstile{}{}\CAPPHI$.
\item $\horseshoe{\CAPTHETA}{\CAPPSI},\CAPTHETA\sdtstile{}{}\CAPPSI$
\item $\conjunction{\CAPTHETA}{\CAPPSI}\sdtstile{}{}\CAPPSI$
\item $\conjunction{\CAPTHETA}{\CAPPSI}\sdtstile{}{}\CAPTHETA$
\item $\CAPTHETA,\CAPPSI\sdtstile{}{}\conjunction{\CAPTHETA}{\CAPPSI}$
\item $\disjunction{\CAPTHETA}{\CAPPSI},\horseshoe{\CAPTHETA}{\CAPPHI},\horseshoe{\CAPPSI}{\CAPPHI}\sdtstile{}{}\CAPPHI$
\item $\CAPTHETA\sdtstile{}{}\disjunction{\CAPTHETA}{\CAPPSI}$
\item $\horseshoe{\CAPTHETA}{\parconjunction{\CAPPSI}{\negation{\CAPPSI}}}\sdtstile{}{}\negation{\CAPTHETA}$
\item $\horseshoe{\negation{\CAPTHETA}}{\parconjunction{\CAPPSI}{\negation{\CAPPSI}}}\sdtstile{}{}\CAPTHETA$
\item $\horseshoe{\CAPTHETA}{\CAPPSI},\horseshoe{\CAPPSI}{\CAPTHETA}\sdtstile{}{}\triplebar{\CAPTHETA}{\CAPPSI}$
\item $\triplebar{\CAPTHETA}{\CAPPSI},\CAPPSI\sdtstile{}{}\CAPTHETA$
\item $\triplebar{\CAPTHETA}{\CAPPSI},\CAPTHETA\sdtstile{}{}\CAPPSI$
\item $\horseshoe{\CAPPSI}{\CAPTHETA},\negation{\CAPTHETA}\sdtstile{}{}\negation{\CAPPSI}$
\item $\disjunction{\CAPPSI}{\CAPTHETA},\negation{\CAPTHETA}\sdtstile{}{}\CAPPSI$
\item $\disjunction{\CAPTHETA}{\CAPPSI},\negation{\CAPPSI}\sdtstile{}{}\CAPTHETA$
\item $\CAPTHETA,\negation{\CAPTHETA}\sdtstile{}{}\CAPPSI$
\item $\triplebar{\CAPPSI}{\CAPTHETA}\sdtstile{}{}\triplebar{\negation{\CAPPSI}}{\negation{\CAPTHETA}}$
\end{enumerate}
\end{multicols}

\notocsubsection{Truth Functional Equivalence}{exercises:GSDTFETheorem} 
Without using truth tables, show that each of the following pairs of sentences is \CAPS{tfe}, for any sentences got by substituting into the schemas. 
Showing that these pairs are \CAPS{tfe} will be helpful later, since it's both needed for the proof of theorem \mvref{Soundness of Std Shortcut Applications} and it amounts to proving theorem \mvref{ExchangeRuleGSDSoundnessLemma} (including for \Rule{$\TRIPLEBAR$-Exchange}), which is needed to prove theorem \mvref{ExchangeRuleGSDSoundness}.
\begin{enumerate}

\item $\negation{\parconjunction{\CAPPHI_1}{\conjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$, $\disjunction{\negation{\CAPPHI_1}}{\disjunction{\ldots}{\negation{\CAPPHI_{\integer{n}}}}}$

%\item $\disjunction{\negation{\CAPPHI_1}}{\disjunction{\ldots}{\negation{\CAPPHI_{\integer{n}}}}}$, $\negation{\parconjunction{\CAPPHI_1}{\conjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$
 
\item $\negation{\pardisjunction{\CAPPHI_1}{\disjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$, $\conjunction{\negation{\CAPPHI_1}}{\conjunction{\ldots}{\negation{\CAPPHI_{\integer{n}}}}}$ 
 
%\item $\conjunction{\negation{\CAPPHI_1}}{\conjunction{\ldots}{\negation{\CAPPHI_{\integer{n}}}}}$, $\negation{\pardisjunction{\CAPPHI_1}{\disjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$ 
 
\item $\negation{\negation{\CAPPHI}}$, $\CAPPHI$

%\item $\CAPPHI$, $\negation{\negation{\CAPPHI}}$ 

\item $\horseshoe{\CAPPHI}{\CAPTHETA}$, $\disjunction{\negation{\CAPPHI}}{\CAPTHETA}$ 

%\item $\disjunction{\negation{\CAPPHI}}{\CAPTHETA}$, $\horseshoe{\CAPPHI}{\CAPTHETA}$
 
\item $\horseshoe{\CAPPHI}{\CAPTHETA}$, $\horseshoe{\negation{\CAPTHETA}}{\negation{\CAPPHI}}$ 

%\item $\horseshoe{\negation{\CAPTHETA}}{\negation{\CAPPHI}}$, $\horseshoe{\CAPPHI}{\CAPTHETA}$ 
 
\item $\negation{\parhorseshoe{\CAPPHI}{\CAPTHETA}}$, $\conjunction{\CAPPHI}{\negation{\CAPTHETA}}$

%\item $\conjunction{\CAPPHI}{\negation{\CAPTHETA}}$, $\negation{\parhorseshoe{\CAPPHI}{\CAPTHETA}}$
 
\item $\conjunction{\CAPTHETA}{\pardisjunction{\CAPPHI_1}{\disjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$, $\disjunction{\parconjunction{\CAPTHETA}{\CAPPHI_1}}{\disjunction{\ldots}{\parconjunction{\CAPTHETA}{\CAPPHI_{\integer{n}}}}}$

%\item $\disjunction{\parconjunction{\CAPTHETA}{\CAPPHI_1}}{\disjunction{\ldots}{\parconjunction{\CAPTHETA}{\CAPPHI_{\integer{n}}}}}$, $\conjunction{\CAPTHETA}{\pardisjunction{\CAPPHI_1}{\disjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$
 

\item $\conjunction{\pardisjunction{\CAPPHI_1}{\disjunction{\ldots}{\CAPPHI_{\integer{n}}}}}{\CAPTHETA}$, $\disjunction{\parconjunction{\CAPPHI_1}{\CAPTHETA}}{\disjunction{\ldots}{\parconjunction{\CAPPHI_{\integer{n}}}{\CAPTHETA}}}$
 
%\item $\disjunction{\parconjunction{\CAPPHI_1}{\CAPTHETA}}{\disjunction{\ldots}{\parconjunction{\CAPPHI_{\integer{n}}}{\CAPTHETA}}}$, $\conjunction{\pardisjunction{\CAPPHI_1}{\disjunction{\ldots}{\CAPPHI_{\integer{n}}}}}{\CAPTHETA}$
 
 
\item $\disjunction{\CAPTHETA}{\parconjunction{\CAPPHI_1}{\conjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$, $\conjunction{\pardisjunction{\CAPTHETA}{\CAPPHI_1}}{\conjunction{\ldots}{\pardisjunction{\CAPTHETA}{\CAPPHI_{\integer{n}}}}}$
 
%\item $\conjunction{\pardisjunction{\CAPTHETA}{\CAPPHI_1}}{\conjunction{\ldots}{\pardisjunction{\CAPTHETA}{\CAPPHI_{\integer{n}}}}}$, $\disjunction{\CAPTHETA}{\parconjunction{\CAPPHI_1}{\conjunction{\ldots}{\CAPPHI_{\integer{n}}}}}$

\item $\disjunction{\parconjunction{\CAPPHI_1}{\conjunction{\ldots}{\CAPPHI_{\integer{n}}}}}{\CAPTHETA}$, $\conjunction{\pardisjunction{\CAPPHI_1}{\CAPTHETA}}{\conjunction{\ldots}{\pardisjunction{\CAPPHI_{\integer{n}}}{\CAPTHETA}}}$

%\item $\conjunction{\pardisjunction{\CAPPHI_1}{\CAPTHETA}}{\conjunction{\ldots}{\pardisjunction{\CAPPHI_{\integer{n}}}{\CAPTHETA}}}$, $\disjunction{\parconjunction{\CAPPHI_1}{\conjunction{\ldots}{\CAPPHI_{\integer{n}}}}}{\CAPTHETA}$

\item $\triplebar{\CAPTHETA}{\CAPPSI}$, $\disjunction{\parconjunction{\CAPTHETA}{\CAPPSI}}{\parconjunction{\negation{\CAPTHETA}}{\negation{\CAPPSI}}}$

\end{enumerate}

%\notocsubsection{Testing for Truth Functional Equivalence}{exercises:TestingGSDTFETheorem} 
%Use truth tables to show that the sentences in each of the pairs given in exercise \ref{exercises:GSDTFETheorem} are \CAPS{tfe}. 

\notocsubsection{Relations Between \GSL{} Sentences}{ex:Relations Between GSL Sentences}
What relations hold among these sentences? Specifically, say whether they are contradictory, contrary, subcontrary, independent, or truth functionally equivalent. You need to supply 30 answers for each problem: for each sentence $\CAPPHI$, you must determine for each of the 5 relations whether it holds between $\CAPPHI$ and each of the 6 other sentences.
\begin{multicols}{2}
\begin{enumerate}
\item {$\Al$}
\item {$\conjunction{\Al}{\Bl}$}
\item {$\conjunction{\negation{\Al}}{\Bl}$}
\item {$\horseshoe{\Al}{\Cl}$}
\item {$\horseshoe{\Al}{\negation{\Cl}}$}
\item {$\disjunction{\parconjunction{\Al}{\Bl}}{\Cl}$}
\end{enumerate}
\end{multicols}
\begin{enumerate}[start=7]
\item {$\conjunction{\Dl}{\negation{\Dl}}$}
\end{enumerate}

%\notocsubsection{Testing for Relations Between \GSL{} Sentences}{ex:Testing Relations Between GSL Sentences}
%Write a single joint truth table for the 7 sentences listed in exercise \ref{ex:Relations Between GSL Sentences}. 
%Read off from that table, for each pair of sentences, whether they are contradictory, contrary, subcontrary, independent, or truth functionally equivalent. 

\notocsubsection{Recursive Proofs}{ex:Recursive Proofs}

\begin{enumerate}
	\item Prove that all positive multiples of 10 are also multiples of 5.
	\item For each even positive integer $n$, prove that dividing $n$ by 2 results in another positive integer.
\end{enumerate}


\notocsubsection{SL Recursive Proofs}{ex:SL Recursive Proofs} 
Prove each of the following claims using a recursive proof. 
\begin{enumerate}
\item In every \GSL{} sentence which is \CAPS{tff}, there is a subsentence which is \CAPS{tfc}.
\begin{commentary}
	\emph{Hint:} The idea behind this proof is easy. Don't over-think it. 	
\end{commentary}

\item Show that every \CAPS{tff} sentence of \GSL{} contains at least one \mention{$\NEGATION$}.
\begin{commentary}
	\emph{Hint:}
	To prove this, it is useful to prove a more specific statement, namely that if $\CAPPHI$ is an \GSL{} sentence that does not contain any negations then $\CAPPHI$ is $\True$ on the model that assigns $\True$ to all sentence letters.
\end{commentary}

\item For every sentence $\CAPPHI$ of \GSL{}, the number of left parentheses occurring in $\CAPPHI$ is less than the number of subsentences. In other words, if LP$\CAPPHI$ is the number of left parentheses in $\CAPPHI$ and SS$\CAPPHI$ is the number of subsentences, then LP$\CAPPHI$ $<$ SS$\CAPPHI$.
\item The number of subsentences in any official \GSL{} sentence $\CAPPHI$ is equal to: the number of tokens of sentence letters in $\CAPPHI$ plus the number of tokens of negation in $\CAPPHI$ plus the number of tokens of left parentheses in $\CAPPHI$.
\item For every sentence $\CAPPHI$ of \GSL{}, there is a \CAPS{tfe} sentence $\CAPPHI'$ without conditionals or biconditionals.
\end{enumerate}

\notocsubsection{DNF}{ex:DNF} 
Put the following into disjunctive normal form.
\begin{multicols}{2}
\begin{enumerate}
\item {$\disjunction{\negation{\parhorseshoe{\Ql}{\Rl}}}{\parhorseshoe{\Ql}{\negation{\Rl}}}$}
\item {$\conjunction{\Ol}{\parhorseshoe{\Ol}{\Ql}}$}
\item {$\horseshoe{\bparhorseshoe{\parhorseshoe{\Ql}{\Rl}}{\Ql}}{\Ql}$}
\item {$\conjunction{\negation{\parhorseshoe{\Ql}{\Rl}}}{\pardisjunction{\Ol}{\Pl}}$}
\end{enumerate}
\end{multicols}


%\theendnotes

